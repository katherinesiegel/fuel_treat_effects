---
title: "update_mtbs_2024"
output: html_document
date: "2025-07-04"
---

## Description
- Add MTBS fires through 2024
- Add FiredPy fires through September 2024
- updates FACTS treatment data through 2024 and adds TWIG ReSHAPE data in addition
- Pulls code from update_mtbs.Rmd (west_us.Rmd and then ft_overlaps.Rmd).

## Notes
- MTBS data downloaded 7/4/2025
- FiredPy data downloaded 7/7/2025
- FACTS data downloaded 7/6/2025
- TWIG ReSHAPE data downloaded 7/6/2025

## Steps
Once GEE finishes processing fire polygons, will need to re-run chunks "make sure all firedpy fires ran in GEE" and "make sure all mtbs fires ran in GEE" to capture any fires that are still missing. As of 7/23 morning, GEE still processing some of the fire CBIs

## After ESA
Things to do after ESA:
- re-do categorization of activities to take both activity and equipment into account (Drip torch, etc)
- use all fires/fuel treatments
- fix EVI
- get climate normals
- fire weather


## Set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Load packages
library(tidyverse)
library(sf)
library(lubridate)
library(raster)
# library(terra)
# library(viridis)
# library(scales)
library(lwgeom)
library(googledrive)
library(furrr)
library(future.apply)
# library(nngeo)
library(igraph)
library(purrr)
library(data.table)
```

Code adapted from west_us.Rmd
## Fire perimeters
### MTBS fire perimeters 
```{r}
### open all fires
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_perims_DD.shp") %>%
  st_transform(., 
               crs = 6350) %>%
  
  ### make column for year
  mutate(ig_year = year(Ig_Date))
  
### get column for state
mtbs <- mtbs %>%
  mutate(state = stringr::str_extract(Event_ID, "^.{2}"))

### filter to western US and surrounding states
mtbs <- mtbs %>%
  filter(state %in% c("AZ", "CA", "CO", "ID", "MT", "NM",
                      "NV", "OR", "UT", "WA", "WY", "ND",
                      "SD", "NE", "KS", "OK", "TX"))

### pull out Nevada fire that gets messed up with I intersect with w_borders
weird_fire <- mtbs %>% filter(Event_ID == "NV4099711695019840830") %>%
  dplyr::select(Event_ID, Incid_Type, 
                Ig_Date, geometry)

### open western states
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp")

### intersect with western US boundaries
mtbs <- st_intersection(mtbs, w_borders)

### reduce cols
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, 
                Ig_Date, geometry)

### drop prescribed fires
mtbs <- mtbs %>%
  filter(!Incid_Type == "Prescribed Fire")

### drop weird fire, add it back
mtbs <- mtbs %>%
  filter(!Event_ID == "NV4099711695019840830")
mtbs <- rbind(mtbs,
              weird_fire)

### Separate out year as column
mtbs <- mtbs %>%
  mutate(date = day(Ig_Date),
         month = month(Ig_Date),
         year = year(Ig_Date))

### Write out
st_write(mtbs,
         "E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp")

rm(w_borders)
rm(mtbs)
gc()
```
### FiredPy
```{r}
### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/fired_conus_ak_2000_to_2024_events.shp")

### drop fire perimeters that are definitely not in forests
firedpy <- firedpy %>%
  filter(!lc_name %in% c("Grasslands", "Barren", "Croplands",
                         "Permanent Wetlands", "Water Bodies",
                         "Urban and Built-up Lands", "Permanent Snow and Ice",
                         "Closed Shrublands", "Open Shrublands"))

### drop fires that are big enough to be included in MTBS (1000 acres or more)
### in firedpy data, tot_ar_km2 = total area burned over course of fire (km2)
firedpy <- firedpy %>%
  mutate(tot_ar_acre = tot_ar_km2 * 247.105) %>%
  filter(tot_ar_acre < 1000)

### transform
firedpy <- firedpy %>%
  st_transform(6350)

### open western states
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp")

### intersect
firedpy_wconus <- st_intersection(firedpy, w_borders)

### subset firedpy to the IDs in firedpy_24_conus
firedpy_keep <- firedpy %>%
  filter(id %in% firedpy_wconus$id)

### Write out
st_write(firedpy_keep,
         "E:/fuel_treat/firedpy/firedpy_2000_2024_west.shp")

rm(w_borders, firedpy, firedpy_wconus, firedpy_keep)
gc()
```

## updated fuel treatment data
FACTS and TWIG use different crs and datums. FACTS uses 4269, while TWIG uses EPSG 3857. Importantly, TWIG's EPSG is mislabeled in the geodatabase as 4326. So need to fix that too.

Fix EPSG code for TWIGS:
ogr2ogr -f "GPKG" treatment_index_correct_crs.gpkg treatment_index.gdb treatment_index -a_srs EPSG:3857

USE GDAL in the command line to reproject both data sources to EPSG 6350 

Fix TWIG: 
ogr2ogr -f "GPKG" twig_gdal.gpkg treatment_index_correct_crs.gpkg -s_srs EPSG:3857 -t_srs EPSG:6350

Fix FACTS: 
ogr2ogr -s_srs EPSG:4269 -t_srs EPSG:6350 facts_gdal.shp S_USA.Actv_HazFuelTrt_PL.shp

Polygons are still slightly offset even after that processing!

```{r}
st_layers("E:/fuel_treat/ft_polys/twig_reshape/treatment_index_correct_crs.gpkg")

check_twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/treatment_index_correct_crs.gpkg")
```
### USFS FACTS
```{r, warning=FALSE}
### Open fuel treatment database
ft <- st_read("E:/fuel_treat/ft_polys/usfs_treat/S_USA.Actv_HazFuelTrt_PL.shp")

### Reproject fuel treatments
ft <- ft %>%
  st_transform(crs = 6350)

### add column for unique identifier
ft <- ft %>%
  mutate(ft_id = row_number())

### Subset to states of the western US (and adjacent states)
ft <- ft %>%
  filter(STATE_ABBR %in% c("AZ", "CA",
                           "CO", "ID",
                           "MT", "NM",
                           "NV", "OR",
                           "UT", "WA", "WY",
                           
                           ### adjacent states
                           "ND", "SD",
                           "NE", "KS", 
                           "OK", "TX"))

### make version of full western fuel treat with id column but no geom
ft_csv <- ft
st_geometry(ft_csv) <- NULL
write_csv(ft_csv, "E:/fuel_treat/ft_polys/usfs_treat/west_fuel_treats.csv")

### clean up
rm(ft_csv)
gc()

### Take out treatments where completed date = NA
ft <- ft %>%
  drop_na(DATE_COMPL)

### simplify columns
ft_simp <- ft %>%
  dplyr::select(ft_id, STATE_ABBR, geometry)

### divide up ft for overlap with western us (otherwise it's very large!)
ft_adj <- ft_simp %>%
  filter(STATE_ABBR %in% c("ND", "SD",
                           "NE", "KS", 
                           "OK", "TX"))
ft_pacific <- ft_simp %>%
  filter(STATE_ABBR %in% c("WA", "OR", "CA"))
ft_sw <- ft_simp %>%
  filter(STATE_ABBR %in% c("AZ", "UT", "CO", "NM"))
ft_n <- ft_simp %>%
  filter(STATE_ABBR %in% c("ID", "NV", "WY", "MT"))
rm(ft_simp)

### Open w_bound
w_bound <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp")

### Intersect treatment boundaries, write out
### adjacent
ft_adj <- st_intersection(ft_adj, 
                          w_bound)
ft_adj <- ft %>%
  filter(ft_id %in% ft_adj$ft_id)
st_write(ft_adj,
         "E:/fuel_treat/ft_polys/usfs_treat/adj_treatments_all.shp")
rm(ft_adj)
gc()

### sw
ft_sw <- st_intersection(ft_sw, 
                         w_bound)
ft_sw <- ft %>%
  filter(ft_id %in% ft_sw$ft_id)
st_write(ft_sw,
         "E:/fuel_treat/ft_polys/usfs_treat/sw_treatments_all.shp")
rm(ft_sw)
gc()

### northern
ft_n <- st_intersection(ft_n, 
                        w_bound)
ft_n <- ft %>%
  filter(ft_id %in% ft_n$ft_id)
st_write(ft_n,
         "E:/fuel_treat/ft_polys/usfs_treat/northern_treatments_all.shp")
rm(ft_n)
gc()

### pacific
ft_pacific <- st_intersection(ft_pacific, 
                              w_bound)
ft_pacific <- ft %>%
  filter(ft_id %in% ft_pacific$ft_id)
st_write(ft_pacific,
         "E:/fuel_treat/ft_polys/usfs_treat/pacific_treatments_all.shp")
rm(ft_pacific)
gc()
```

#### facts drop WFU and date complete = invalid
```{r, warning=FALSE}
############################
### adj
############################
### open facts files 
ft_adj <- st_read("E:/fuel_treat/ft_polys/usfs_treat/adj_treatments_all.shp")

### remove date_compl = NULL
ft_adj <- ft_adj[year(ft_adj$DATE_COMPL) > 1900 &
                   !is.na(ft_adj$DATE_COMPL), ]

### add col for completion year
ft_adj <- ft_adj %>%
  mutate(year_comp = year(DATE_COMPL))
### 25 treatments completed in year "-1"...

### check for wfu
table(ft_adj$ACTIVITY)

### remove natural ignitions
ft_adj <- ft_adj %>%
  filter(!ACTIVITY == "Wildfire - Natural Ignition")

### write out
st_write(ft_adj, 
         "E:/fuel_treat/ft_polys/usfs_treat/adj_treatments_all.shp",
         append = FALSE)

############################
### northern
############################
### open facts files 
ft_n <- st_read("E:/fuel_treat/ft_polys/usfs_treat/northern_treatments_all.shp")

### remove date_compl = NULL
ft_n <- ft_n[year(ft_n$DATE_COMPL) > 10 &
               !is.na(ft_n$DATE_COMPL), ]

### add col for completion year
ft_n <- ft_n %>%
  mutate(year_comp = year(DATE_COMPL))
### 39192 treatments completed in year "-1"...

### check for wfu
table(ft_n$ACTIVITY)

### remove natural ignitions
ft_n <- ft_n %>%
  filter(!ACTIVITY %in% c("Wildfire - Natural Ignition",
                          "Wildfire - Fuels Benefit",
                          "Wildfire - Human Ignition",
                          "Wildland Fire Use"))

### write out
st_write(ft_n, 
         "E:/fuel_treat/ft_polys/usfs_treat/northern_treatments_all.shp",
         append = FALSE)

############################
### southwest
############################
### open facts files 
ft_sw <- st_read("E:/fuel_treat/ft_polys/usfs_treat/sw_treatments_all.shp")

### remove date_compl = NULL
ft_sw <- ft_sw[year(ft_sw$DATE_COMPL) > 10 &
                 !is.na(ft_sw$DATE_COMPL), ]

### add col for completion year
ft_sw <- ft_sw %>%
  mutate(year_comp = year(DATE_COMPL))

### check for wfu
table(ft_sw$ACTIVITY)

### remove natural ignitions
ft_sw <- ft_sw %>%
  filter(!ACTIVITY %in% c("Wildfire - Natural Ignition",
                          "Wildfire - Fuels Benefit",
                          "Wildfire - Human Ignition",
                          "Wildland Fire Use"))

### write out
st_write(ft_sw, 
         "E:/fuel_treat/ft_polys/usfs_treat/sw_treatments_all.shp",
         append = FALSE)

############################
### pacific
############################
### open facts files 
ft_pac <- st_read("E:/fuel_treat/ft_polys/usfs_treat/pacific_treatments_all.shp")

### remove date_compl = NULL
ft_pac <- ft_pac[year(ft_pac$DATE_COMPL) > 10 &
                   !is.na(ft_pac$DATE_COMPL), ]

### add col for completion year
ft_pac <- ft_pac %>%
  mutate(year_comp = year(DATE_COMPL))
### 69394 treatments completed in year "-1"...

### check for wfu
table(ft_pac$ACTIVITY)

### remove natural ignitions
ft_pac <- ft_pac %>%
  filter(!ACTIVITY %in% c("Wildfire - Natural Ignition",
                          "Wildfire - Fuels Benefit",
                          "Wildfire - Human Ignition",
                          "Wildland Fire Use"))

### write out
st_write(ft_pac, 
         "E:/fuel_treat/ft_polys/usfs_treat/pacific_treatments_all.shp",
         append = FALSE)
```
#### year completed issues
```{r}
### subset ft_pac to year_comp < 1
check_yr <- ft_pac %>%
  filter(year_comp < 1) %>%
  dplyr::select(ft_id, SUID, ACTIVITY_C, ACTIVITY, STATE_ABBR,
                DATE_PLANN, DATE_AWARD, DATE_COMPL, year_comp,
                TREATMENT_, ACTIVITY_S, EQUIPMENT, METHOD,
                TREATMENT1, PURPOSE_CO, geometry)

### add year planned
check_yr <- check_yr %>%
  mutate(year_plan = year(DATE_PLANN))

table(check_yr$year_plan)

### write out treatments planned for 1905 
check_1905 <- check_yr %>%
  filter(year_plan < 1910)
st_write(check_1905,
         "E:/fuel_treat/ft_polys/usfs_treat/pac_treat_1905.shp")

### write out treatments planned for 2020 
check_2020 <- check_yr %>%
  filter(year_plan == 2020)
st_write(check_2020,
         "E:/fuel_treat/ft_polys/usfs_treat/pac_treat_2020.shp")
```

### TWIG ReSHAPE
```{r}
### open twig
twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/treatment_index.gdb",
                layer = "treatment_index")

### Subset to states of the western US (and adjacent states)
twig <- twig %>%
  filter(state %in% c("AZ", "CA",
                      "CO", "ID",
                      "MT", "NM",
                      "NV", "OR",
                      "UT", "WA", "WY",
                      
                      ### adjacent states
                      "ND", "SD",
                      "NE", "KS", 
                      "OK", "TX"))

### add col for completion year
twig <- twig %>%
  mutate(year_comp = year(actual_completion_date))

### Check out year distribution
table(twig$year_comp)

### there's a treatment with a completion date of 2105, but "date_current" is in 2015 (2015-10-14 14:18:09). Seems likely to be a typo --> reassign to 2015
twig <- twig %>%
  mutate(year_comp = ifelse(year_comp > 2030, 2015, year_comp))

### take out treatments where completed date = NA
twig <- twig %>%
  drop_na(year_comp)

### figure out which types of geometries we have
table(st_geometry_type(twig, by_geometry = TRUE))

######################################
### figure out what the Z dimension is
######################################

### look at subset
check_z <- twig %>%
  filter(unique_id %in% c("AC13535801035910359", "AC77295601035910359",
                          "AC80562301035910359", "AC1254035010602",
                          "6005281010602", "AC34427701026410264"))
coords_check_z <- st_coordinates(check_z)
head(coords_check_z)

### drop z coords
check_z_drop <- st_zm(check_z, drop = TRUE, what = "ZM")
coords_check_z_drop <- st_coordinates(check_z_drop)
head(coords_check_z_drop)

######################################
######################################

### drop z coords
twig_2d <- st_zm(twig, drop = TRUE, what = "ZM")

### write out
st_write(twig_2d, "E:/fuel_treat/ft_polys/twig_reshape/twig_wus_comp.shp")

### natural ignitions?
table(twig_2d$twig_category)

### drop unplanned ignitions
twig_2d <- twig_2d %>%
  filter(!twig_category == "Unplanned Ignition")

### write out
st_write(twig_2d, 
         "E:/fuel_treat/ft_polys/twig_reshape/twig_wus_comp_drop_unplan.shp")
```

#### twigs fuel treats in western US
```{r}
### open twigs treats
twig_2d <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_wus_comp_drop_unplan.shp")

### Reproject fuel treatments
twig_2d <- twig_2d %>%
  st_transform(crs = 6350)

### add ft_id
twig_2d <- twig_2d %>%
  mutate(ft_id = row_number())

### simplify columns
twig_simp <- twig_2d %>%
  dplyr::select(ft_id,
                unique_id = uniqu_d,
                state,
                geometry)

### divide up ft for overlap with western us (otherwise it's very large!)
twig_adj <- twig_simp %>%
  filter(state %in% c("ND", "SD",
                      "NE", "KS", 
                      "OK", "TX"))
twig_pacific <- twig_simp %>%
  filter(state %in% c("WA", "OR", "CA"))
twig_sw <- twig_simp %>%
  filter(state %in% c("AZ", "UT", "CO", "NM"))
twig_n <- twig_simp %>%
  filter(state %in% c("ID", "NV", "WY", "MT"))
rm(twig_simp)

### Open w_bound
w_bound <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp")

# ### make version of w_bound in EPSG of twigs data for use in git bash
# w_bound_3857 <- st_transform(w_bound, 3857)
# st_write(w_bound_3857, "E:/fuel_treat/ft_polys/twig_reshape/w_bound_3857.shp")

### crop in gdal command line:
# ogr2ogr -f "ESRI Shapefile" treatment_index_6350.shp treatment_index.gdb treatment_index -clipsrc w_bound_3857.shp

### reproject to 6350 to match FACTS database
# ogr2ogr -t_srs EPSG:6350 twigs_6350.shp treatment_index_6350.shp


### Intersect treatment boundaries, write out
### adjacent
twig_adj <- st_intersection(twig_adj, 
                            w_bound)
twig_adj <- twig_2d %>%
  filter(ft_id %in% twig_adj$ft_id)
st_write(twig_adj,
         "E:/fuel_treat/ft_polys/twig_reshape/adj_treatments_all.shp")
rm(twig_adj)
gc()

### sw
twig_sw <- st_intersection(twig_sw, 
                           w_bound)
twig_sw <- twig_2d %>%
  filter(ft_id %in% twig_sw$ft_id)
st_write(twig_sw,
         "E:/fuel_treat/ft_polys/twig_reshape/sw_treatments_all.shp")
rm(twig_sw)
gc()

### northern
twig_n <- st_intersection(twig_n, 
                          w_bound) #303397
twig_n <- twig_2d %>%
  filter(ft_id %in% twig_n$ft_id)
st_write(twig_n,
         "E:/fuel_treat/ft_polys/twig_reshape/northern_treatments_all.shp")
rm(twig_n)
gc()

### pacific
twig_pacific <- st_intersection(twig_pacific, 
                                w_bound)
twig_pacific <- twig_2d %>%
  filter(ft_id %in% twig_pacific$ft_id)
st_write(twig_pacific,
         "E:/fuel_treat/ft_polys/twig_reshape/pacific_treatments_all.shp")
rm(twig_pacific)
gc()
```

## split fuel treat multipolygons
### try with a single ft
```{r}
### open sw
ft_sw <- st_read("E:/fuel_treat/ft_polys/usfs_treat/sw_treatments_all.shp")

### subset to single ft that has multiple polygons
check_ft <- ft_sw %>%
  filter(ft_id == 222401)

### split
check_ft_cast <- st_cast(check_ft, "POLYGON")

### write out
st_write(check_ft_cast, "E:/fuel_treat/ft_polys/usfs_treat/check_multipoly.shp")
```

### split all multipolygons
#### split FACTS 
```{r, warning=FALSE}
### ft_sw
ft_sw_cast <- st_cast(ft_sw, "POLYGON")

### write out
st_write(ft_sw_cast, "E:/fuel_treat/ft_polys/usfs_treat/sw_split.shp")

###########################################
### ft_adj
ft_adj <- st_read("E:/fuel_treat/ft_polys/usfs_treat/adj_treatments_all.shp")

### split polygons
ft_adj_cast <- st_cast(ft_adj, "POLYGON")

### write out
st_write(ft_adj_cast, 
         "E:/fuel_treat/ft_polys/usfs_treat/adj_split.shp")

############################
### northern
ft_n <- st_read("E:/fuel_treat/ft_polys/usfs_treat/northern_treatments_all.shp")

### split polygons
ft_n_cast <- st_cast(ft_n, "POLYGON")

### write out
st_write(ft_n_cast, 
         "E:/fuel_treat/ft_polys/usfs_treat/north_split.shp")

############################
### southwest
ft_sw <- st_read("E:/fuel_treat/ft_polys/usfs_treat/sw_treatments_all.shp")

### split polygons
ft_sw_cast <- st_cast(ft_sw, "POLYGON")

### write out
st_write(ft_sw_cast, 
         "E:/fuel_treat/ft_polys/usfs_treat/sw_split.shp")

############################
### pacific
ft_pac <- st_read("E:/fuel_treat/ft_polys/usfs_treat/pacific_treatments_all.shp")

### split polygons
ft_pac_cast <- st_cast(ft_pac, "POLYGON")

### write out
st_write(ft_pac_cast, 
         "E:/fuel_treat/ft_polys/usfs_treat/pacific_split.shp")
```

##### combine to get ft_id's
```{r}
### open all 
adj <- st_read("E:/fuel_treat/ft_polys/usfs_treat/adj_split.shp")
north <- st_read("E:/fuel_treat/ft_polys/usfs_treat/north_split.shp")
southwest <- st_read("E:/fuel_treat/ft_polys/usfs_treat/sw_split.shp")
pacific <- st_read("E:/fuel_treat/ft_polys/usfs_treat/pacific_split.shp")

### combine
all_facts <- rbind(adj, north, southwest, pacific)

### add unique identifier
all_facts <- all_facts %>%
  mutate(poly_id = row_number())

### write out
st_write(all_facts, "E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")

### drop Planned Treatment Burned in Wildfire
### open
all_facts <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")

### filter
all_facts <- all_facts %>%
  filter(!ACTIVITY == "Planned Treatment Burned in Wildfire")

### write out
st_write(all_facts, 
         "E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp",
         append = FALSE)
```

#### split TWIG 
```{r, warning=FALSE}
### ft_sw
tw_sw <- st_read("E:/fuel_treat/ft_polys/twig_reshape/sw_treatments_all.shp")

### split
tw_sw_cast <- st_cast(tw_sw, "POLYGON")

### write out
st_write(tw_sw_cast, "E:/fuel_treat/ft_polys/twig_reshape/sw_split.shp")

###########################################
### ft_adj
tw_adj <- st_read("E:/fuel_treat/ft_polys/twig_reshape/adj_treatments_all.shp")

### split polygons
tw_adj_cast <- st_cast(tw_adj, "POLYGON")

### write out
st_write(tw_adj_cast, 
         "E:/fuel_treat/ft_polys/twig_reshape/adj_split.shp")

############################
### northern
tw_n <- st_read("E:/fuel_treat/ft_polys/twig_reshape/northern_treatments_all.shp")

### split polygons
tw_n_cast <- st_cast(tw_n, "POLYGON")

### write out
st_write(tw_n_cast, 
         "E:/fuel_treat/ft_polys/twig_reshape/north_split.shp")

############################
### pacific
ft_pac <- st_read("E:/fuel_treat/ft_polys/twig_reshape/pacific_treatments_all.shp")

### split polygons
ft_pac_cast <- st_cast(ft_pac, "POLYGON")

### write out
st_write(ft_pac_cast, 
         "E:/fuel_treat/ft_polys/twig_reshape/pacific_split.shp")
```

##### combine to get ft_id's
```{r}
### open all 
adj <- st_read("E:/fuel_treat/ft_polys/twig_reshape/adj_split.shp")
north <- st_read("E:/fuel_treat/ft_polys/twig_reshape/north_split.shp")
southwest <- st_read("E:/fuel_treat/ft_polys/twig_reshape/sw_split.shp")
pacific <- st_read("E:/fuel_treat/ft_polys/twig_reshape/pacific_split.shp")

### combine
all_twig <- rbind(adj, north, southwest, pacific)

### add unique identifier
all_twig <- all_twig %>%
  mutate(poly_id = row_number())

### write out
st_write(all_twig, "E:/fuel_treat/ft_polys/twig_reshape/all_twig_split.shp")
```

### get rid of prescribed fires in firedpy
```{r}
### open facts treatments
facts <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")

### subset facts to rx fire
facts_rx <- facts %>%
  filter((ACTIVITY %in% c("Broadcast Burning - Covers a majority of the unit",
                          "Burning of Piled Material",
                          "Control of Understory Vegetation- Burning",
                          "Invasives - Cultural /Fire",
                          "Jackpot Burning - Scattered concentrations",
                          "Natural regeneration - prescribed fire",
                          "Site Preparation for Natural Regeneration - Burning",
                          "Site Preparation for Planting - Burning",
                          "Underburn - Low Intensity (Majority of Unit)",
                          "Wildlife Habitat Prescribed fire")) |
           TREATMENT_ %in% c("Broadcast Burn",
                             "Jackpot Burn",
                             "Machine Pile Burn"))
rm(facts)
gc()

### open twigs treatments
twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/all_twig_split.shp")

### subset twig to rx fire
twig_rx <- twig %>%
  filter((method %in% c("Fire", "Prescribed Burn", "Wildfire")) |
           activty %in% c("Broadcast Burning - Covers a majority of the unit", 
                          "Burning of Piled Material",
                          "Control of Understory Vegetation- Burning",
                          "Invasives - Cultural /Fire",
                          "Jackpot Burning - Scattered concentrations",
                          "Natural regeneration - prescribed fire",
                          "Site Preparation for Natural Regeneration - Burning",
                          "Site Preparation for Planting - Burning",
                          "Site preparation for re-vegetation - prescribed fire",
                          "Site Preparation for Seeding - Burning",
                          "Underburn - Low Intensity (Majority of Unit)",
                          "Wildfire - Fuels Benefit",
                          "Wildlife Habitat Prescribed fire"))
rm(twig)
gc()

### simplify
twig_rx <- twig_rx %>%
  dplyr::select(poly_id, 
                activity = activty,
                treatment = method,
                date_comp = actl_c_,
                geometry) %>%
  mutate(source = "twig")
facts_rx <- facts_rx %>%
  dplyr::select(poly_id, 
                activity = ACTIVITY,
                treatment = TREATMENT_,
                date_comp = DATE_COMPL,
                geometry) %>%
  mutate(source = "facts")

### combine
all_rx <- rbind(twig_rx, facts_rx)

### clean up
rm(facts_rx, twig_rx)
gc()

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west.shp")

### have any of the rx treatments overlapped with firedpy perimeters?
ft_firedpy <- st_intersection(firedpy, all_rx) 

### add year column 
ft_firedpy <- ft_firedpy %>%
  mutate(ft_year = year(date_comp))

### subset to overlaps in the same year
ft_firedpy <- ft_firedpy %>%
  filter(ft_year == ig_year)

### 2381 instances where there was a firedpy detection that overlapped with a fire-use fuel treatment in the same year

### drop these from the firedpy dataset
firedpy_use <- firedpy %>%
  filter(!id %in% ft_firedpy$id)

### write out
st_write(firedpy_use, "E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp")
```

#### add state to firedpy
```{r}
### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp")

### open w_states
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp")

### intersect with western US boundaries
firedpy <- st_intersection(firedpy, w_borders)

### reduce cols
firedpy <- firedpy %>%
  mutate(Incid_Type = "non_rx") %>%
  dplyr::select(Event_ID =  id, 
                Incid_Type, 
                Ig_Date = ig_date, 
                date = ig_day,
                month = ig_mnth,
                year = ig_year,
                state = NAME_1,
                geometry)

### fix state names
firedpy <- firedpy %>%
  mutate(state = ifelse(state == "Arizona", "AZ", ifelse(state == "California", "CA", ifelse(state == "Colorado", "CO", ifelse(state == "Idaho", "ID", ifelse(state == "Montana", "MT", ifelse(state == "Nevada", "NV", ifelse(state == "New Mexico", "NM", ifelse(state == "Oregon", "OR", ifelse(state == "Utah", "UT", ifelse(state == "Washington", "WA", ifelse(state == "Wyoming", "WY", state))))))))))))

st_write(firedpy, "E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp",
         append = FALSE)
```


## Harmonize FACTS and TWIG
Specifically, TWIG has data from FACTS Hazardous Fuels, but there are some polygons in TWIG that aren't in FACTS and vice versa
```{r}
### open twig
all_twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/all_twig_split.shp")

### filter to FACTS Hazardous Fuels
twig_fhf <- all_twig %>%
  filter(idntfr_ == "FACTS Hazardous Fuels")

### write out
st_write(twig_fhf,
         "E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp")

### open TWIG FACTS hazardous fuels
twig_fhf <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp")
twig_fhf <- twig_fhf %>%
  rename(unique_id = uniqu_d,
         treatment_date = trtmnt_,
         date_source = dat_src,
         identifier_database = idntfr_,
         date_current = dt_crrn,
         actual_comp_date = actl_c_,
         activity_code = actvty_,
         activity = activty,
         equipment = equpmnt,
         category = categry,
         twig_category = twg_ctg,
         fund_source = fnd_src,
         fund_code = fund_cd,
         total_cost = ttl_cst,
         cost_per_uom = cst_pr_,
         shape_length = shp_Lng,
         shape_area = shap_Ar,
         year_comp = yer_cmp)

### open facts
facts <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")
```
### try centroid approach with small area
```{r}
### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/test_ft_diff/clip_twig.shp") %>%
  rename(., unique_id = uniqu_d,
         treatment_date = trtmnt_,
         date_source = dat_src,
         identifier_database = idntfr_,
         date_current = dt_crrn,
         actual_comp_date = actl_c_,
         activity_code = actvty_,
         activity = activty,
         equipment = equpmnt,
         category = categry,
         twig_category = twg_ctg,
         fund_source = fnd_src,
         fund_code = fund_cd,
         total_cost = ttl_cst,
         cost_per_uom = cst_pr_,
         shape_length = shp_Lng,
         shape_area = shap_Ar,
         year_comp = yer_cmp) %>%
  filter(., identifier_database == "FACTS Hazardous Fuels")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/test_ft_diff/clip_facts.shp")

# ### visualize
# ggplot() +
#   geom_sf(data = fa_c, color = "red", fill = NA) +
#   geom_sf(data = tw_c, color = "blue", fill = NA) +
#   theme_void()
# 
# ### take a look at subset
# test_tw <- tw_c %>%
#   filter(state == "WY" & treatment_date == "2012-10-24")
# test_fa <- fa_c %>%
#   filter(STATE_ABBR == "WY" & DATE_COMPL == "2012-10-24")

### keep necessary columns
test_tw <- tw_c %>%
  dplyr::select(poly_id_twig = poly_id,
                date_comp_twig = treatment_date,
                activity_code_twig = activity_code)
test_fa <- fa_c %>%
  dplyr::select(poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C)

### add centroids
test_tw_c <- test_tw %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- test_fa %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- test_tw %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- test_fa %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- test_tw %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/test_ft_diff/test_centroids_2.shp")
```

#### test poly_id issue
```{r}
### open twig and facts
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp")
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")

### figure out if the poly_ids are repeated
tw_poly <- tw_c %>%
  filter(poly_id %in% fa_c$poly_id)
fa_poly <- fa_c %>%
  filter(poly_id %in% tw_c$poly_id)

### there are 80,744 poly_ids duplicated across the two datasets

### try out for one state
### not an issue for AZ, CA, CO, ID, MT, NM, NV OR, UT, WA, WY (no repeated poly_ids across the datasets)
### it is an issue for the adjacent states

### open twig
tw_c_1 <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  # filter(state == "WY")
  filter(!state %in% c("AZ", "CA", "CO", "ID", 
                       "MT", "NM", "NV", "OR", "UT", 
                       "WA", "WY"))

### open facts
fa_c_1 <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  # filter(state == "WY")
  filter(!state %in% c("AZ", "CA", "CO", "ID", 
                       "MT", "NM", "NV", "OR", "UT", 
                       "WA", "WY"))

### figure out if poly_id is an issue
tw_poly_1 <- tw_c_1 %>%
  filter(poly_id_twig %in% fa_c_1$poly_id_fact)
fa_poly_1 <- fa_c_1 %>%
  filter(poly_id_fact %in% tw_c_1$poly_id_twig)

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_neva.shp")


```


### try centroid approach for colorado
```{r}
### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "CO")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "CO")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_colo.shp")
```

#### other states
```{r}
### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "AZ")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "AZ")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_ariz.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "NM")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "NM")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_nmex.shp")
```

```{r}
### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "UT")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "UT")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_utah.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "ID")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "ID")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_idah.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "WY")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "WY")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_wyom.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "NV")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "NV")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_neva.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "MT")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "MT")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_mont.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "WA")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "WA")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_wash.shp")

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "OR")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "OR")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_oreg.shp")

### clean up
rm(fa_c, tw_c, test_fa_c, test_tw_c, matched_ids_twig, test_tw,
   matched_ids_fact, tf_join, tf_matched, unique_twig, unique_facts,tw_fa)
gc()

### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state == "CA")

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state == "CA")

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_cali.shp")

rm(fa_c, tw_c, test_fa_c, test_tw_c, matched_ids_twig,
   matched_ids_fact, tf_join, tf_matched, unique_twig, unique_facts,tw_fa)
gc()

### re-do SD and OK with unique identifiers (poly_id repeated across them)
### open twig
tw_c <- st_read("E:/fuel_treat/ft_polys/twig_reshape/twig_fhf.shp") %>%
  dplyr::select(., poly_id_twig = poly_id,
         date_comp_twig = trtmnt_,
         activity_code_twig = actvty_,
         state,
         geometry) %>% 
  filter(state %in% c("OK", "SD")) %>%
  mutate(poly_id_twig = paste0(poly_id_twig, "_twig"))

### open facts
fa_c <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp") %>%
  dplyr::select(., poly_id_fact = poly_id,
                date_comp_fact = DATE_COMPL,
                activity_code_fact = ACTIVITY_C,
                state = STATE_ABBR,
                geometry) %>% 
  filter(state %in% c("OK", "SD")) %>%
  mutate(poly_id_fact = paste0(poly_id_fact, "_fact"))

### verify that poly_id isn't an issue now
tw_poly_1 <- tw_c %>%
  filter(poly_id_twig %in% fa_c$poly_id_fact)
fa_poly_1 <- fa_c %>%
  filter(poly_id_fact %in% tw_c$poly_id_twig)

### add centroids
test_tw_c <- tw_c %>%
  mutate(geometry = st_centroid(geometry))
test_fa_c <- fa_c %>%
  mutate(geometry = st_centroid(geometry))

### set threshold of 5 meters
cent_thresh <- 2.5

### spatial join
tf_join <- st_join(test_tw_c, 
                   test_fa_c, 
                   join = st_is_within_distance, 
                   dist = cent_thresh)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
test_tw <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  test_tw %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

# st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_adj.shp")
st_write(tw_fa, "E:/fuel_treat/ft_polys/harmonize_ft/centroids_adj_update.shp")

rm(fa_c, tw_c, test_fa_c, test_tw_c, tf_join, tf_matched,
   unique_twig, unique_facts,tw_fa)
gc()

### open old version
tw_fa_check <- st_read("E:/fuel_treat/ft_polys/harmonize_ft/centroids_adj.shp")

### drop source from id in new version
tw_fa <- tw_fa %>%
  mutate(poly_id = gsub("[^0-9.-]", "", poly_id))
tw_fa$poly_id <- as.numeric(tw_fa$poly_id)
tw_fa_check$poly_id <- as.numeric(tw_fa_check$poly_id)

### see if the poly_ids are the same in both data sets
setequal(tw_fa$poly_id, tw_fa_check$poly_id)

### they are the same, so can continue to use the original for the combined data
```

### combine fts
Combine the 11 states harmonized + TWIG non-FACTS Hazardous Fuels
```{r}
### open twig without FACTS haz fuels
all_twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/all_twig_split.shp") %>%
  filter(., !idntfr_ == "FACTS Hazardous Fuels") %>%
  dplyr::select(poly_id,
                date_comp = trtmnt_,
                act_code = actvty_,
                geometry,
                source = idntfr_,
                state)

### get file list for state-level harmonized
state_files <- list.files(path = "E:/fuel_treat/ft_polys/harmonize_ft",
                        pattern = ".shp$",
                        full.names = TRUE)

### open one at a time and add column for state
# state_ft_all <- lapply(state_files, st_read)
adj <- st_read(state_files[[1]]) %>%
  mutate(., state = "adj")
ariz <- st_read(state_files[[3]]) %>%
  mutate(., state = "AZ")
cali <- st_read(state_files[[4]]) %>%
  mutate(., state = "CA")
colo <- st_read(state_files[[5]]) %>%
  mutate(., state = "CO")
idah <- st_read(state_files[[6]]) %>%
  mutate(., state = "ID")
mont <- st_read(state_files[[7]]) %>%
  mutate(., state = "MT")
neva <- st_read(state_files[[8]]) %>%
  mutate(., state = "NV")
nmex <- st_read(state_files[[9]]) %>%
  mutate(., state = "NM")
oreg <- st_read(state_files[[10]]) %>%
  mutate(., state = "OR")
utah <- st_read(state_files[[11]]) %>%
  mutate(., state = "UT")
wash <- st_read(state_files[[12]]) %>%
  mutate(., state = "WA")
wyom <- st_read(state_files[[13]]) %>%
  mutate(., state = "WY")

### combine
state_ft_all <- bind_rows(adj, ariz, cali, colo, 
                          idah, mont, neva, nmex, 
                          oreg, utah, wash, wyom)

### combine with non-FACTS HFs
ft_all <- rbind(state_ft_all,
                all_twig)

### add column for pid_unique (which can be matched to other datasets based on poly_id and source)
ft_all <- ft_all %>% 
  mutate(pid_unique = paste0(poly_id, "_", source))

st_write(ft_all,
         "E:/fuel_treat/ft_polys/all_ft_harm.shp",
         append = FALSE)
st_write(ft_all,
         "E:/fuel_treat/ft_polys/all_ft_harm.gpkg",
         append = FALSE)

### clean up
rm(adj, ariz, cali, colo, idah, mont, nmex, neva,
   oreg, utah, wash, wyom, state_ft_all)

rm(all_twig)
```
#### busted code: parallelize to harmonize whole region
```{r}
### set up parallels
plan(multisession, workers = parallel::detectCores() - 1)

### set s2 off
sf::sf_use_s2(FALSE)

### split into chunks
tw_chunks <- split(test_tw_c,
                   sort(rank(1:nrow(test_tw_c)) %% future::nbrOfWorkers()))

### spatial join with filtered reference set
tf_join_chunks <- future_lapply(tw_chunks, function(chunk) {
  
  ### bounding box
  bbox <- st_bbox(chunk)
  buffer_dist <- 10  # meters
  bbox_exp <- bbox + c(-buffer_dist, -buffer_dist, 
                       buffer_dist, buffer_dist)
  
  ### subset facts by spatial intersection with buffered chunk bbox
  bbox_sfc <- st_as_sfc(st_bbox(bbox_exp, crs = st_crs(test_fa_c)))
  chunk_facts <- test_fa_c[st_intersects(test_fa_c, 
                                         bbox_sfc, sparse = FALSE), ]
  
  ### spatial join on reduced set
  st_join(chunk, 
          chunk_facts, 
          join = st_is_within_distance, 
          dist = cent_thresh)
}, future.seed = TRUE)

### combine 
tf_join <- do.call(rbind, tf_join_chunks)

### check for matches
tf_matched <- tf_join %>%
  filter(!is.na(date_comp_fact) & 
           date_comp_twig == date_comp_fact &
           activity_code_twig == activity_code_fact)

### grab unique poly_ids
matched_ids_twig <- tf_matched$poly_id_twig
matched_ids_fact <- tf_matched$poly_id_fact

### extract unique polygons
unique_twig <- tw_c %>% 
  filter(!poly_id_twig %in% matched_ids_twig)
unique_facts <- fa_c %>% 
  filter(!poly_id_fact %in% matched_ids_fact)

### fix col names
unique_twig <- unique_twig %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")
unique_facts <- unique_facts %>%
  dplyr::select(poly_id = poly_id_fact,
                date_comp = date_comp_fact,
                act_code = activity_code_fact,
                geometry) %>%
  mutate(source = "facts")
tw_c <- tw_c %>%
  dplyr::select(poly_id = poly_id_twig,
                date_comp = date_comp_twig,
                act_code = activity_code_twig,
                geometry) %>%
  mutate(source = "twig")  

### harmonize them
tw_fa <- bind_rows(
  tw_c %>% 
    filter(poly_id %in% matched_ids_twig),
  unique_twig,
  unique_facts)

st_write(tw_fa, "E:/fuel_treat/ft_polys/centroids_all_montana.shp")


# ### split into chunks
# tw_chunks <- split(test_tw_c,
#                    sort(rank(1:nrow(test_tw_c)) %% future::nbrOfWorkers()))
# 
# ### spatial join
# tf_join_chunks <- future_lapply(tw_chunks,
#                                 function(chunk) {
#                                   st_join(chunk,
#                                           test_fa_c,
#                                           join = st_is_within_distance,
#                                           dist = cent_thresh)
#                                 })

# ### set up parallels
# library(future)
# plan(multisession, workers = parallel::detectCores() - 1)
# 
# ### split into chunks
# tw_chunks <- split(test_tw_c, 
#                    sort(rank(1:nrow(test_tw_c)) %% future::nbrOfWorkers()))
# 
# ### spatial join
# tf_join_chunks <- future_lapply(tw_chunks, 
#                                 function(chunk) {
#                                   nngeo::st_join_nn(chunk, 
#                                                     test_fa_c, 
#                                                     maxdist = cent_thresh, 
#                                                     k = 1)
#                                 })
# 
# ### combine
# tf_join <- do.call(rbind, tf_join_chunks)
```


## Get burned fts for whole time series
### intersect with fts (fire post-treatment)
#### adjacent states
```{r}
### open ft_all, restrict to adj states
ft_adj <- st_read("E:/fuel_treat/ft_polys/all_ft_harm.gpkg") %>%
  filter(., state %in% c("adj", "ND", "OK", "SD", "TX"))

### Add date cols for treatments
ft_adj <- ft_adj %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### treatments completed range from 1984-2024

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         !state %in% c("WA", "OR", "CA", "AZ", "NV",
                       "UT", "ID"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., !state %in% c("WA", "OR", "CA", "AZ", "NV",
                          "UT", "ID"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(ft_adj$pid_unique))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- ft_adj[i, ]
  
  ### subset to fires that burned after
  fire_temp <- m_f_adj %>%
    filter(Ig_Date > tr_temp$date_comp)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, fire_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(ft_adj$pid_unique)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
adj_treat_burn <- ft_adj[1, ]
adj_treat_burn <- adj_treat_burn %>%
  mutate(pid_unique = "empty")

### drop geom
st_geometry(adj_treat_burn) <- NULL

### drop cols
adj_treat_burn <- adj_treat_burn %>%
  dplyr::select(poly_id, source, pid_unique)

### add cols for merge
adj_treat_burn <- adj_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = as.Date(NA),
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique, 
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    adj_treat_burn <- rbind(adj_treat_burn,
                           temp_data)
  } 
  
}

### didn't actually catch any new ones

### write out
write_csv(adj_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/adj_ft_burn.csv")

### clean up
rm(adj_treat_burn, ft_adj, fire_temp, store_intersect_all, temp_data,
   temp_intersect, tr_temp, m_f_adj)
gc()
```

#### southwestern states
```{r}
### open ft_all, restrict to adj states
ft_sw <- st_read("E:/fuel_treat/ft_polys/all_ft_harm.gpkg") %>%
  filter(., state %in% c("AZ", "NM", "CO", "UT"))

### fix date that is entered as 2105
ft_sw <- ft_sw %>% 
    mutate(date_comp = gsub("2105", "2015", date_comp))

### Add date cols for treatments
ft_sw <- ft_sw %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

range(ft_sw$date_comp)
### treatments completed range from 1984-2025

### drop treatments completed in 2025
ft_sw <- ft_sw %>%
  filter(year_comp < 2025)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("AZ", "NM", "CO", "UT", 
                      "CA", "ID", "NV", "WY", 
                      "NE", "KS", "OK", "TX"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("AZ", "NM", "CO", "UT", 
                         "CA", "ID", "NV", "WY", 
                         "NE", "KS", "OK", "TX"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

```

##### loop - don't run
```{r}
### set up to parallelize
### load libraries
# library(doParallel)
# library(foreach)

### set up cores
# plan(multisession, workers = parallel::detectCores() - 1)
# num_cores <- parallel::detectCores() - 1
# cl <- makeCluster(num_cores)
# registerDoParallel(cl)
plan(multisession, workers = 2)

### split ft_sw
ft_sw_split <- split(ft_sw, ft_sw$pid_unique)

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
  ### fires post-treatment date                              
  fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp, ]
  
  # ### spatial intersection
  # temp_intersect <- st_intersection(tr_temp, fire_temp)
  
  ### spatial join instead of st_intersection
  temp_joined <- st_join(tr_temp,
                         fire_temp,
                         join = st_intersects, 
                         left = FALSE)
  
  # ### result of intersection
  # list(temp_intersect, tr_temp$poly_id)
  
  ### result of join
  list(temp_joined, tr_temp$pid_unique)
})


### could try switching to st_join since I don't need the intersected geometries right now:
# temp_intersect <- st_join(tr_temp, fire_temp, join = st_intersects)

# ### intersect in parallel
# store_intersect_all <- foreach(i = 1:length(unique_ids), 
#                                .packages = c("sf", "dplyr")) %dopar% {
#   
#   tr_temp <- ft_sw[i, ]
#   fire_temp <- m_f_adj %>%
#     filter(Ig_Date > tr_temp$date_comp)
#   
#   temp_intersect <- st_intersection(tr_temp, fire_temp)
#   
#   list(temp_intersect, unique_ids[i])
# }
# 
# # Stop the cluster
# stopCluster(cl)

rm(ft_sw)
gc()

### loop to figure out which treatments burned after treatment
sw_treat_burn <- data.frame()

### loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  ### joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  ### skip if no matches
  if (nrow(temp_data) == 0) next
  
  ### drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  ### simplify columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  ### append
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/sw_ft_burn.csv")

### clean up
rm(adj_treat_burn, ft_adj, fire_temp, store_intersect_all, temp_data,
   temp_intersect, tr_temp, m_f_adj)
gc()
```
##### split ft_harm
```{r}
### open
ft_all <- st_read("E:/fuel_treat/ft_polys/all_ft_harm.gpkg")

### split
split_ft_all <- ft_all %>%
  group_by(state) %>%
  group_split()
### 6 = ND
### 9 = OK
### 11 = SD
### 12 = TX
### 16 = adj

### write them out
st_write(split_ft_all[[1]], 
         "E:/fuel_treat/ft_polys/ft_harm_ariz.shp",
         append = FALSE)
st_write(split_ft_all[[2]], 
         "E:/fuel_treat/ft_polys/ft_harm_cali.shp",
         append = FALSE)
st_write(split_ft_all[[3]], 
         "E:/fuel_treat/ft_polys/ft_harm_colo.shp",
         append = FALSE)
st_write(split_ft_all[[4]], 
         "E:/fuel_treat/ft_polys/ft_harm_idah.shp",
         append = FALSE)
st_write(split_ft_all[[5]], 
         "E:/fuel_treat/ft_polys/ft_harm_mont.shp",
         append = FALSE)
st_write(split_ft_all[[7]], 
         "E:/fuel_treat/ft_polys/ft_harm_newm.shp",
         append = FALSE)
st_write(split_ft_all[[8]], 
         "E:/fuel_treat/ft_polys/ft_harm_neva.shp",
         append = FALSE)
st_write(split_ft_all[[10]], 
         "E:/fuel_treat/ft_polys/ft_harm_oreg.shp",
         append = FALSE)
st_write(split_ft_all[[13]], 
         "E:/fuel_treat/ft_polys/ft_harm_utah.shp",
         append = FALSE)
st_write(split_ft_all[[14]], 
         "E:/fuel_treat/ft_polys/ft_harm_wash.shp",
         append = FALSE)
st_write(split_ft_all[[15]], 
         "E:/fuel_treat/ft_polys/ft_harm_wyom.shp",
         append = FALSE)
```

##### colorado
```{r}
### open ft_all, restrict to adj states
ft_colo <- st_read("E:/fuel_treat/ft_polys/ft_harm_colo.shp")

### Add date cols for treatments
ft_colo <- ft_colo %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### drop 2025
ft_colo <- ft_colo %>%
  filter(year_comp < 2025)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("WY", "UT", "AZ", "CO", "NM",
                      "NB", "OK", "KS"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("WY", "UT", "AZ", "CO", "NM",
                      "NB", "OK", "KS"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to utah
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "Colorado")

### intersect fires with colo
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_colo, ft_colo$pid_unique)

rm(ft_colo)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/colo_ft_burn.csv")
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/colo_ft_burn_update.csv")

rm(ft_sw_split, m_f_adj, store_intersect_all, 
   sw_treat_burn, temp_data, w_borders, i)
gc()
```
##### washington
```{r}
### open ft_all, restrict to adj states
ft_wash <- st_read("E:/fuel_treat/ft_polys/ft_harm_wash.shp")

### Add date cols for treatments
ft_wash <- ft_wash %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### drop 2025
ft_wash <- ft_wash %>%
  filter(year_comp < 2025)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("WA", "OR", "ID"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("WA", "OR", "ID"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to utah
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "Washington")

### intersect fires with colo
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_wash, ft_wash$pid_unique)

rm(ft_wash)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/wash_ft_burn.csv")
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/wash_ft_burn_update.csv")

rm(ft_sw_split, m_f_adj, store_intersect_all, 
   sw_treat_burn, temp_data, w_borders, i)
gc()
```

##### arizona
```{r}
### open ft_all, restrict to adj states
ft_ariz <- st_read("E:/fuel_treat/ft_polys/ft_harm_ariz.shp")

### Add date cols for treatments
ft_ariz <- ft_ariz %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### drop 2025
ft_ariz <- ft_ariz %>%
  filter(year_comp < 2025)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("AZ", "NM", "CO", "UT", "CA", "NV"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("AZ", "NM", "CO", "UT", "CA", "NV"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to utah
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "Arizona")

### intersect fires with colo
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_ariz, ft_ariz$pid_unique)

rm(ft_wash)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/ariz_ft_burn_update.csv")

rm(ft_sw_split, m_f_adj, store_intersect_all, 
   sw_treat_burn, temp_data, w_borders, i)
gc()
```

##### wyom
```{r}
### open ft_all, restrict to adj states
ft_wyom <- st_read("E:/fuel_treat/ft_polys/ft_harm_wyom.shp")

### Add date cols for treatments
ft_wyom <- ft_wyom %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### drop 2025
ft_wyom <- ft_wyom %>%
  filter(year_comp < 2025)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("WY", "MT", "CO", "ID", "ND", "SD", "NE", "UT"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("WY", "MT", "CO", "ID", "ND", "SD", "NE", "UT"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to utah
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "Wyoming")

### intersect fires with colo
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_wyom, ft_wyom$pid_unique)

rm(ft_wyom)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/wyom_ft_burn_update.csv")

rm(ft_sw_split, m_f_adj, store_intersect_all, 
   sw_treat_burn, temp_data, w_borders, i)
gc()
```
##### montana
```{r}
### open ft_all, restrict to adj states
ft_mont <- st_read("E:/fuel_treat/ft_polys/ft_harm_mont.shp")

### Add date cols for treatments
ft_mont <- ft_mont %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### drop 2025
ft_mont <- ft_mont %>%
  filter(year_comp < 2025)

table(ft_mont$source)

# ### Round 1: twig, facts, NFPORS
# ft_mont <- ft_mont %>%
#   filter(!source == "FACTS Common Attributes")

# ### round 2: FCA, through 1990
# ft_mont <- ft_mont %>%
#   filter(source == "FACTS Common Attributes") %>%
#   filter(year_comp < 1991)

### round 3: FCA, 1991-1999
ft_mont <- ft_mont %>%
  filter(source == "FACTS Common Attributes") %>%
  filter(year_comp > 1990) %>%
  filter(year_comp < 2000)

# ft_mont <- ft_mont %>%
#   filter(!source == "FACTS Common Attributes")

# ### round 2: FACTS common attributes
# ft_mont <- ft_mont %>%
#   filter(source == "FACTS Common Attributes")

# ### round 2.1: before 1995
# ft_mont <- ft_mont %>%
#   filter(year_comp < 1995)

# ### round 2.2: after 1994 but before 2010
# ft_mont <- ft_mont %>%
#   filter(year_comp > 1994) %>%
#   filter(year_comp < 2010)

# ### round 2.3: after 2009
# ft_mont <- ft_mont %>%
#   filter(year_comp > 2009)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("MT", "ND", "SD", "WY", "ID"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("MT", "ND", "SD", "WY", "ID"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset to fires after treatments
# m_f_adj <- m_f_adj %>%
#   filter(year > 1994)
# m_f_adj <- m_f_adj %>%
#   filter(year > 2009)
m_f_adj <- m_f_adj %>%
  filter(year > 1990)

### subset fires to utah
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "Montana")

### intersect fires with utah
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_mont, ft_mont$pid_unique)

rm(ft_mont)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/mont_fca_1991_1999_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_fca_1990_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_ftn_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_fca_10_24_ft_burn.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_fca_95_09_ft_burn.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_fca_95_ft_burn.csv")
```

##### california
```{r}
### open ft_all, restrict to adj states
ft_cali <- st_read("E:/fuel_treat/ft_polys/ft_harm_cali.shp")

### Add date cols for treatments
ft_cali <- ft_cali %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp)) 

### drop 2025
ft_cali <- ft_cali %>%
  filter(year_comp < 2025)

# table(ft_cali$source)
### facts: 3151
### FACTS Common Attributes: 82157
### NFPORS: 12461 
### twig: 96265 

# ### Round 1: facts and NFPORS
# ft_cali <- ft_cali %>%
#   filter(source %in% c("facts", "NFPORS"))

### Round 2: twig
# ft_cali <- ft_cali %>%
#   filter(source == "twig")

### Round 3: FCA
ft_cali <- ft_cali %>%
  filter(source == "FACTS Common Attributes")

### round 3.1: FCA through 1995
ft_cali <- ft_cali %>%
  filter(year_comp < 1996)

# ### Round 2.1: twig before 2014
# ft_cali <- ft_cali %>%
#   filter(year_comp < 2015)

# ### Round 2.2: twig after 2014 but before 2021 (2015-2020)
# ft_cali <- ft_cali %>%
#   filter(year_comp > 2014) %>%
#   filter(year_comp < 2021)

# ### Round 2.3: twig after 2020
# ft_cali <- ft_cali %>%
#   filter(year_comp > 2020)

# ### Round 2.3: twig 2020
# ft_cali <- ft_cali %>%
#   filter(year_comp > 2020)

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("CA", "AZ", "NV", "OR"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("CA", "AZ", "NV", "OR"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to cali
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "California")

### intersect fires with cali
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

# ### round 2.2 fires
# m_f_adj <- m_f_adj %>%
#   filter(year > 2014)

# ### round 2.3 fires
# m_f_adj <- m_f_adj %>%
#   filter(year > 2020)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_cali, ft_cali$pid_unique)

rm(ft_cali)
gc()

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### write out
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/cali_tw_21_24_ft_burn.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/cali_tw15_20_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/cali_tw_21_24_ft_burn_update.csv")
write_csv(sw_treat_burn,
          "E:/fuel_treat/ft_polys/burned_ft/cali_fca_1995_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/cali_tw_14_ft_burn.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/cali_fn_ft_burn_update.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_fca_95_ft_burn.csv")
# write_csv(sw_treat_burn,
#           "E:/fuel_treat/ft_polys/burned_ft/mont_ftn_ft_burn.csv")

rm(ft_sw_split, m_f_adj, store_intersect_all, 
   sw_treat_burn, temp_data, w_borders, i)
gc()
```

#### combine treatments
```{r}
### open southern states
ariz <- read.csv("E:/fuel_treat/ft_polys/burned_ft/ariz_ft_burn.csv")
colo <- read.csv("E:/fuel_treat/ft_polys/burned_ft/colo_ft_burn.csv")
utah <- read.csv("E:/fuel_treat/ft_polys/burned_ft/utah_ft_burn.csv")
nmex <- read.csv("E:/fuel_treat/ft_polys/burned_ft/newm_ft_burn.csv")

### combine sw
sw_ft <- rbind(ariz, colo, utah, nmex)
write_csv(sw_ft, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/sw_ft_burn_update.csv")
rm(ariz, colo, utah, nmex)
gc()

### open pacific states
cali_1 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_fca_96_24_ft_burn_update.csv")
cali_2 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_fca_1995_ft_burn_update.csv")
cali_3 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_fn_ft_burn_update.csv")
cali_4 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_twig_2014_ft_burn_update.csv")
cali_5 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_tw15_20_ft_burn_update.csv")
cali_6 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/cali_tw_21_24_ft_burn_update.csv")

oreg_1 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_fca_91_05_ft_burn_update.csv")
oreg_2 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_fca_2006_24_ft_burn_update.csv")
oreg_3 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_fca_1990_ft_burn_update.csv")
oreg_4 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_facts_nfpors_ft_burn_update.csv")
oreg_5 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_twig_16_24_ft_burn_update.csv")
oreg_6 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/oreg_twig_2015_ft_burn_update.csv")

wash <- read.csv("E:/fuel_treat/ft_polys/burned_ft/wash_ft_burn.csv")

### combine pacific
pc_ft <- rbind(cali_1, cali_2, cali_3, cali_4, cali_5, cali_6,
               oreg_1, oreg_2, oreg_3, oreg_4, oreg_5, oreg_6, wash)
write_csv(pc_ft, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/pc_ft_burn.csv")
rm(cali_1, cali_2, cali_3, cali_4, cali_5, cali_6,
   oreg_1, oreg_2, oreg_3, oreg_4, oreg_5, wash)
gc()

### open northern states
wyom <- read.csv("E:/fuel_treat/ft_polys/burned_ft/wyom_ft_burn.csv")

idah_1 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/idah_fca_97_24_ft_burn.csv")
idah_2 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/idah_fca24_ft_burn.csv")
idah_3 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/idah_fca95_ft_burn.csv")
idah_4 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/idah_nfpors_ft_burn.csv")
idah_5 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/idah_twig_ft_burn.csv")

mont_1 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/mont_fca_10_24_ft_burn.csv")
mont_2 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/mont_fca_95_09_ft_burn.csv")
mont_3 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/mont_fca_95_ft_burn.csv")
mont_4 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/mont_ftn_ft_burn.csv")

neva <- read.csv("E:/fuel_treat/ft_polys/burned_ft/neva_ft_burn.csv")
adj <- read.csv("E:/fuel_treat/ft_polys/burned_ft/adj_ft_burn.csv")

### combine northern
no_ft <- rbind(wyom, neva, adj,
               idah_1, idah_2, idah_3, idah_4, idah_5,
               mont_1, mont_2, mont_3, mont_4)
write_csv(no_ft, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/nr_ft_burn.csv")
rm(wyom, neva, adj,
   idah_1, idah_2, idah_3, idah_4, idah_5,
   mont_1, mont_2, mont_3, mont_4)
gc()

### combine all
all_ft <- rbind(sw_ft, pc_ft, no_ft)
write_csv(all_ft, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn.csv")
```
##### combine treatments updated
```{r}
### get all files names that end w "update"
update_files <- list.files(path = "E:/fuel_treat/ft_polys/burned_ft",
                           pattern = "_update\\.csv$",
                           full.names = TRUE)

### function to read subset
read_csv_subset <- function(files, indices) {
  selected <- files[indices]
  data_list <- lapply(selected, read.csv)
  names(data_list) <- basename(selected)
  return(data_list)
}

### sw subset
sw_subset <- read_csv_subset(update_files, c(1, 2, 9, 19, 26))
sw_subset <- do.call(rbind, sw_subset)
write_csv(sw_subset, 
          "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/sw_ft_burn_update.csv")

### northern subset
no_subset <- read_csv_subset(update_files, c(10:18, 28))
no_subset <- do.call(rbind, no_subset)
write_csv(no_subset, 
          "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/nr_ft_burn_update.csv")

### pacific subset
pa_subset <- read_csv_subset(update_files, c(3:8, 20:25, 27))
pa_subset <- do.call(rbind, pa_subset)
write_csv(pa_subset, 
          "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/pc_ft_burn_update.csv")

### combine all
all_ft <- rbind(sw_subset, no_subset, pa_subset)
write_csv(all_ft, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv")
```

##### compare with previous output
```{r}
### open previous output
test <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn.csv")
missing_new <- test %>% filter(!poly_id %in% all_ft$poly_id)
missing_old <- all_ft %>% filter(!poly_id %in% test$poly_id)

### there are 27 poly_ids from the old all_ft that are missing from the new all_ft 
#### all are new mexico FCA that burned in the fire NM3340010860119951021 or NM3369410861319950727
#### poly_ids: "413572", "415766", "416695", "416704", "420254", "420460", "420719", "420753", "421026", "421069", "421077", "421160", "421164", "421170", "421413", "421421", "421435", "421557", "421617", "421697", "421700", "421903", "422101", "422139", "422267", "422298", "422317"

### and 8 poly_ids from new all_ft that are not present in old all_ft

### take a look at the new mexico polys missing:
ft_nmex <- st_read("E:/fuel_treat/ft_polys/ft_harm_newm.shp") %>%
  filter(., poly_id %in% missing_new$poly_id)

### Add date cols for treatments
ft_nmex <- ft_nmex %>%
  mutate(day_comp = day(date_comp),
         month_comp = month(date_comp),
         year_comp = year(date_comp))

### open MTBS
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  
  ### add states
  mutate(.,
         state = stringr::str_extract(Event_ID, "^.{2}")) %>%
  
  ### filter to states that could overlap with adj fts
  filter(., 
         state %in% c("AZ", "NM", "CO", "UT", "TX", "OK"))

### open firedpy
firedpy <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  
  ### filter to states that could overlap with adj fts
  filter(., state %in% c("AZ", "NM", "CO", "UT", "TX", "OK"))

### align column order
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, 
                date, month, year, state, geometry)

### rbind mtbs and firedpy
m_f_adj <- rbind(mtbs, firedpy)

### clean up
rm(mtbs, firedpy)
gc()

### subset fires to new mexico
w_borders <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/west_states.shp") %>%
  filter(., NAME_1 == "New Mexico")

### intersect fires with colo
m_f_adj <- st_intersection(m_f_adj,
                           w_borders)
m_f_adj <- m_f_adj %>%
  dplyr::select(-NAME_1)

plan(multisession, workers = 5)

### split ft_sw
ft_sw_split <- split(ft_nmex, ft_nmex$pid_unique)

### intersect in parallel
store_intersect_all <- future_map(ft_sw_split, 
                                  function(tr_temp) {
                                    
                                    ### fires post-treatment date                             
                                    fire_temp <- m_f_adj[m_f_adj$Ig_Date > tr_temp$date_comp,
                                    ]
                                    
                                    # ### spatial intersection
                                    # temp_intersect <- st_intersection(tr_temp, fire_temp)
                                    
                                    ### spatial join instead of st_intersection
                                    temp_joined <- st_join(tr_temp,
                                                           fire_temp,
                                                           join = st_intersects, 
                                                           left = FALSE)
                                    
                                    # ### result of intersection
                                    # list(temp_intersect, tr_temp$poly_id)
                                    
                                    ### result of join
                                    list(temp_joined, tr_temp$pid_unique)
                                  },
                                  .options = furrr_options(seed = TRUE)
)

# Start with an empty data frame
sw_treat_burn <- data.frame()

# Loop through the joined results
for (i in seq_along(store_intersect_all)) {
  
  print(paste0("STEP ", i))
  
  # Get the joined sf object (fires joined to treatment i)
  temp_data <- store_intersect_all[[i]][[1]]
  
  # Skip if there were no matches
  if (nrow(temp_data) == 0) next
  
  # Drop geometry
  temp_data <- st_drop_geometry(temp_data)
  
  # Keep only desired columns
  temp_data <- temp_data %>%
    dplyr::select(poly_id, source, pid_unique,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  # Append to result
  sw_treat_burn <- bind_rows(sw_treat_burn, temp_data)
}

### open sw ft
sw_ft <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/sw_ft_burn_update.csv")

### add these updated intersections
all_sw <- rbind(sw_ft, sw_treat_burn)

### write out
write_csv(all_sw, "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/sw_ft_burn_update.csv")

### add these new ones to all_ft
all_ft_update <- rbind(all_ft, sw_treat_burn)

### write out
write_csv(all_ft_update,
          "E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv")
```
## Burned treatment footprints
```{r}
## open all burned fts
all_ft <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv")

### open polygons (n = 1028132)
ft_poly <- st_read("E:/fuel_treat/ft_polys/all_ft_harm.gpkg")

# ### make joint ID columns for filtering
# all_ft <- all_ft %>%
#   mutate(pid = paste0(poly_id, "_", source))
# ft_poly <- ft_poly %>%
#   mutate(pid = paste0(poly_id, "_", source))

### filter to just include ft polygons that subsequently burned
ft_poly <- ft_poly %>%
  filter(pid_unique %in% all_ft$pid_unique) # (n = 165524)

### write out
st_write(ft_poly,
        "E:/fuel_treat/ft_polys/burned_ft/burned_fts_update.shp")

table(ft_poly$state)

#    AZ    CA    CO    ID    MT    NM    NV    OR    SD    UT    WA    WY 
# 13844 60745  5373 10893 23596  3188   502 33337    33   883  8329  4808 

### table of activity counts by state
ft_burned_csv <- ft_poly 
st_geometry(ft_burned_csv) <- NULL
ft_burned_summ <- ft_burned_csv %>%
  group_by(state,
           act_code) %>%
  summarise(treatment_count = length(unique(pid_unique)))
write_csv(ft_burned_csv,
          "E:/fuel_treat/ft_burned_summary.csv")
```

### Fires that burned fts
```{r}
## open all burned fts
all_ft <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv")

### open mtbs and firedpy (raw versions to avoid splits across state boundaries)
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_perims_DD.shp")
fired <- st_read("E:/fuel_treat/firedpy/fired_conus_ak_2000_to_2024_events.shp")

### subset to fires that actually burned through treatments
mtbs <- mtbs %>%
  filter(Event_ID %in% all_ft$Event_ID) %>%
  dplyr::select(Event_ID, geometry)
fired <- fired %>%
  filter(id %in% all_ft$Event_ID) %>%
  dplyr::select(Event_ID = id, geometry)

### open versions with info I want, drop geometry
mtbs_use <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp")
st_geometry(mtbs_use) <- NULL
fired_use <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp")
st_geometry(fired_use) <- NULL

### subset to fires that burned through treatments
mtbs_use <- mtbs_use %>%
  filter(Event_ID %in% all_ft$Event_ID)
fired_use <- fired_use %>%
  filter(Event_ID %in% all_ft$Event_ID)

### remove duplicates
mtbs_use <- distinct(mtbs_use)
fired_use <- distinct(fired_use)

### simplify states in fired_use (based on actual distribution across state lines -- assign to state it's majority in)
fired_use <- fired_use %>%
  mutate(state = ifelse(Event_ID %in% c("701", "702"), "CA",
                        ifelse(Event_ID == "14510", "AZ",
                               ifelse(Event_ID == "14543", "NM",
                                      ifelse(Event_ID == "145855", "CO",
                                             ifelse(Event_ID == "171512", "ID",
                                                    ifelse(Event_ID %in% c("130181",
                                                                           "171513"), 
                                                           "MT",
                                                           state)))))))
fired_use <- distinct(fired_use)

### combine with updated geometries
mtbs <- merge(x = mtbs,
              y = mtbs_use,
              by = "Event_ID")
fired <- merge(x = fired,
               y = fired_use,
               by = "Event_ID")

### align crs
mtbs <- mtbs %>%
  st_transform(crs = 6350)
fired <- fired %>%
  st_transform(crs = 6350)

### combine
fired <- fired %>%
  dplyr::select(-state)
all_fires <- rbind(mtbs, fired)

### make sure the fts are all correct
all_fires <- all_fires %>% 
  filter(Event_ID %in% all_ft$Event_ID)

### write out
st_write(mtbs, "E:/fuel_treat/mtbs_ft.shp",
         append = FALSE)
st_write(fired, "E:/fuel_treat/firedpy_ft.shp",
         append = FALSE)
# st_write(fired, "E:/fuel_treat/mtbs_firedpy_ft.shp",
#          append = FALSE)
```

#### fires for CBI
```{r}
### open fires that burned fuel treats
mtbs <- st_read("E:/fuel_treat/mtbs_ft.shp")
fired <- st_read("E:/fuel_treat/firedpy_ft.shp")

### figure out which mtbs IDs i still need to do
### get mtbs file names
mtbs_files <- list.files(path = "E:/fuel_treat/mtbs/cbi_gee_mtbs/",
                         pattern = ".tif$",
                         full.names = FALSE)

### restrict to mtbs IDs
mtbs_files <- sub("_.*", "", mtbs_files)
mtbs_files <- unique(mtbs_files)

### subset to mtbs fires without CBI yet
mtbs_need <- mtbs %>%
  filter(!Event_ID %in% mtbs_files)

### which fires that already have GEE are not in the new dataset?
mtbs_missing <- mtbs_files[!mtbs_files %in% mtbs$Event_ID]

### clean up
rm(mtbs, mtbs_all, mtbs_files, mtbs_missing)
gc()

### figure out which firedpy IDs i still need to do
### get firedpy file names
fired_files <- list.files(path = "E:/fuel_treat/firedpy/cbi_gee_firedpy/",
                         pattern = ".tif$",
                         full.names = FALSE)

### restrict to firedpy IDs
fired_files <- sub("_.*", "", fired_files)
fired_files <- unique(fired_files)

### subset to firedpy fires without CBI yet
fired_need <- fired %>%
  filter(!Event_ID %in% fired_files)

### which fires that already have GEE are not in the new dataset?
fired_missing <- fired_files[!fired_files %in% fired$Event_ID]

### clean up
rm(fired, fired_files, fired_missing)
gc()
```

##### prep mtbs for GEE
```{r}
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)

### extract state as column
mtbs_need <- mtbs_need %>%
  mutate(state = stringr::str_extract(Event_ID, "^.{2}"))

### Fire seasons
#### In Parks et al. 2019, they use the following seasons:
#### AZ and NM: April 1-June 30 (julian 91-181)
#### CA, ID, MT, OR, UT, WA, WY: June 1-Sept 15 (julian 152-258)
#### assume it's the same for CO, NV
#### use these
# other_julian <- c("CA", "CO", "ID",
#                   "MT", "NV", "OR",
#                   "SD", "TX",
#                   "UT", "WA", "WY")

### use julian fire season dates for CA, ID, MT, OR, UT, WA, WY

### assign julian start and end date based on state dates from Parks et al. 2019
mtbs_need <- mtbs_need %>%
  mutate(Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258))

### Select columns for GEE
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)
mtbs_need <- mtbs_need %>%
  dplyr::select(Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day,
                End_Day,
                Incid_Type,
                geometry)

### Make sure date columns don't get read in with decimals
mtbs_need$Fire_Year <- as.character(mtbs_need$Fire_Year, 0)
mtbs_need$Start_Day <- as.character(mtbs_need$Start_Day, 0)
mtbs_need$End_Day <- as.character(mtbs_need$End_Day, 0)

### Write out shp for gee
st_write(mtbs_need,
         "E:/fuel_treat/mtbs/mtbs_gee.shp",
         append = FALSE)
```

##### prep firedpy for GEE
```{r}
### open shp to get states
fired <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp") %>%
  filter(., Event_ID %in% fired_need$Event_ID) %>%
  dplyr::select(., Event_ID,
                state)
st_geometry(fired) <- NULL

### simplify states in fired_use (based on actual distribution across state lines -- assign to state it's majority in)
fired <- fired %>%
  mutate(state = ifelse(Event_ID %in% c("701", "702"), "CA",
                        ifelse(Event_ID == "14510", "AZ",
                               ifelse(Event_ID == "14543", "NM",
                                      ifelse(Event_ID == "145855", "CO",
                                             ifelse(Event_ID == "171512", "ID",
                                                    ifelse(Event_ID %in% c("130181",
                                                                           "171513"), 
                                                           "MT",
                                                           state)))))))
fired <- distinct(fired)

### combine with fired_need
fired_need <- merge(x = fired_need,
                    y = fired,
                    by = "Event_ID")

### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)

### Fire seasons
#### In Parks et al. 2019, they use the following seasons:
#### AZ and NM: April 1-June 30 (julian 91-181)
#### CA, ID, MT, OR, UT, WA, WY: June 1-Sept 15 (julian 152-258)
#### assume it's the same for CO, NV
#### use these
# other_julian <- c("CA", "CO", "ID",
#                   "MT", "NV", "OR",
#                   "SD", "TX",
#                   "UT", "WA", "WY")

### use julian fire season dates for CA, ID, MT, OR, UT, WA, WY

### assign julian start and end date based on state dates from Parks et al. 2019
fired_need <- fired_need %>%
  mutate(Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258))

### Select columns for GEE
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)
fired_need <- fired_need %>%
  dplyr::select(Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day,
                End_Day,
                Incid_Type,
                geometry)

### Make sure date columns don't get read in with decimals
fired_need$Fire_Year <- as.character(fired_need$Fire_Year, 0)
fired_need$Start_Day <- as.character(fired_need$Start_Day, 0)
fired_need$End_Day <- as.character(fired_need$End_Day, 0)

### Write out shp for gee
st_write(fired_need,
         "E:/fuel_treat/firedpy/firedpy_gee.shp",
         append = FALSE)

### subset to 3 to check updated CBI code
fired_check <- fired_need %>%
  filter(Fire_ID %in% c("169259", "170012", "170101"))

### write out
st_write(fired_check,
         "E:/fuel_treat/firedpy/firedpy_gee_test.shp",
         append = FALSE)
```

###### cbi test
```{r}
library(terra)

########################
### 170101
########################

### open files
orig <- rast("C:/Users/kjsie/Downloads/170101_CBI_bc.tif")
test <- rast("C:/Users/kjsie/Downloads/170101_CBI_bc_test.tif")

### calculate difference
cbi_diff <- orig - test
minmax(cbi_diff)

### the layers are the same

########################
### 170012
########################

### open files
orig <- rast("C:/Users/kjsie/Downloads/170012_CBI_bc.tif")
test <- rast("C:/Users/kjsie/Downloads/170012_CBI_bc_test.tif")

### calculate difference
cbi_diff <- orig - test
minmax(cbi_diff)

### the layers are the same

########################
### 169259
########################

### open files
orig <- rast("C:/Users/kjsie/Downloads/169259_CBI_bc.tif")
test <- rast("C:/Users/kjsie/Downloads/169259_CBI_bc_test.tif")

### calculate difference
cbi_diff <- orig - test
minmax(cbi_diff)

### the layers are the same
```

#### make sure all firedpy fires ran in GEE - don't output yet because GEE still running (7/23)
```{r} 
### open firedpy polygons
fired_need <- st_read("E:/fuel_treat/firedpy/firedpy_gee.shp")

### folder url
folder_firedpy_url <- "https://drive.google.com/drive/u/0/folders/1T_aweemZT3NShOaradGqKoA5ts5_zytn"

### identify the folder
folder_firedpy <- drive_get(as_id(folder_firedpy_url))

### identify the rasters in that folder
drive_firedpy <- drive_ls(folder_firedpy)

### figure out which fires ran

### make df
firedpy_ran <- as.data.frame(drive_firedpy[, c(1:2)])

### split fire name strings
firedpy_ran$name <- gsub('_CBI_bc.tif', '', firedpy_ran$name)

### which fires are missing?
firedpy_missing <- fired_need %>%
  filter(!Fire_ID %in% firedpy_ran$name)

# ### split for gee
# num_groups <- 4
# 
# ### split
# firedpy_missing <- firedpy_missing %>% 
#    group_by((row_number()-1) %/% (n()/num_groups)) %>%
#    nest %>% pull(data)
# 
# check <- firedpy_missing[[1]]
# 
# ### write these out for GEE
# st_write(firedpy_missing[[1]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_1.shp")
# st_write(firedpy_missing[[2]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_2.shp")
# st_write(firedpy_missing[[3]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_3.shp")
# st_write(firedpy_missing[[4]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_4.shp")

### split for gee
num_groups <- 3

### split
firedpy_missing <- firedpy_missing %>% 
   group_by((row_number()-1) %/% (n()/num_groups)) %>%
   nest %>% pull(data)

check <- firedpy_missing[[1]]

### write these out for GEE
st_write(firedpy_missing[[1]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_5.shp")
st_write(firedpy_missing[[2]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_6.shp")
st_write(firedpy_missing[[3]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_7.shp")
```

#### make sure all mtbs fires ran in GEE - don't output yet because GEE still running (7/23)
```{r}
### open mtbs polygons
mtbs_need <- st_read("E:/fuel_treat/mtbs/mtbs_gee.shp")

### folder url
folder_mtbs_url <- "https://drive.google.com/drive/u/2/folders/1lmUd7_JezuRS4-Vqm3JGMnOQv0QjnMmO"

### identify the folder
folder_mtbs <- drive_get(as_id(folder_mtbs_url))

### identify the rasters in that folder
drive_mtbs <- drive_ls(folder_mtbs)

### figure out which fires ran

### make df
mtbs_ran <- as.data.frame(drive_mtbs[, c(1:2)])

### split fire name strings
mtbs_ran$name <- gsub('_CBI_bc.tif', '', mtbs_ran$name)

mtbs_missing <- mtbs_need %>%
  filter(!Fire_ID %in% mtbs_ran$name)

# ### split for gee
# num_groups <- 4
# 
# ### split
# firedpy_missing <- firedpy_missing %>% 
#    group_by((row_number()-1) %/% (n()/num_groups)) %>%
#    nest %>% pull(data)
# 
# check <- firedpy_missing[[1]]
# 
# ### write these out for GEE
# st_write(firedpy_missing[[1]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_1.shp")
# st_write(firedpy_missing[[2]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_2.shp")
# st_write(firedpy_missing[[3]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_3.shp")
# st_write(firedpy_missing[[4]],
#          "E:/fuel_treat/firedpy/firedpy_gee_still_4.shp")

### split for gee
num_groups <- 3

### split
firedpy_missing <- firedpy_missing %>% 
   group_by((row_number()-1) %/% (n()/num_groups)) %>%
   nest %>% pull(data)

check <- firedpy_missing[[1]]

### write these out for GEE
st_write(firedpy_missing[[1]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_5.shp")
st_write(firedpy_missing[[2]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_6.shp")
st_write(firedpy_missing[[3]],
         "E:/fuel_treat/firedpy/firedpy_gee_still_7.shp")
```
still_1 ran in GEE
still_2 ran part way
haven't run still_3 or still_4 yet

## Old code had this, not sure if I still need it
### Treatments that might have been missed in loops
```{r}
### burned treatments
ft_burned <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats.shp")

### all fuel treatment footprints (minus wildfire ones)
all_fts <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/all_treatments_non_wf.shp")

### filter out treatments that I know burned
all_fts_unb <- all_fts %>%
  filter(!ft_id %in% ft_burned$ft_id)

# st_write(all_fts_unb,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/fts_to_check.shp")

### remove intermediates
rm(all_fts, ft_burned)

### do some of the fuel treatments overlap with MTBS (regardless of temporal sequence?)

### open mtbs
mtbs <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_1984_2022_fuel_treats.shp")

### subset to ft's within MTBS borders
fts_mtbs <- st_intersection(all_fts_unb,
                            mtbs)

length(unique(all_fts_unb$ft_id)) ## 188215
length(unique(fts_mtbs$ft_id))    ## 16061

### get full polygons for footprints that overlap
fts_mtbs_comp <- all_fts_unb %>%
  filter(ft_id %in% fts_mtbs$ft_id)

rm(all_fts_unb, fts_mtbs)

### table
table(fts_mtbs_comp$PURPOSE_CO)

# FIRE  FTF  FTI  FTM FUEL   RF TMBR  TSI WILD 
# 1057 1604 8066 2544    2    1    8    6    6 

### Add date cols for treatments
fts_mtbs_comp <- fts_mtbs_comp %>%
  mutate(date_comp = day(DATE_COMPL),
         month_comp = month(DATE_COMPL),
         year_comp = year(DATE_COMPL))
```
#### loop through for subsequent fires
##### FTM 
```{r}
### subset
ftm <- fts_mtbs_comp %>%
  filter(PURPOSE_CO == "FTM")

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(ftm$ft_id))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- ftm[i, ]
  
  ### subset to fires that burned after
  mtbs_n_temp <- mtbs %>%
    filter(Ig_Date > tr_temp$DATE_COMPL)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, mtbs_n_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(ftm$ft_id)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
other_treat_burn <- ftm[1, ]
other_treat_burn <- other_treat_burn %>%
  mutate(ft_id = "empty")

### drop geom
st_geometry(other_treat_burn) <- NULL

### drop cols
other_treat_burn <- other_treat_burn %>%
  dplyr::select(ft_id)

### add cols for merge
other_treat_burn <- other_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = NA,
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(ft_id,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    other_treat_burn <- rbind(other_treat_burn,
                               temp_data)
  } 
  
}

### drop the empty row
other_treat_burn <- other_treat_burn %>%
  filter(!ft_id == "empty")

### 0 treatments burned

# write_csv(other_treat_burn,
#           "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/second_loop_1.csv")
```

##### FTF
```{r}
### subset
ftf <- fts_mtbs_comp %>%
  filter(PURPOSE_CO == "FTF")

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(ftf$ft_id))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- ftf[i, ]
  
  ### subset to fires that burned after
  mtbs_n_temp <- mtbs %>%
    filter(Ig_Date > tr_temp$DATE_COMPL)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, mtbs_n_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(ftf$ft_id)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
other_treat_burn <- ftf[1, ]
other_treat_burn <- other_treat_burn %>%
  mutate(ft_id = "empty")

### drop geom
st_geometry(other_treat_burn) <- NULL

### drop cols
other_treat_burn <- other_treat_burn %>%
  dplyr::select(ft_id)

### add cols for merge
other_treat_burn <- other_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = NA,
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(ft_id,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    other_treat_burn <- rbind(other_treat_burn,
                               temp_data)
  } 
  
}

### drop the empty row
other_treat_burn <- other_treat_burn %>%
  filter(!ft_id == "empty")

### 0 fuel treatments burned

# write_csv(other_treat_burn,
#           "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/second_loop_2.csv")
```

##### not NA, FTF, FTI, or FTM
```{r}
### subset
ft_other <- fts_mtbs_comp %>%
  filter(!PURPOSE_CO %in% c("FTF", "FTM", "FTI")) %>%
  filter(!is.na(PURPOSE_CO))

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(ft_other$ft_id))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- ft_other[i, ]
  
  ### subset to fires that burned after
  mtbs_n_temp <- mtbs %>%
    filter(Ig_Date > tr_temp$DATE_COMPL)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, mtbs_n_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(ft_other$ft_id)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
other_treat_burn <- ft_other[1, ]
other_treat_burn <- other_treat_burn %>%
  mutate(ft_id = "empty")

### drop geom
st_geometry(other_treat_burn) <- NULL

### drop cols
other_treat_burn <- other_treat_burn %>%
  dplyr::select(ft_id)

### add cols for merge
other_treat_burn <- other_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = NA,
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(ft_id,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    other_treat_burn <- rbind(other_treat_burn,
                               temp_data)
  } 
  
}

### drop the empty row
other_treat_burn <- other_treat_burn %>%
  filter(!ft_id == "empty")

### 12 fuel treatments burned

write_csv(other_treat_burn,
          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/second_loop_1.csv")
```

##### FTI
```{r}
### subset
fti <- fts_mtbs_comp %>%
  filter(PURPOSE_CO == "FTI") 

### fti overlap with mtbs
fti_mtbs <- st_intersection(mtbs, fti)

### restrict mtbs to these
mtbs_fti <- mtbs %>%
  filter(Event_ID %in% fti_mtbs$Event_ID)
rm(fti_mtbs)

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(fti$ft_id))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- fti[i, ]
  
  ### subset to fires that burned after
  mtbs_n_temp <- mtbs_fti %>%
    filter(Ig_Date > tr_temp$DATE_COMPL)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, mtbs_n_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(fti$ft_id)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
other_treat_burn <- fti[1, ]
other_treat_burn <- other_treat_burn %>%
  mutate(ft_id = "empty")

### drop geom
st_geometry(other_treat_burn) <- NULL

### drop cols
other_treat_burn <- other_treat_burn %>%
  dplyr::select(ft_id)

### add cols for merge
other_treat_burn <- other_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = NA,
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(ft_id,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    other_treat_burn <- rbind(other_treat_burn,
                               temp_data)
  } 
  
}

### drop the empty row
other_treat_burn <- other_treat_burn %>%
  filter(!ft_id == "empty")

### 463 fuel treatments burned

write_csv(other_treat_burn,
          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/second_loop_2.csv")

```

##### purpose code = NA
```{r}
### subset
pc_na <- fts_mtbs_comp %>%
  filter(is.na(PURPOSE_CO)) 

### pc_na overlap with mtbs
pc_na_mtbs <- st_intersection(mtbs, pc_na)

### restrict mtbs to these
mtbs_na <- mtbs %>%
  filter(Event_ID %in% pc_na_mtbs$Event_ID)
rm(pc_na_mtbs)

### Loop to figure out which treatments burned after treatment
store_intersect_all <- list()

for (i in 1:length(unique(pc_na$ft_id))) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- pc_na[i, ]
  
  ### subset to fires that burned after
  mtbs_n_temp <- mtbs_na %>%
    filter(Ig_Date > tr_temp$DATE_COMPL)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, mtbs_n_temp)
  
  ### store intersections as a list
  store_intersect_all[[i]] <- list(temp_intersect, unique(pc_na$ft_id)[i])
  
}

### Now need code to see how many treatments actually burned
### See how many treatments burned
other_treat_burn <- pc_na[1, ]
other_treat_burn <- other_treat_burn %>%
  mutate(ft_id = "empty")

### drop geom
st_geometry(other_treat_burn) <- NULL

### drop cols
other_treat_burn <- other_treat_burn %>%
  dplyr::select(ft_id)

### add cols for merge
other_treat_burn <- other_treat_burn %>%
  mutate(Event_ID = NA, 
         Incid_Type = NA, 
         Ig_Date = NA,
         date = NA, month = NA, year = NA)

for (i in 1:length(store_intersect_all)) {
# for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  temp_data <- as.data.frame(store_intersect_all[[i]][[1]])
  
  ### drop geom
  temp_data$geometry <- NULL
  
  ### Subset columns
  temp_data <- temp_data %>%
    dplyr::select(ft_id,
                  Event_ID, Incid_Type, 
                  Ig_Date,
                  date, month, year)
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    other_treat_burn <- rbind(other_treat_burn,
                               temp_data)
  } 
  
}

### drop the empty row
other_treat_burn <- other_treat_burn %>%
  filter(!ft_id == "empty")

write_csv(other_treat_burn,
          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/second_loop_3.csv")
```

#### combine second round of loops
```{r}
### list files
loop_files <- list.files(path = "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/",
                        pattern = "^second_loop_",
                        full.names = TRUE)

### open them
loop_files <- lapply(loop_files, read.csv)

### combine
loop_files <- do.call("rbind", loop_files)

### write out
write_csv(loop_files,
          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/remaining_burned_fts.csv")

### open original with full dataset
all_fts <- read.csv("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fts_w_us.csv")

### combine
all_fts <- rbind(all_fts,
                 loop_files)

### write out
write_csv(all_fts,
          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fts_w_us_updated.csv")
```


## Burned footprints subset to fire perimeter
Pick the code back up here

### get burned fts
```{r, warning = FALSE}
### Open csv of all burned footprints
all_ft <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv") %>%
  distinct(.)

### Open fuel treatment database, subset to burned fts
ft_footprint <- st_read("E:/fuel_treat/ft_polys/all_ft_harm.gpkg") %>%
  filter(., pid_unique %in% all_ft$pid_unique)

### make valid
ft_footprint <- st_make_valid(ft_footprint)

### drop duplicates
ft_footprint <- distinct(ft_footprint)

### get poly_id and event_id from all_ft (165531)
all_ft <- all_ft %>%
  dplyr::select(pid_unique, poly_id, Event_ID)

### merge fts
ft_footprint <- merge(x = ft_footprint,
                      y = all_ft,
                      by = c("pid_unique", "poly_id"),
                      all = TRUE)

### save a version of this
st_write(ft_footprint, "E:/fuel_treat/ft_polys/burned_ft/all_ft_burned_full_poly_update.gpkg",
         append = FALSE)
```

### code that checks for perfect overlap in burned fts
```{r}
### check for duplicated geometries
same_geom <- st_equals(ft_footprint)

### pull out duplicated geoms
dup_groups <- unique(lapply(same_geom, sort))
dup_groups <- dup_groups[sapply(dup_groups, length) > 1]
dup_groups <- dup_groups[!duplicated(dup_groups)]

### get max group size
max_cols <- max(sapply(dup_groups, length))

### grab poly_ids
dup_ids <- lapply(dup_groups, function(group) {
  ids <- ft_footprint$pid_unique[group]
  length(ids) <- max_cols  
  return(ids)
})

### as df
dup_df <- as.data.frame(do.call(rbind, dup_ids))
colnames(dup_df) <- paste0("pid_unique_", seq_len(ncol(dup_df)))

# ### check out some overlaps
# check <- ft_footprint %>%
#   filter(poly_id %in% c("10000", "122671", "56437")) ### same year

### drop geom from ft_footprint
ft_info <- ft_footprint
st_geometry(ft_info) <- NULL
rm(ft_footprint)
gc()

#############################################
### see if the date_comp is also the same
#############################################
to_check <- c("date_comp", "Event_ID")

### check if values are the same
all_equal_or_na <- function(x) {
  x <- na.omit(x)
  length(unique(x)) <= 1
}

### list to store output
attribute_consistency <- lapply(to_check, function(attr_name) {
  sapply(1:nrow(dup_df), function(i) {
    
    ### get poly_id
    ids <- dup_df[i, , drop = TRUE]
    ids <- ids[!is.na(ids)]
    
    ### get col vals
    vals <- ft_info[[attr_name]][ft_info$pid_unique %in% ids]
    
    ### check if vals are the same
    all_equal_or_na(vals)
  })
})

### put into df
consist_df <- as.data.frame(attribute_consistency)
names(consist_df) <- to_check
consist_df$group_id <- 1:nrow(dup_df)
consist_df <- cbind(group = apply(dup_df, 1, paste, collapse = ","), consist_df)

### which polys have the same date, etc?
consistent_groups <- consist_df[apply(consist_df[to_check], 1, all), ]

### date_comp can differ but same fire
consist_eventid <- consist_df %>%
  filter(Event_ID == TRUE)

### write out dups 
write_csv(consistent_groups,
          "E:/fuel_treat/ft_polys/same_poly_ft_match_update.csv")
write_csv(consist_df,
          "E:/fuel_treat/ft_polys/same_poly_ft_diff_attributes_update.csv")
write_csv(dup_df,
          "E:/fuel_treat/ft_polys/same_poly_ft_attr_unchecked_update.csv")
write_csv(consist_eventid,
          "E:/fuel_treat/ft_polys/same_poly_ft_same_fire_update.csv")
```
#### NOT SURE WHAT TO DO NEXT to harmonize the fts that are the same/have the same date but different activity codes

### USE E:/fuel_treat/ft_polys/same_poly_ft_same_fire.csv to get just a single burn date for the fts that overlapped and burned in the same fire

### subset to burned area
```{r}
### get the geometry of the part that burned in the wildfire (not the whole fuel treatment footprint)

### open fts
ft_footprint <- st_read("E:/fuel_treat/ft_polys/burned_ft/all_ft_burned_full_poly_update.gpkg")

### Open csv of all burned footprints
all_ft <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv") %>%
  distinct(.) %>%
  dplyr::select(., poly_id, Event_ID, pid_unique)

### Open all fires that subsequently burned fuel treatments
mtbs <- st_read("E:/fuel_treat/mtbs_ft.shp") %>%
  
  ### subset to fires that burned into fts
  filter(., Event_ID %in% all_ft$Event_ID) %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, geometry)

### firedpy
fired <- st_read("E:/fuel_treat/firedpy_ft.shp") %>%
  
  ### subset to fires that burned into fts
  filter(., Event_ID %in% all_ft$Event_ID) %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, geometry)

### combine fires
all_fires <- rbind(fired, mtbs)

### clean up
rm(fired, mtbs)
gc()

### load libraries for intersection
library(doParallel)
library(foreach)

### set up parallel processing
num_cores <- 10 
cl <- makeCluster(num_cores)
registerDoParallel(cl)

### get dummy df
temp_ft_dummy <- ft_footprint[4, ]
temp_fire_dummy <- all_fires %>%
  filter(Event_ID %in% temp_ft_dummy$Event_ID)
ft_intersect_dummy <- st_intersection(temp_ft_dummy,
                                      temp_fire_dummy)
ft_intersect_dummy <- ft_intersect_dummy %>%
  dplyr::select(-Event_ID.1)
ft_intersect_dummy$state[ft_intersect_dummy$state == "OR"] <- "dummy_row"

# ### make test df
# loop_test <- ft_footprint[1:10, ]

### split rows outside loop to avoid issues with parallel processing
row_data <- split(ft_footprint, seq(nrow(ft_footprint)))

### intersect in parallel
process_intersection_safe <- function(temp_ft) {
  
  ### grab pid_unique for error log
  pid_unique <- temp_ft$pid_unique
  
  ### subset to relevant fire
  temp_fire <- all_fires %>%
    filter(Event_ID %in% temp_ft$Event_ID)
  
  ### make geoms valid
  temp_ft <- st_make_valid(temp_ft)
  temp_fire <- st_make_valid(temp_fire)  
  
  ### log missing
  if (nrow(temp_fire) == 0 || st_is_empty(temp_ft) || st_is_empty(temp_fire)) {
    return(list(success = NULL, fail = as.character(pid_unique)))
  }
  
  ### skip empty or invalid geometries
  if (nrow(temp_fire) == 0 || st_is_empty(temp_ft) || st_is_empty(temp_fire)) {
    return(list(success = NULL, fail = as.character(pid_unique)))
  }
  
  ### intersect
  result <- tryCatch({
    st_intersection(temp_ft, temp_fire)
  }, error = function(e) {
    return(NULL)
  })
  
  ### handle failure
   if (is.null(result) || nrow(result) == 0) {
    return(list(success = NULL, fail = as.character(pid_unique)))
  }
  
  ### drop extra col
  result <- result %>%
    dplyr::select(-Event_ID.1)
  
  ### return output
  return(list(success = result, fail = NULL))
}

### run loop in parallel
ft_intersections <- foreach(temp_ft = row_data, 
                            # .combine = rbind, 
                            .packages = c("sf", "dplyr")) %dopar% {
                              process_intersection_safe(temp_ft)
                            }
### stop parallel cluster
stopCluster(cl)

### split results
intersections_list <- lapply(ft_intersections, `[[`, "success")
failures_list <- unlist(lapply(ft_intersections, `[[`, "fail"))

### combine successful intersections
# ft_intersections_all <- do.call(rbind, 
#                                 intersections_list[!sapply(intersections_list, 
#                                                            is.null)])

### remove nulls
valid_intersections <- intersections_list[!sapply(intersections_list, 
                                                  is.null)]

### break into chunks for combining
chunk_size <- 1000
chunks <- split(valid_intersections, 
                ceiling(seq_along(valid_intersections) / chunk_size))

### parallelize
num_cores <- 10
cl <- makeCluster(num_cores)
registerDoParallel(cl)

### combine each chunk in parallel
combined_chunks <- foreach(chunk = chunks,
                           .packages = "sf") %dopar% {
  do.call(rbind, chunk)
}

# Stop the cluster
stopCluster(cl)

### combine all chunks together
ft_intersections_all <- do.call(rbind, combined_chunks)

### clean up
rm(valid_intersections, temp_fire_dummy, temp_ft_dummy,
   combined_chunks, ft_intersections, ft_footprint, all_ft, all_fires)
gc()

#########################
### get year burned
#########################
### Open all fires that subsequently burned fuel treatments
mtbs <- st_read("E:/fuel_treat/mtbs_ft.shp") %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, year, geometry)

### firedpy
fired <- st_read("E:/fuel_treat/firedpy_ft.shp") %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, year, geometry)

### combine fires
all_fires <- rbind(fired, mtbs)

### simplify fires
all_fires_simple <- all_fires %>%
  st_drop_geometry() %>%
  distinct(Event_ID, .keep_all = TRUE)

### merge with ft_intersections
ft_merge <- merge(x = ft_intersections_all,
                  y = all_fires_simple,
                  by = "Event_ID",
                  all.x = TRUE)
# ft_intersections_all <- ft_intersections_all %>%
#   left_join(all_fires_simple$Event_ID)

### add column for year_prior to ft_merge
ft_merge <- ft_merge %>%
  mutate(year_prior = year - 1)

#### DEAL WITH pid_unique vs poly_id HERE!!!!
########################################
##########################################
###########################################

### deal with duplicate poly_ids -- need unique identifier for GEE
test <- ft_merge
st_geometry(test) <- NULL
test_summ <- test %>%
  group_by(pid_unique, Event_ID) %>%
  summarise(n_occ = n())

### make unique identification col
ft_merge <- ft_merge %>%
  mutate(poly_fire = paste0(pid_unique, "_", Event_ID))

### write out
st_write(ft_merge,
         "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.gpkg",
         append = FALSE)
st_write(ft_merge,
         "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.shp",
         append = FALSE)
# st_write(ft_intersections,
#          "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons.gpkg",
#          append = FALSE)
# st_write(ft_intersections,
#          "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons.shp",
#          append = FALSE)
```

#### deal with loop failures
```{r}
### figure out what happened with failed intersections
failed_intersect <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_combined/all_ft_burn_update.csv") %>%
  filter(., poly_id %in% failures_list)

### there weren't any loop failures!
```

##### previous code here
```{r}
### load libraries for intersection
library(doParallel)
library(foreach)

### set up parallel processing
num_cores <- 10 
cl <- makeCluster(num_cores)
registerDoParallel(cl)

### get dummy df
temp_ft_dummy <- ft_footprint[4, ]
temp_fire_dummy <- all_fires %>%
  filter(Event_ID %in% temp_ft_dummy$Event_ID)
ft_intersect_dummy <- st_intersection(temp_ft_dummy,
                                      temp_fire_dummy)
ft_intersect_dummy <- ft_intersect_dummy %>%
  dplyr::select(-Event_ID.1)
ft_intersect_dummy$state[ft_intersect_dummy$state == "OR"] <- "dummy_row"

# ### make test df
# loop_test <- ft_footprint[1:10, ]

### intersect in parallel
process_intersection <- function(i) {
  
  ### subset to row
  temp_ft <- ft_footprint[i, ]
  
  ### make valid
  temp_ft <- st_make_valid(temp_ft)
  
  ### subset to relevant fire
  temp_fire <- all_fires %>%
    filter(Event_ID %in% temp_ft$Event_ID)
  
  ### intersect geom
  ft_intersect <- st_intersection(temp_ft,
                                  temp_fire)
  
  ### drop extra col
  ft_intersect <- ft_intersect %>%
    dplyr::select(-Event_ID.1)
  
  ### return output
  return(ft_intersect)
}

### run loop in parallel
ft_intersections <- foreach(i = 1:nrow(ft_footprint), 
                            .combine = rbind, 
                            .packages = c("sf", "dplyr")) %dopar% {
  process_intersection(i)
}

### combine the dummy row
ft_intersections <- rbind(ft_intersect_dummy,
                          ft_intersections)

### stop parallel cluster
stopCluster(cl)

### drop dummy row
ft_intersections <- ft_intersections %>%
  filter(!state == "dummy_row")

#########################
### get year burned
#########################
### Open all fires that subsequently burned fuel treatments
mtbs <- st_read("E:/fuel_treat/mtbs_ft.shp") %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, year, geometry)

### firedpy
fired <- st_read("E:/fuel_treat/firedpy_ft.shp") %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, year, geometry)

### combine fires
all_fires <- rbind(fired, mtbs)

### drop geom
st_geometry(all_fires) <- NULL

### merge with ft_intersections
ft_intersections <- merge(x = ft_intersections, 
                          y = all_fires, 
                          by = "Event_ID", 
                          all.x = TRUE)

### add column for year_prior to ft_intersections
ft_intersections <- ft_intersections %>%
  mutate(year_prior = year - 1)

### deal with duplicate poly_ids -- need unique identifier for GEE
test <- ft_intersections
st_geometry(test) <- NULL
test_summ <- test %>%
  group_by(poly_id, Event_ID, act_code) %>%
  summarise(n_occ = n())

### make unique identification col
ft_intersections <- ft_intersections %>%
  mutate(poly_fire = paste0(poly_id, "_", Event_ID))
```



#### simplify duplicates
##### old approach
```{r}
### drop fts that have perfect overlap (geometry, date_comp) with another one in the dataset
simp_ft_intersections <- ft_intersections %>%
  filter(!poly_id %in% unlist(dup_df[, c("poly_id_2", "poly_id_3", "poly_id_4", "poly_id_5", 
                                         "poly_id_6", "poly_id_7", "poly_id_8", "poly_id_9", "poly_id_10", 
                                         "poly_id_11", "poly_id_12", "poly_id_13", "poly_id_14", "poly_id_15", 
                                         "poly_id_16", "poly_id_17", "poly_id_18", "poly_id_19", "poly_id_20", 
                                         "poly_id_21", "poly_id_22", "poly_id_23", "poly_id_24", "poly_id_25", 
                                         "poly_id_26", "poly_id_27", "poly_id_28", "poly_id_29", "poly_id_30", 
                                         "poly_id_31", "poly_id_32", "poly_id_33", "poly_id_34", "poly_id_35", 
                                         "poly_id_36", "poly_id_37", "poly_id_38", "poly_id_39", "poly_id_40", 
                                         "poly_id_41", "poly_id_42", "poly_id_43", "poly_id_44", "poly_id_45", 
                                         "poly_id_46", "poly_id_47", "poly_id_48", "poly_id_49", "poly_id_50", 
                                         "poly_id_51", "poly_id_52", "poly_id_53", "poly_id_54", "poly_id_55", 
                                         "poly_id_56", "poly_id_57", "poly_id_58", "poly_id_59", "poly_id_60", 
                                         "poly_id_61", "poly_id_62", "poly_id_63", "poly_id_64", "poly_id_65", 
                                         "poly_id_66", "poly_id_67", "poly_id_68", "poly_id_69")]))

### can write this out, but note that it might not keep the "right" fuel treatment...

### need to make sure the date burned is the earliest that particular area burned, in order to get the pre-fire vegetation
st_write(simp_ft_intersections,
         "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_simple.gpkg",
         append = FALSE)
st_write(simp_ft_intersections,
         "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_simple.shp",
         append = FALSE)
```

##### new approach
```{r}
### re-open
ft_intersections <- st_read("E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.gpkg")
consistent_groups <- read.csv("E:/fuel_treat/ft_polys/same_poly_ft_match_update.csv")
consist_df <- read.csv("E:/fuel_treat/ft_polys/same_poly_ft_diff_attributes_update.csv")
same_fire <- read.csv("E:/fuel_treat/ft_polys/same_poly_ft_same_fire_update.csv")

### make df of group ids for polygons that burned in the same fire
group_df <- same_fire %>%
  separate_rows(group, sep = ",") %>%
  mutate(group = str_trim(group)) %>%
  rename(poly_id = group) %>%
  filter(!poly_id == "NA") %>%
  dplyr::select(poly_id, group_id)

### compare # poly_id
length(unique(group_df$poly_id))
nrow(group_df)

### join with polys
ft_join <- merge(x = ft_intersections,
                 y = group_df,
                 by = "poly_id",
                 all.x = TRUE)

### make version to get minimum date
ft_min <- ft_join
st_geometry(ft_min) <- NULL

### make sure year_prior is correct across polys with the same group_id
ft_range_summ <- ft_min %>%
  filter(!is.na(group_id)) %>%
  group_by(group_id) %>%
  summarise(min_date = min(year_prior, na.rm = TRUE),
            max_date = max(year_prior, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(range_year = max_date - min_date)
### range = 0, so no need to mess with year_prior

### now just need one row per group
ft_simple <- ft_join %>%
  group_by(group_id) %>%
  
  ### keep all rows where group_id = NA (these don't have overlapping fts)
  filter(is.na(group_id) |
           
           ### and keep just one ft for each of the group_ids to reduce GEE effort
           poly_id == min(poly_id, na.rm = TRUE)) %>%
  ungroup()

### calculate area
ft_simple$poly_area <- st_area(ft_simple)

### make area into numeric
ft_simple <- ft_simple %>%
  mutate(area_m2 = as.numeric(poly_area))

### simplify for GEE
ft_simple <- ft_simple %>%
  dplyr::select(poly_id, pid_unique, poly_fire, year_prior, geometry)

### write out for GEE
st_write(ft_simple, 
         "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_gee_update.shp")
```

## Which fuel treatments are forested?
Using LCMAP in GEE
```{r}
### in GEE, I used LCMAP to calculate the forested area (m2) for each fuel treatment in the year before the wildfire

### open resulting csvs
ft1 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/forested_area_ft_1.csv")
ft2 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/forested_area_ft_2.csv")
ft3 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/forested_area_ft_3.csv")
ft4 <- read.csv("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/forested_area_ft_4.csv")

### combine
forest_area <- rbind(ft1, ft2, ft3, ft4)

### fix cols
forest_area <- forest_area %>%
  dplyr::select(poly_id, poly_fire, pid_unique, 
                forested_area = forestedArea, year_prior)
rm(ft1, ft2, ft3, ft4)

### how many repeats are there?
length(unique(forest_area$pid_unique))

### combine with geometry
ft_forest <- merge(x = ft_simple, 
                   y = forest_area,
                   by = c("poly_id", "pid_unique", 
                          "poly_fire", "year_prior"),
                   all = TRUE)

### calculate geometry area
ft_forest$poly_area_m2 <- st_area(ft_forest)

### drop unit
ft_forest$poly_area_m2 <- as.numeric(ft_forest$poly_area_m2)

### drop fuel treatments with 0 m2 of forest pre-fire
ft_forest <- ft_forest %>%
  filter(forested_area > 0)
length(unique(ft_forest$pid_unique)) ## 91791

### drop fuel treatments with < 900 m2 (one landsat pixel) of forest pre-fire
ft_forest <- ft_forest %>%
  filter(!forested_area < 900)
length(unique(ft_forest$pid_unique)) ## 88260

### get percent forested pre-fire
ft_forest <- ft_forest %>%
  mutate(portion_forest = forested_area/poly_area_m2)

### visuals
ft_forest %>%
  filter(poly_fire == "14_FACTS Common Attributes_WY4373810408120010730") %>%
  ggplot() +
  geom_sf()

### plot distribution of proportion of forest pre-fire
ft_forest_df <- ft_forest
st_geometry(ft_forest_df) <- NULL
ft_forest_df %>%
  filter(portion_forest < 1.00001) %>%
  ggplot(aes(x = portion_forest)) +
  geom_histogram() +
  theme_bw() +
  xlab("proportion of forest pre-fire") +
  NULL

### write out csv of ft's that have enough forest area to continue
st_write(ft_forest,
          "E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/forested_ft.csv")
```

## Do some fires only burn non-fuel treatment activities?
In the TWIG dataset, they assign treatment category to all activities.
FACTS Common Attributes and FACTS Hazardous Fuels have activity codes, equipment, categories. So TWIG harmonizes that with the NFPORS data, which doesn't have that level of metadata.

### For purpose of ESA, drop NFPORS because missing activity code
So can't distinguish between mechanical treatments that are for fuel treatment vs. not
```{r}
### open fts
ft_intersections <- st_read("E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.gpkg")

### drop geom
st_geometry(ft_intersections) <- NULL
write_csv(ft_intersections,
          "E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.csv")

### open ft without geom
ft_intersections <- read.csv("E:/fuel_treat/ft_polys/burned_ft/all_burned_ft_polygons_update.csv")

### open original twig data
twig <- st_read("E:/fuel_treat/ft_polys/twig_reshape/all_twig_split.shp")

### drop geom
st_geometry(twig) <- NULL

### simplify and rename cols
twig <- twig %>%
  rename(unique_id = uniqu_d,
         treatment_date = trtmnt_,
         date_source = dat_src,
         identifier_database = idntfr_,
         date_current = dt_crrn,
         actual_comp_date = actl_c_,
         activity_code = actvty_,
         activity = activty,
         equipment = equpmnt,
         category = categry,
         twig_category = twg_ctg,
         fund_source = fnd_src,
         fund_code = fund_cd,
         total_cost = ttl_cst,
         cost_per_uom = cst_pr_,
         shape_length = shp_Lng,
         shape_area = shap_Ar,
         year_comp = yer_cmp) %>%
  dplyr::select(poly_id, 
                state,
                source = identifier_database,
                date_comp = treatment_date,
                act_code = activity_code,
                activity,
                equipment, 
                category)

### fix "twig" category in ft_intersections
ft_intersections <- ft_intersections %>%
  mutate(source = ifelse(source == "twig", 
                         "FACTS Hazardous Fuels",
                         source))

### make act_code a character in ft_intersections
ft_intersections$act_code <- as.character(ft_intersections$act_code)

### make dates in ft_intersections
ft_intersections$date_comp <- as.Date(ft_intersections$date_comp,
                                      format = "%Y-%m-%d")

### subset ft_intersections to twig sources
ft_twig <- ft_intersections %>%
  filter(source %in% twig$source)

### merge twig in with fts
ft_twig <- merge(x = ft_twig,
                 y = twig, 
                 by = c("poly_id", "date_comp", "act_code", "source", "state"),
                 all.x = TRUE)

### subset ft_intersections to facts source
ft_fact <- ft_intersections %>%
  filter(source == "facts")

### open original facts data
all_facts <- st_read("E:/fuel_treat/ft_polys/usfs_treat/all_facts_split.shp")

### drop geom
st_geometry(all_facts) <- NULL

### simplify and rename cols
all_facts <- all_facts %>%
  mutate(source = "facts") %>%
  dplyr::select(poly_id, 
                state = STATE_ABBR,
                source,
                date_comp = DATE_COMPL,
                act_code = ACTIVITY_C,
                activity = ACTIVITY,
                equipment = EQUIPMENT, 
                category = TREATMENT_)

### merge facts in with fts
ft_fact <- merge(x = ft_fact,
                 y = all_facts, 
                 by = c("poly_id", "date_comp", "act_code", 
                        "source", "state"),
                 all.x = TRUE)

### combine back
all_ft <- rbind(ft_twig, ft_fact)

### drop wildfire
all_ft <- all_ft %>%
  filter(!act_code == "1115")

### categorize types of activities
all_ft <- all_ft %>%
  mutate(activity_cat = ifelse(act_code %in% c("1100", "1111", "1112", "1113",
                                               "1205", "2540", "4471", "4491", 
                                               "4541", "6101", "7015", "7050"),
                               "fire_ft",
                               ifelse(act_code %in% c("1000", "1136", "1139", 
                                                      "1140", "1150", "1152", 
                                                      "1153", "1154", "1160", 
                                                      "1169", "1180", "1182",
                                                      "1256", "2370", "3370",
                                                      "4455", "4473", "4475",
                                                      "4493", "4495", "4511",
                                                      "4521", "4530", "4540",
                                                      "6103", "6133"),
                                      "mech_ft",
                                      ifelse(act_code %in% c("1102", "1120",
                                                             "2321", "2340",
                                                             "2341", "2360",
                                                             "2400",
                                                             "2510", "2530",
                                                             "3192", "3193",
                                                             "4101", "4102",
                                                             "4111", "4113",
                                                             "4115", "4117",
                                                             "4121", "4122",
                                                             "4131", "4132", 
                                                             "4141", "4142",
                                                             "4143", "4145",
                                                             "4146", "4148",
                                                             "4151", "4152",
                                                             "4162", "4175",
                                                             "4177", "4183",
                                                             "4192", "4193", 
                                                             "4194", "4196",
                                                             "4210", "4211",
                                                             "4220", "4231",
                                                             "4232", "4241",
                                                             "4242", "4270",
                                                             "4314", "4320",
                                                             "4331", "4341",
                                                             "4382", "4383",
                                                             "4394", "4401",
                                                             "4431", "4452",
                                                             "4462", "4464",
                                                             "4466", "4471", 
                                                             "4472",
                                                             "4474", "4484",
                                                             "4494", "4550",
                                                             "4570", "4931",
                                                             "5100", "5510",
                                                             "5520", "5530",
                                                             "5540", "5550",
                                                             "5633", "6050",
                                                             "6100", "6104",
                                                             "6107", "6110",
                                                             "6111", "6130",
                                                             "6131", "6160",
                                                             "6200", "6423",
                                                             "6630", "7100",
                                                             "7065", "7067",
                                                             "8100",
                                                             "8200", "8220",
                                                             "9008", "9400"),
                                             "non_ft",
                                             ifelse(act_code %in% c("1130", "1131"),
                                                    "m_pile_burn",
                                                    ifelse(act_code == "1115", "wildfire",
                                                    # ifelse(is.na(act_code),
                                                    #        category,
                                                           category))))))
### fix NFPORS
all_ft <- all_ft %>% 
  mutate(activity_cat = ifelse(is.na(activity_cat),
                               category,
                               activity_cat))

### write out
write_csv(all_ft,
          "E:/fuel_treat/ft_polys/all_ft_category.csv")
```

#### without NFPORS
```{r}
### drop NFPORS
all_ft <- all_ft %>%
  filter(!source == "NFPORS")

### find fires with just one activity_cat
fire_summ <- all_ft %>%
  group_by(Event_ID) %>%
  summarise(n_activity = length(unique(activity_cat))) %>%
  ungroup() %>%
  filter(n_activity < 2)

### take a look at the activity codes
fire_one <- all_ft %>%
  filter(Event_ID %in% fire_summ$Event_ID) %>%
  dplyr::select(Event_ID, activity_cat) %>%
  distinct()

### which fires only have non fuel treatment activities?
fire_one <- fire_one %>%
  filter(activity_cat == "non_ft")

### open fires
### Open all fires that subsequently burned fuel treatments
mtbs <- st_read("E:/fuel_treat/mtbs_ft.shp") %>%
  
  ### subset to fires that burned into fts
  filter(., Event_ID %in% all_ft$Event_ID) %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, geometry)

### firedpy
fired <- st_read("E:/fuel_treat/firedpy_ft.shp") %>%
  
  ### subset to fires that burned into fts
  filter(., Event_ID %in% all_ft$Event_ID) %>%
  
  ### simplify cols
  dplyr::select(., Event_ID, geometry)

### combine fires
all_fires <- rbind(fired, mtbs)

### clean up
rm(fired, mtbs)
gc()

### write out
st_write(all_fires,
         "E:/fuel_treat/all_burned_ft_fires.shp")

### drop fires that only burned non-fts
fires_ft <- all_fires %>%
  filter(!Event_ID %in% fire_one$Event_ID)

### write out
st_write(fires_ft,
         "E:/fuel_treat/burned_ft_fires_use.shp",
         append = FALSE)


### fire 2982 should only have non_ft treatments
```
#### start with fires with 1 treatment
For ESA, let's start with fires that only received a single treatment
```{r}
### open fires we're using
fires_ft <- st_read("E:/fuel_treat/burned_ft_fires_use.shp")

### open fts, filter to fires we're using
all_ft <- read.csv("E:/fuel_treat/ft_polys/all_ft_category.csv") %>%
  filter(., Event_ID %in% fires_ft$Event_ID)

### get # polys for each fire
n_ft <- all_ft %>% 
  group_by(Event_ID) %>% 
  summarise(n_poly = length(unique(pid_unique)))

### get fires with just 1 treatment
ft_1 <- n_ft %>%
  filter(n_poly < 2)

### filter to those fires
ft_1 <- all_ft %>% 
  filter(Event_ID %in% ft_1$Event_ID)

### filter fires to those fires
fires_use <- fires_ft %>% 
  filter(Event_ID %in% ft_1$Event_ID)

### write out
st_write(fires_use,
         "E:/fuel_treat/burned_ft_fires_single_ft.shp")
```

### download CBI from google drive
#### firedpy
```{r}
### folder url
folder_fp_url <- "https://drive.google.com/drive/u/2/folders/1T_aweemZT3NShOaradGqKoA5ts5_zytn"

### identify the folder
folder_fp <- drive_get(as_id(folder_fp_url))

### identify the rasters in that folder
drive_fp <- drive_ls(folder_fp)

### set download path
fp_path <- "E:/fuel_treat/firedpy/cbi_gee_firedpy/"

### filter files to just include the bias corrected ones
bc_files <- drive_fp[grepl("_CBI_bc\\.tif$", drive_fp$name), ]

### run through files to download
for (i in seq_along(drive_fp$name)) {
  drive_download(
    as_id(drive_fp$id[[i]]),
    path = file.path(fp_path, drive_fp$name[[i]]),
    overwrite = TRUE
  )
}
```

##### figure out downloaded fires
```{r}
### fires I need
fires_use <- st_read("E:/fuel_treat/burned_ft_fires_single_ft.shp")

### figure out which fp fires I have
fp_fires <- list.files(path = "E:/fuel_treat/firedpy/cbi_gee_firedpy",
                       pattern = "*_CBI_bc.tif",
                       full.names = TRUE)
fp_file_base <- basename(fp_fires)
fp_file_name <- sub("_CBI_bc\\.tif$", "", fp_file_base)

### figure out which mtbs fires I have
mt_fires <- list.files(path = "E:/fuel_treat/mtbs/cbi_gee_mtbs",
                       pattern = "*_CBI_bc.tif",
                       full.names = TRUE)
mt_file_base <- basename(mt_fires)
mt_file_name <- sub("_CBI_bc\\.tif$", "", mt_file_base)

### combine vectors
all_files <- c(fp_file_name, mt_file_name)

### which fires do I still need?
fires_missing <- fires_use %>%
  filter(!Event_ID %in% all_files)

### open mtbs and firedpy (raw versions to avoid splits across state boundaries)
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_perims_DD.shp")
fired <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp")

### subset to fires I still need
mtbs <- mtbs %>%
  filter(Event_ID %in% fires_missing$Event_ID)
fired <- fired %>%
  filter(Event_ID %in% fires_missing$Event_ID)

### PREP MTBS
### extract state as column
mtbs <- mtbs %>%
  mutate(state = stringr::str_extract(Event_ID, "^.{2}"))

### Fire seasons
#### In Parks et al. 2019, they use the following seasons:
#### AZ and NM: April 1-June 30 (julian 91-181)
#### CA, ID, MT, OR, UT, WA, WY: June 1-Sept 15 (julian 152-258)
#### assume it's the same for CO, NV
#### use these
# other_julian <- c("CA", "CO", "ID",
#                   "MT", "NV", "OR",
#                   "SD", "TX",
#                   "UT", "WA", "WY")

### use julian fire season dates for CA, ID, MT, OR, UT, WA, WY

### assign julian start and end date based on state dates from Parks et al. 2019
mtbs <- mtbs %>%
  mutate(Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258))

### add year
mtbs <- mtbs %>%
  mutate(year = year(Ig_Date))

### Select columns for GEE
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)
mtbs <- mtbs %>%
  dplyr::select(Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day,
                End_Day,
                Incid_Type,
                geometry)

### Make sure date columns don't get read in with decimals
mtbs$Fire_Year <- as.character(mtbs$Fire_Year, 0)
mtbs$Start_Day <- as.character(mtbs$Start_Day, 0)
mtbs$End_Day <- as.character(mtbs$End_Day, 0)

### transform
mtbs <- mtbs %>%
  st_transform(crs = 6350)

### PREP FIREDPY

### simplify states in fired_use (based on actual distribution across state lines -- assign to state it's majority in)
fired <- fired %>%
  mutate(state = ifelse(Event_ID %in% c("701", "702"), "CA",
                        ifelse(Event_ID == "14510", "AZ",
                               ifelse(Event_ID == "14543", "NM",
                                      ifelse(Event_ID == "145855", "CO",
                                             ifelse(Event_ID == "171512", "ID",
                                                    ifelse(Event_ID %in% c("130181",
                                                                           "171513"), 
                                                           "MT",
                                                           state)))))))

### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)

### Fire seasons
#### In Parks et al. 2019, they use the following seasons:
#### AZ and NM: April 1-June 30 (julian 91-181)
#### CA, ID, MT, OR, UT, WA, WY: June 1-Sept 15 (julian 152-258)
#### assume it's the same for CO, NV
#### use these
# other_julian <- c("CA", "CO", "ID",
#                   "MT", "NV", "OR",
#                   "SD", "TX",
#                   "UT", "WA", "WY")

### use julian fire season dates for CA, ID, MT, OR, UT, WA, WY

### assign julian start and end date based on state dates from Parks et al. 2019
fired <- fired %>%
  mutate(Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258))

### Select columns for GEE
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)
fired <- fired %>%
  dplyr::select(Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day,
                End_Day,
                Incid_Type,
                geometry)

### Make sure date columns don't get read in with decimals
fired$Fire_Year <- as.character(fired$Fire_Year, 0)
fired$Start_Day <- as.character(fired$Start_Day, 0)
fired$End_Day <- as.character(fired$End_Day, 0)

### 

### combine
fm <- rbind(fired, mtbs)

### write out
st_write(fm,
         "E:/fuel_treat/fires_need_gee.shp")

```

#### filter fires to forested fuel treatments
```{r}
### open fires that burned a single ft
fires <- st_read("E:/fuel_treat/burned_ft_fires_single_ft.shp")

### pull out fire name from ft_forest
ft_forest <- ft_forest %>%
  separate(poly_fire, into = c("poly_id_2", "source", "Event_ID"), 
           sep = "_")

### filter to fires in forested fts
fires_forest <- fires %>% 
  filter(Event_ID %in% ft_forest$Event_ID)

### write out
st_write(fires_forest, 
         "E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/fires_forest.shp")
```

##### sample pts for these fires
Use code from ft_overlaps to make sample points

###### mtbs
```{r, warning=FALSE}
### open fires_forest
fires_forest <- st_read("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/fires_forest.shp")

### open mtbs fires
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_1984_2024_west.shp") %>%
  filter(., Event_ID %in% fires_forest$Event_ID)

### add column for file path
mtbs <- mtbs %>%
  mutate(fire_file = paste0("E:/fuel_treat/mtbs/cbi_gee_mtbs/", 
                            Event_ID, "_CBI_bc.tif"))

### get path for fires
mtbs_path <- list.files(path = "E:/fuel_treat/mtbs/cbi_gee_mtbs",
                        full.names = TRUE)

# ### simplify to fire name
# mt_file_base <- basename(mtbs_path)
# mt_file_name <- sub("_CBI_bc\\.tif$", "", mt_file_base)

### subset to fires I want
mt_fires <- mtbs_path[mtbs_path %in% mtbs$fire_file]

# ### restrict mtbs_path to the fires I need
# mtbs_path <- mtbs_path[mtbs_path %in% fires_forest$Event_ID]

### store pts
store_cbi_pts <- list()

### Loop through files to write out pts
for (i in 1:length(mt_fires)) {
  
  ### print step
  print(paste0("STEP ", i))
  
  ### open file
  mtbs_i <- raster(mt_fires[i])
  
  # ### reproject to 6350
  # mtbs_i <- projectRaster(mtbs_i, 
  #                         crs = 6350, 
  #                         method = "bilinear")
  
  ### fire name
  cbi_fire_name <- mt_fires[i]
  cbi_fire_name <- gsub('_CBI_bc.tif','', cbi_fire_name)
  cbi_fire_name <- gsub('E:/fuel_treat/mtbs/cbi_gee_mtbs/',
                        '', cbi_fire_name)
  
  ### make points
  mtbs_pt <- mtbs_i %>%
    rasterToPoints(spatial = TRUE)
  
  ### convert to sf
  mtbs_pt <- st_as_sf(mtbs_pt) %>%
    
    ### add fire name
    mutate(fire_id = cbi_fire_name) %>%
    
    ### transform
    st_transform(6350)
  
  ### get fire year and year_prior
  fire_info_i <- mtbs %>%
    filter(Event_ID %in% mtbs_pt$fire_id)
  
  ### drop geometry
  st_geometry(fire_info_i) <- NULL
  
  ### drop duplicates
  fire_info_i <- distinct(fire_info_i)
  
  ### add this data to sf df
  mtbs_pt <- mtbs_pt %>%
    mutate(ig_date = fire_info_i$Ig_Date,
           fire_year = fire_info_i$year,
           year_prior = fire_year - 1,
           
           ### make uid for sample pt
           row_num = row_number(),
           uid = paste0(fire_id, "_", row_num))
  
  ### drop excess col
  mtbs_pt <- mtbs_pt %>%
    dplyr::select(-row_num)
  
  ### add to list
  store_cbi_pts[[i]] <- mtbs_pt
  
  # ### name for pts
  # mtbs_name <- mtbs_path[i]
  # mtbs_name <- gsub('_CBI_bc.tif','', mtbs_name)
  # mtbs_name <- gsub('E:/usda_2023/usfs_fuel_treatments/western_us/cbi_fuel_treat_mtbs/',
  #                   '', mtbs_name)
  # 
  # ### make output file
  # mtbs_dir <- file.path(paste0("E:/usda_2023/usfs_fuel_treatments/western_us/cbi_pts/",
  #                              mtbs_name,
  #                              ".shp"))
  # 
  # ### write out
  # st_write(mtbs_pt,
  #          mtbs_dir)
  
  rm(mtbs_i, mtbs_pt)
}

### combine sfs
cbi_full <- do.call(rbind, store_cbi_pts)

### which fires from mtbs are missing in mt_fires?
missing_mtbs <- mtbs %>%
  filter(!Event_ID %in% cbi_full$fire_id)

rm(store_cbi_pts)
gc()

### write out
st_write(cbi_full,
         "E:/fuel_treat/mtbs/cbi_gee_mtbs/cbi_pts_mtbs.shp",
         append = FALSE)

rm(cbi_full)
gc()
```
###### firedpy
```{r}
### open fires_forest
fires_forest <- st_read("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/fires_forest.shp")

### open fired fires
fired <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west.shp") %>%
  filter(., id %in% fires_forest$Event_ID)

### clean columns
fired <- fired %>%
  mutate(Incid_Type = "unknown") %>%
  dplyr::select(Event_ID = id, Incid_Type,
                Ig_Date = ig_date,
                date = ig_day, month = ig_mnth, year = ig_year,
                geometry)

### add column for file path
fired <- fired %>%
  mutate(fire_file = paste0("E:/fuel_treat/firedpy/cbi_gee_firedpy/", 
                            Event_ID, "_CBI_bc.tif"))

### get path for fires
fired_path <- list.files(path = "E:/fuel_treat/firedpy/cbi_gee_firedpy",
                        full.names = TRUE)

### subset to fires I want
fp_fires <- fired_path[fired_path %in% fired$fire_file]

### store pts
store_cbi_pts <- list()

### Loop through files to write out pts
for (i in 1:length(fp_fires)) {
  
  ### print step
  print(paste0("STEP ", i))
  
  ### open file
  fired_i <- raster(fp_fires[i])
  
  ### fire name
  cbi_fire_name <- fp_fires[i]
  cbi_fire_name <- gsub('_CBI_bc.tif','', cbi_fire_name)
  cbi_fire_name <- gsub('E:/fuel_treat/firedpy/cbi_gee_firedpy/',
                        '', cbi_fire_name)
  
  ### make points
  fired_pt <- fired_i %>%
    rasterToPoints(spatial = TRUE)
  
  ### convert to sf
  fired_pt <- st_as_sf(fired_pt) %>%
    
    ### add fire name
    mutate(fire_id = cbi_fire_name) %>%
    
    ### transform
    st_transform(6350)
  
  ### get fire year and year_prior
  fire_info_i <- fired %>%
    filter(Event_ID %in% fired_pt$fire_id)
  
  ### drop geometry
  st_geometry(fire_info_i) <- NULL
  
  ### drop duplicates
  fire_info_i <- distinct(fire_info_i)
  
  ### add this data to sf df
  fired_pt <- fired_pt %>%
    mutate(ig_date = fire_info_i$Ig_Date,
           fire_year = fire_info_i$year,
           year_prior = fire_year - 1,
           
           ### make uid for sample pt
           row_num = row_number(),
           uid = paste0(fire_id, "_", row_num))
  
  ### drop excess col
  fired_pt <- fired_pt %>%
    dplyr::select(-row_num)
  
  ### add to list
  store_cbi_pts[[i]] <- fired_pt
  
  # ### name for pts
  # mtbs_name <- mtbs_path[i]
  # mtbs_name <- gsub('_CBI_bc.tif','', mtbs_name)
  # mtbs_name <- gsub('E:/usda_2023/usfs_fuel_treatments/western_us/cbi_fuel_treat_mtbs/',
  #                   '', mtbs_name)
  # 
  # ### make output file
  # mtbs_dir <- file.path(paste0("E:/usda_2023/usfs_fuel_treatments/western_us/cbi_pts/",
  #                              mtbs_name,
  #                              ".shp"))
  # 
  # ### write out
  # st_write(mtbs_pt,
  #          mtbs_dir)
  
  rm(fired_i, fired_pt)
}

### combine sfs
cbi_full <- do.call(rbind, store_cbi_pts)

### which fires from fired are missing in fp_fires?
missing_fp <- fired %>%
  filter(!Event_ID %in% cbi_full$fire_id)

### missing fires didn't download from GEE

rm(store_cbi_pts)
gc()

### write out
st_write(cbi_full,
         "E:/fuel_treat/firedpy/cbi_gee_firedpy/cbi_pts_fired.shp",
         append = FALSE)

rm(cbi_full)
gc()
```
###### combine
```{r}
### open pts from firedpy and mtbs
fp <- st_read("E:/fuel_treat/firedpy/cbi_gee_firedpy/cbi_pts_fired.shp")
mt <- st_read("E:/fuel_treat/mtbs/cbi_gee_mtbs/cbi_pts_mtbs.shp")

### fix date column for fp
### drop time from date character string
fp$ig_date <- sub(" .*", "", fp$ig_date)
### convert to date
fp$ig_date <- as.Date(fp$ig_date, format = "%Y-%m-%d")

### combine
fm <- rbind(fp, mt)

### write out
st_write(fm,
         "E:/fuel_treat/esa_subset/esa_sample_pts.shp",
         append = FALSE)

### make small version to play around in earth engine with
fm_sample <- fm %>%
  sample_n(100)

### write out
st_write(fm_sample,
         "E:/fuel_treat/esa_subset/esa_sample_pts_test.shp",
         append = FALSE)
```

## 1. ESA fires and fuel treatments
```{r}
### open fires with single fuel treatment in forest
fires_forest <- st_read("E:/fuel_treat/ft_polys/burned_ft/burned_ft_lc/fires_forest.shp")

### open mtbs fires and filter
mtbs_esa <- st_read("E:/fuel_treat/mtbs/mtbs_perims_DD.shp") %>%
  filter(., Event_ID %in% fires_forest$Event_ID) 

### fix cols
mtbs_esa <- mtbs_esa %>%
  ### make date cols
  mutate(date = day(Ig_Date),
         month = month(Ig_Date),
         year = year(Ig_Date)) %>%
  ### simplify cols
  dplyr::select(Event_ID, Incid_Type, Ig_Date, date, month, year, geometry) %>%
  ### transform
  st_transform(crs = 6350)
  
### open fired fires and clean cols
fired <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west.shp") %>%
  filter(., id %in% fires_forest$Event_ID) %>%
  mutate(., Incid_Type = "unknown") %>%
  dplyr::select(., Event_ID = id, Incid_Type,
                Ig_Date = ig_date,
                geometry)

### fix dates
fired$Ig_Date <- as.Date(fired$Ig_Date)

### make new date cols
fired <- fired %>%
  mutate(date = day(Ig_Date),
         month = month(Ig_Date),
         year = year(Ig_Date)) %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, date, month, year, geometry)

### combine fires
all_fires <- rbind(mtbs_esa, fired)

### write out
st_write(all_fires,
         "E:/fuel_treat/esa_subset/esa_fires.shp",
         append = FALSE)

### open fuel treatments (full, not just burned)
ft_footprint <- st_read("E:/fuel_treat/ft_polys/burned_ft/all_ft_burned_full_poly_update.gpkg")

### filter to fires
ft_fires <- ft_footprint %>%
  filter(Event_ID %in% all_fires$Event_ID)

### add fire info
fires_info <- all_fires
st_geometry(fires_info) <- NULL

### combine with fts
ft_fires <- merge(x = ft_fires,
                  y = fires_info,
                  by = "Event_ID",
                  all.x = TRUE)

### distinct
ft_fires <- distinct(ft_fires)

### write out
st_write(ft_fires,
         "E:/fuel_treat/esa_subset/esa_fts.shp",
         append = FALSE)
```

### deal with adjacent fires
Some of the fires in esa_fires.shp are actually parts of the same fire
```{r}
### open fires
all_fires <- st_read("E:/fuel_treat/esa_subset/esa_fires.shp")

### figure out which fires overlap
adj_matrix <- st_intersects(all_fires, sparse = FALSE)

### figure out which have similar dates too
date_diff_matrix <- outer(all_fires$Ig_Date, 
                          all_fires$Ig_Date, 
                          function(x, y) abs(as.numeric(difftime(x, y, units = "days"))))

### set distance between ignition dates
n_days <- 20

### make combined adjacency condition: polygons touch AND ignition dates are within 20 days from each other
combined_matrix <- adj_matrix & (date_diff_matrix <= n_days)

### make graph of connected components
g <- graph_from_adjacency_matrix(combined_matrix, mode = "undirected")

### assign group ids based on connected components
all_fires$group_id <- components(g)$membership

### combine geometries for grouped polygons
fires_merged <- all_fires %>%
  group_by(group_id) %>%
  arrange(Ig_Date) %>%
  summarise(
    
    ### keep earliest ignition date and corresponding Event_ID
    Ig_Date = first(Ig_Date), 
    Event_ID = first(Event_ID),
    
    ### keep track of the number of merged fires
    n_fires = n(),
    geometry = st_union(geometry),
    .groups = "drop")

### write out
st_write(fires_merged,
         "E:/fuel_treat/esa_subset/esa_fires_simp.shp",
         append = FALSE)
```

### check for perfect overlap in fires
```{r}
### open fires
fires <- st_read("E:/fuel_treat/esa_subset/esa_fires_simp.shp")

### check for duplicated geometries
same_geom <- st_equals(fires)

### pull out duplicated geoms
dup_groups <- unique(lapply(same_geom, sort))
dup_groups <- dup_groups[sapply(dup_groups, length) > 1]
dup_groups <- dup_groups[!duplicated(dup_groups)]

### get max group size
max_cols <- max(sapply(dup_groups, length))

### grab poly_ids
dup_ids <- lapply(dup_groups, function(group) {
  ids <- fires$Event_ID[group]
  length(ids) <- max_cols  
  return(ids)
})

### as df
dup_df <- as.data.frame(do.call(rbind, dup_ids))
colnames(dup_df) <- paste0("Event_ID_", seq_len(ncol(dup_df)))

### the fires that overlap are 411 and 412

### drop fire 412 from dataset since it completely overlaps and ig_date is earlier for 411
fires <- fires %>%
  filter(!Event_ID == "412")

### write out
st_write(fires, 
         "E:/fuel_treat/esa_subset/esa_fires_simp_fix.shp")

# ### check out some overlaps
# check <- ft_footprint %>%
#   filter(poly_id %in% c("10000", "122671", "56437")) ### same year

# ### drop geom from ft_footprint
# ft_info <- fires
# st_geometry(ft_info) <- NULL
# rm(fires)
# gc()

#############################################
### see if the date_comp is also the same
#############################################
to_check <- c("date_comp", "Event_ID")

### check if values are the same
all_equal_or_na <- function(x) {
  x <- na.omit(x)
  length(unique(x)) <= 1
}

### list to store output
attribute_consistency <- lapply(to_check, function(attr_name) {
  sapply(1:nrow(dup_df), function(i) {
    
    ### get poly_id
    ids <- dup_df[i, , drop = TRUE]
    ids <- ids[!is.na(ids)]
    
    ### get col vals
    vals <- ft_info[[attr_name]][ft_info$pid_unique %in% ids]
    
    ### check if vals are the same
    all_equal_or_na(vals)
  })
})

### put into df
consist_df <- as.data.frame(attribute_consistency)
names(consist_df) <- to_check
consist_df$group_id <- 1:nrow(dup_df)
consist_df <- cbind(group = apply(dup_df, 1, paste, collapse = ","), consist_df)

### which polys have the same date, etc?
consistent_groups <- consist_df[apply(consist_df[to_check], 1, all), ]

### date_comp can differ but same fire
consist_eventid <- consist_df %>%
  filter(Event_ID == TRUE)

### write out dups 
write_csv(consistent_groups,
          "E:/fuel_treat/ft_polys/same_poly_ft_match_update.csv")
write_csv(consist_df,
          "E:/fuel_treat/ft_polys/same_poly_ft_diff_attributes_update.csv")
write_csv(dup_df,
          "E:/fuel_treat/ft_polys/same_poly_ft_attr_unchecked_update.csv")
write_csv(consist_eventid,
          "E:/fuel_treat/ft_polys/same_poly_ft_same_fire_update.csv")
```
##### check
```{r}
ft <- st_read("E:/fuel_treat/esa_subset/esa_fts.shp")

ft_check <- ft %>% filter(Event_ID == "127720")

contained <- st_within(ft_check, fires, sparse = FALSE)

### get the fire without the ft
no_intersect_i <- rmapshaper::ms_erase(fires, ft_check)
  
### get just the part of use_ft that's inside the fire
use_ft_crop_i <- st_intersection(ft_check, fires)

### give them the same column names, standardize and clean geoms
### no intersection
no_intersect_i <- no_intersect_i %>%
  dplyr::select(Event_ID, geometry) %>%
  st_make_valid() %>%
  st_buffer(0)

### inner lines
use_ft_crop_i <- use_ft_crop_i %>%
  dplyr::select(Event_ID = poly_id, geometry)%>%
  st_make_valid() %>%
  st_buffer(0)

### combine them
comb_sf <- rbind(no_intersect_i,
                 use_ft_crop_i)

### make valid and fix geoms
comb_sf <- comb_sf %>%
  st_make_valid() %>%
  st_buffer(0) %>%
  st_set_precision(1e6)

### union geoms to dissolve overlaps
comb_sf_union <- comb_sf %>%
  group_by(Event_ID) %>%
  summarise(geometry = st_union(geometry)) %>%
  ungroup() %>%
  st_make_valid()

### make inner line
inner_line <- comb_sf_union %>%
  ms_innerlines() %>%
  # as_tibble() %>%
  st_as_sf()

### add the inner line to the result

### make sure there's a value
if (!is_empty(inner_line)) {  
  
  ### add it to the output list
  boundary_polys[[i]] <- inner_line
  
}

# ### deal with situations where fire is contained by ft
# if (st_within(fire, fts[i, ], sparse = FALSE)) {

# ### get ft if fire inside ft
# fully_contained_inner_line <- st_difference(fts[i, ], fire)

### deal with situations where fire is inside ft
fully_contained <- st_within(fires, ft_check, sparse = FALSE)

### check if all fire geoms are fully contained within ft
if (all(fully_contained)) {
  
  ### when fire is fully contained, grab the ft's inner lines 
  fully_contained_inner_line <- st_difference(ft_check, fires)
  
  ### convert to MULTILINESTRING if necessary
  if (inherits(st_geometry(fully_contained_inner_line), "sfc_LINESTRING")) {
    fully_contained_inner_line <- st_cast(fully_contained_inner_line, "MULTILINESTRING")
  }
  
  ### if it's a MULTILINESTRING, merge and add it
  if (inherits(st_geometry(fully_contained_inner_line), "sfc_MULTILINESTRING")) {
    fully_contained_inner_line <- st_line_merge(fully_contained_inner_line)
    
    ### add to result list
    boundary_polys[[i]] <- fully_contained_inner_line
  }
}
   
```


##### deal with complete overlaps
```{r}
### open fires
fires_merged <- st_read("E:/fuel_treat/esa_subset/esa_fires_simp.shp")

### set overlap threshold
overlap_thresh <- 0.01

### make col for overlaps
fires_merged$merged <- FALSE

### loop through each fire and compare geometries within the same group
for (i in 1:nrow(fires_merged)) {
  for (j in 1:nrow(fires_merged)) {
    if (i != j) {
      # Check if geometries are identical (exact overlap)
      if (isTRUE(st_equals(fires_merged$geometry[i], fires_merged$geometry[j]))) {
        # If geometries are identical, mark them as merged
        fires_merged$merged[i] <- TRUE
        fires_merged$merged[j] <- TRUE
      } else {
        # Otherwise, check for near-perfect overlap based on area
        if (abs(as.numeric(st_area(fires_merged$geometry[i])) - as.numeric(st_area(fires_merged$geometry[j]))) < overlap_thresh) {
          # If the area difference is small and ignition dates are close, mark them as merged
          if (abs(as.numeric(difftime(fires_merged$Ig_Date[i], fires_merged$Ig_Date[j], units = "days"))) <= 20) {
            fires_merged$merged[i] <- TRUE
            fires_merged$merged[j] <- TRUE
          }
        }
      }
    }
  }
}

### merge the geoms for the non-merged fires
fires_merged_final <- fires_merged %>%
  filter(!merged) %>%
  arrange(Ig_Date) %>%
  summarise(
    Ig_Date = first(Ig_Date),  # Keep the first ignition date (or use min/max)
    Event_ID = first(Event_ID), # First Event_ID (or adjust as needed)
    n_fires = n(),
    geometry = st_union(geometry), # Merge geometries
    .groups = "drop")

# Step 6: Optionally, handle merged fires separately (if you'd like to process them)
merged_fires <- adjacent_fires %>%
  filter(merged)

# Step 7: Save the results (if you need to output the merged shapefile)
st_write(fires_merged_final, "E:/fuel_treat/esa_subset/esa_fires_simp_2.shp")
```


#### deal with CBI rasters
```{r}
### lookup table- each row lists Event_IDs that belong to the same group
event_groups <- all_fires %>%
  st_drop_geometry() %>%
  group_by(group_id) %>%
  summarise(event_ids = list(unique(Event_ID)))

### loop over groups and combine rasters
for (i in seq_len(nrow(event_groups))) {
  
  group_id <- event_groups$group_id[i]
  ids <- event_groups$event_ids[[i]]  # Vector of Event_IDs
  
  ### build file paths
  raster_paths <- paste0("E:/fuel_treat/all_fires_cbi/", ids, "_CBI_bc.tif")
  
  ### load rasters
  rasters <- lapply(raster_paths, function(p) {
    if (file.exists(p)) {
      r <- raster(p)
      names(r) <- "CBI_bc"
      return(r)
    } else {
      warning("Missing file: ", p)
      return(NULL)
    }
  })
  
  ### drop missing rasters
  rasters <- Filter(Negate(is.null), rasters)  
  
  ### skip empty groups
  if (length(rasters) == 0) next
  
  ### mosaic the rasters — prioritize non-NA values
  mosaic_fun <- function(x, y) {
    overlay(x, y, fun = function(a, b) ifelse(!is.na(a), a, b))
  }
  
  merged_raster <- Reduce(mosaic_fun, rasters)
  
  ### save to raster
  writeRaster(
    merged_raster,
    filename = paste0("E:/fuel_treat/all_fires_cbi/raster_joined/CBI_group_", group_id, ".tif"),
    format = "GTiff",
    overwrite = TRUE
  )
  
  cat("✔ Saved merged raster for group:", group_id, "\n")
}

```

### Treatment boundaries
```{r}
### open data
setwd("~/data-store/data/iplant/home/kjsiegel/fuel_treat/esa")
fire <- st_read("esa_fires_simp.shp")
fts <- st_read("esa_fts.shp")

### drop fire 412 from dataset because perfect overlap with 411
fire <- fire %>%
  filter(!Event_ID == "412")

### set precision and make valid
fts <- st_set_precision(fts, 1e6) %>% st_make_valid()
fire <- st_set_precision(fire, 1e6) %>% st_make_valid()

# Output list
boundary_polys <- list()

# Loop through each feature in fts
for (i in 1:nrow(fts)) {
  cat("Processing row", i, "\n")  # Optional debug message
  
  polygon_i <- fts[i, ]
  
  contained <- st_within(polygon_i, fire, sparse = FALSE)
  
  if (!FALSE %in% contained) {
    # Fully contained in fire — just keep the polygon itself
    polygon_i <- polygon_i %>%
      dplyr::select(geometry)
    
    if (!is.null(polygon_i) && nrow(polygon_i) > 0 && !all(st_is_empty(polygon_i))) {
      boundary_polys[[i]] <- polygon_i
    }
    
  } else {
    # Fire without this ft
    no_intersect_i <- rmapshaper::ms_erase(fire, fts[i, ])
    
    # Portion of ft inside fire
    use_ft_crop_i <- st_intersection(fts[i, ], fire)
    
    # Clean geometries
    no_intersect_i <- no_intersect_i %>%
      dplyr::select(Event_ID, geometry) %>%
      st_make_valid() %>%
      st_buffer(0)
    
    use_ft_crop_i <- use_ft_crop_i %>%
      dplyr::select(Event_ID = poly_id, geometry) %>%
      st_make_valid() %>%
      st_buffer(0)
    
    # Combine and dissolve
    comb_sf <- rbind(no_intersect_i, use_ft_crop_i) %>%
      st_make_valid() %>%
      st_buffer(0) %>%
      st_set_precision(1e6)
    
    comb_sf_union <- comb_sf %>%
      group_by(Event_ID) %>%
      summarise(geometry = st_union(geometry)) %>%
      ungroup() %>%
      st_make_valid()
    
    # Create inner lines
    inner_line <- try(ms_innerlines(comb_sf_union) %>% st_as_sf(), silent = TRUE)
    
    if (!inherits(inner_line, "try-error") && !is.null(inner_line) &&
        nrow(inner_line) > 0 && !all(st_is_empty(inner_line))) {
      boundary_polys[[i]] <- inner_line
    }
    
    # Check if fire is fully inside ft
    fully_contained <- st_within(fire, fts[i, ], sparse = FALSE)
    
    if (all(fully_contained)) {
      fully_contained_inner_line <- st_difference(fts[i, ], fire)
      
      if (!st_is_empty(fully_contained_inner_line)) {
        if (inherits(st_geometry(fully_contained_inner_line), "sfc_LINESTRING")) {
          fully_contained_inner_line <- st_cast(fully_contained_inner_line, "MULTILINESTRING")
        }
        
        if (inherits(st_geometry(fully_contained_inner_line), "sfc_MULTILINESTRING")) {
          fully_contained_inner_line <- st_line_merge(fully_contained_inner_line)
        }
        
        if (!is.null(fully_contained_inner_line) && !all(st_is_empty(fully_contained_inner_line))) {
          boundary_polys[[i]] <- fully_contained_inner_line
        }
      }
    }
  }
}

# Clean list: remove null or empty entries
boundary_polys_clean <- boundary_polys[!sapply(boundary_polys, function(x) {
  is.null(x) || inherits(x, "try-error") || nrow(x) == 0 || all(st_is_empty(x))
})]

# Combine into one sf object
result <- do.call(rbind, boundary_polys_clean) %>% st_make_valid()

# # View result
# plot(st_geometry(result))

st_write(result,
         "~/data-store/data/iplant/home/kjsiegel/fuel_treat/esa/ft_fire_boundaries_fix_overlap.shp")
```

### clean up sample points
Drop points from fire that is fully contained by treatment
```{r}
### open sample pts
esa <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts.shp")

### remove points in fire_ids 127720 and 127745
esa <- esa %>%
  filter(!fire_id %in% c("127720", "127745"))

### write out
st_write(esa, "E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")
```

## Distance to boundaries
update with code from cyverse
```{r}
### open inner lines
lines_fires <- st_read("E:/fuel_treat/esa_subset/ft_boundaries/inner_lines.shp")

### open sample points
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")

### remove fire CA3320411691620031026 (2003) because it burned over ft previously burned in CA3314611689619930509 (1993)
pts <- pts %>%
  filter(!fire_id == "CA3320411691620031026")

### drop associated inner line
lines_fires <- lines_fires %>%
  filter(!Event_ID == "CA3320411691620031026")

### set up parallels
plan(multisession, workers = 15)

### split into chunks
pts_chunks <- split(pts,
                   sort(rank(1:nrow(pts)) %% future::nbrOfWorkers()))

### function for each chunk
process_chunk <- function(pts_chunk) {
  
  ### function for each worker
  get_dist_df <- function(pt_i) {
    line_i <- lines_fires %>%
      filter(Event_ID %in% pt_i$fire_id)

    if (nrow(line_i) == 0) {
      return(data.frame(uid = pt_i$uid, dist_bound = NA_real_))
    }

    dist_i <- st_distance(pt_i, line_i)

    return(data.frame(uid = pt_i$uid, dist_bound = as.numeric(dist_i)))
  }

  ### apply function to each row in each chunk
  results <- lapply(1:nrow(pts_chunk), function(i) {
    get_dist_df(pts_chunk[i, ])
  })

  ### combine results from this chunk
  do.call(rbind, results)
}

### run function on each chunk in parallel
dist_list <- future_lapply(pts_chunks, process_chunk)

### combine all chunks into final data frame
dist_df <- do.call(rbind, dist_list)

### save
write_csv(dist_df,
         "~/data-store/data/iplant/home/kjsiegel/fuel_treat/esa/pts_dist.csv")
```

#### clean up distances
```{r}
### open cyverse output
pts_dist <- read.csv("E:/fuel_treat/covars/pts_dist.csv")

### drop dups
pts_dist <- distinct(pts_dist)

### keep minimum distance (7528390)
pts_dist <- pts_dist %>%
  arrange(dist_bound) %>%
  group_by(uid) %>%
  slice_min(order_by = dist_bound, n = 1) %>%
  ungroup()

### write out
write_csv(pts_dist, "E:/fuel_treat/covars/pts_dist_min.csv")

### combine with pts attributes
pts_att <- merge(x = pts,
                 y = pts_dist,
                 by = "uid",
                 all.x = TRUE)

### check out NA distances
dist_na <- pts_att %>%
  filter(is.na(dist_bound))

### write out missing distances
st_write(dist_na,
         "E:/fuel_treat/esa_dist_missing.shp")

### write out distances we have
st_write(pts_att,
         "E:/fuel_treat/covars/esa_pts_dist_min.shp")

test <- pts_att %>% filter(fire_id == "WA4624311735619970811")
st_write(test,
         "E:/fuel_treat/covars/esa_pts_dist_min_test.shp")
```

##### understand missing distances
```{r}
### open pts with missing distances
dist_na <- st_read("E:/fuel_treat/esa_dist_missing.shp")

##### need to harmonize fires and then re-run
### 128668 in pretty much entirely inside OR4530512138720070712 and ignition date within 2 days of each other. distances ran for 128668 but not for OR4530512138720070712 -- need to run for OR4530512138720070712
### 2091 contained by CA4095112320220060902 and occurred after --> drop 2091 and re-do boundaries for the treatment, then recalculate distances
### 136922 mostly contained by ID4355611124820160823 with ignition date within about 4 days. Distance points ran for 136922 but not ID4355611124820160823

##### need to re-run for part of fire (because combined adjacent fires)
### 115264: ft contained by fire, part of fire didn't calculate distances --> re-run  [diff fires/fts]
### part of 146803 is missing distance for points [diff fires/fts]
### part of 96707 is missing distance for points [diff fires/fts]
### part of 96707 is missing distance for points [diff fires/fts]
### part of 146388 is missing distance for points [diff fires/fts]
### part of 172929 is missing distance for points [diff fires/fts]
### part of 130719 missing [diff fires/fts]
### 171512 missing distance for some pts [diff fires/fts]
### 170789 missing distance for some pts [diff fires/fts]
### 172929 missing distance for some pts [diff fires/fts]

##### to drop
### 142201 completely contained by ft -- drop
### 142599 completely contained by ft -- drop
### 142757 completely contained by ft -- drop
### 142755 completely contained by ft -- drop
### 13333 contained by ft -- drop
### 13011 contained by ft -- drop
### 147525 contained by ft -- drop
### 138225 contained by ft -- drop
### 138297 contained by ft -- drop
### 137074 contained by ft -- drop
### 130782 (3/31/2021) contained by ft -- drop
### 130798 (8/20/2006) contained by ft -- drop
### 130497 contained by ft -- drop
### 130228 contained by ft -- drop
### 129984 contained by ft -- drop
### 128885 contained by ft -- drop
### 129087 contained by ft -- drop
### 129127 contained by ft -- drop
### 128297 contained by ft -- drop
### 176951 contained by ft -- drop
### 2823 mostly contained by CA4045212284620080621 and ignition date within a few weeks -- drop 2823
### 13403 mostly inside AZ3449111148820150606 and ignition date within 8 days -- drop 13403
### 138570 didn't really burn (MODIS corners) -- drop
### 174804 mostly contained by ID4663111491320120822 and ignition date 13 days apart -- drop 174804
### CA3314611689619930509 in 1993 and CA3320411691620031026 in 2003. CA3314611689619930509 burned part of ft but not all. drop CA3320411691620031026 because complication of reburn

```

##### fix missing distances
```{r}
### open sample points
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")

### open inner lines
lines_fires <- st_read("E:/fuel_treat/esa_subset/ft_boundaries/inner_lines.shp")

### drop fires identified before
pts <- pts %>%
  filter(!fire_id %in% c("142201", "142599", "142757", "142755", "13333",
                         "13011", "147525", "138225", "138297", "137074",
                         "130782", "130798", "130497", "130228", "129984",
                         "128885", "129087", "129127", "128297", "176951",
                         "2823", "13403", "138570", "174804", "CA3320411691620031026"))
```

###### fires that need to be harmonized
```{r}
### 128668 in pretty much entirely inside OR4530512138720070712 and ignition date within 2 days of each other. distances ran for 128668 but not for OR4530512138720070712 -- need to run for OR4530512138720070712
oreg_453_pts <- pts %>% filter(fire_id == "OR4530512138720070712")

### subset lines_fires
line_oreg_453 <- lines_fires %>% 
  filter(Event_ID == "128668") %>%
  filter(line_id == 38)

### distance function
get_dist_df <- function(pt_i) {
  dist_i <- st_distance(pt_i, line_oreg_453)
  return(data.frame(uid = pt_i$uid, dist_bound = as.numeric(dist_i)))
}

### apply function to each row in each chunk
results <- lapply(1:nrow(oreg_453_pts), function(i) {
  get_dist_df(oreg_453_pts[i, ])
})

### combine results from this chunk
results_df_oreg_453 <- do.call(rbind, results)

### 136922 mostly contained by ID4355611124820160823 with ignition date within about 4 days. Distance points ran for 136922 but not ID4355611124820160823
idah_435_pts <- pts %>% filter(fire_id == "ID4355611124820160823")

### subset lines_fires
line_idah_435 <- lines_fires %>% 
  filter(Event_ID == "136922") %>%
  filter(line_id == 132)

### distance function
get_dist_df <- function(pt_i) {
  dist_i <- st_distance(pt_i, line_idah_435)
  return(data.frame(uid = pt_i$uid, dist_bound = as.numeric(dist_i)))
}

### apply function to each row in each chunk
results <- lapply(1:nrow(idah_435_pts), function(i) {
  get_dist_df(idah_435_pts[i, ])
})

### combine results from this chunk
results_df_idah_435 <- do.call(rbind, results)

### 2091 contained by CA4095112320220060902 and occurred after --> drop 2091 and re-do boundaries for the treatment, then recalculate distances
cali_409_pts <- pts %>% filter(fire_id == "CA4095112320220060902")

# st_write(cali_409_pts,
#          "E:/fuel_treat/esa_subset/ft_boundaries/cali_409_pts_new.shp")

### open cali results from cyverse
cali_409_pts <- read.csv("E:/fuel_treat/covars/dist_cali_409.csv")

### open pts dist
pts_dist <- read.csv("E:/fuel_treat/covars/pts_dist_min.csv")

### combine
rerun_fires <- rbind(cali_409_pts,
                     results_df_idah_435,
                     results_df_oreg_453)

### drop those fires from pts
pts_dist <- pts_dist %>%
  filter(!uid %in% rerun_fires$uid)

### combine
pts_dist <- rbind(pts_dist, 
                  rerun_fires)

### write out
write_csv(pts_dist, 
          "E:/fuel_treat/covars/pts_dist_min_fix.csv")

# ### open fires and fts
# fires <- st_read("E:/fuel_treat/esa_subset/esa_fires_simp.shp") %>%
#   filter(., Event_ID == "CA4095112320220060902")
# fts <- st_read("E:/fuel_treat/esa_subset/esa_fts.shp") %>%
#   filter(., Event_ID == "CA4095112320220060902")
# 
# # ggplot() +
# #   geom_sf(data = fires, color = "blue", fill = "lightblue") +
# #   geom_sf(data = fts, color = "red")
# 
# ### set precision and make valid
# fts <- st_set_precision(fts, 1e6) %>% st_make_valid()
# fires <- st_set_precision(fires, 1e6) %>% st_make_valid()
# 
# ### output list
# boundary_polys <- list()
# 
# ### loop through each feature in fts
# for (i in 1:nrow(fts)) {
#   cat("Processing row", i, "\n") 
#   
#   polygon_i <- fts[i, ]
#   
#   contained <- st_within(polygon_i, fires, sparse = FALSE)
#   
#   if (!FALSE %in% contained) {
#     
#     ### fully contained in fire — just keep the polygon itself
#     polygon_i <- polygon_i %>%
#       dplyr::select(geometry)
#     
#     if (!is.null(polygon_i) && nrow(polygon_i) > 0 && !all(st_is_empty(polygon_i))) {
#       boundary_polys[[i]] <- polygon_i
#     }
#     
#   } else {
#     
#     ### fire without this ft
#     no_intersect_i <- rmapshaper::ms_erase(fires, fts[i, ])
#     
#     ### portion of ft inside fire
#     use_ft_crop_i <- st_intersection(fts[i, ], fires)
#     
#     ### clean geometries
#     no_intersect_i <- no_intersect_i %>%
#       dplyr::select(Event_ID, geometry) %>%
#       st_make_valid() %>%
#       st_buffer(0)
#     
#     use_ft_crop_i <- use_ft_crop_i %>%
#       dplyr::select(Event_ID = poly_id, geometry) %>%
#       st_make_valid() %>%
#       st_buffer(0)
#     
#     ### combine and dissolve
#     comb_sf <- rbind(no_intersect_i, use_ft_crop_i) %>%
#       st_make_valid() %>%
#       st_buffer(0) %>%
#       st_set_precision(1e6)
#     
#     comb_sf_union <- comb_sf %>%
#       group_by(Event_ID) %>%
#       summarise(geometry = st_union(geometry)) %>%
#       ungroup() %>%
#       st_make_valid()
#     
#     ### create inner lines
#     inner_line <- try(ms_innerlines(comb_sf_union) %>% st_as_sf(), silent = TRUE)
#     
#     if (!inherits(inner_line, "try-error") && !is.null(inner_line) &&
#         nrow(inner_line) > 0 && !all(st_is_empty(inner_line))) {
#       boundary_polys[[i]] <- inner_line
#     }
#     
#     ### check if fire is fully inside ft
#     fully_contained <- st_within(fires, fts[i, ], sparse = FALSE)
#     
#     if (all(fully_contained)) {
#       fully_contained_inner_line <- st_difference(fts[i, ], fires)
#       
#       if (!st_is_empty(fully_contained_inner_line)) {
#         if (inherits(st_geometry(fully_contained_inner_line), "sfc_LINESTRING")) {
#           fully_contained_inner_line <- st_cast(fully_contained_inner_line, "MULTILINESTRING")
#         }
#         
#         if (inherits(st_geometry(fully_contained_inner_line), "sfc_MULTILINESTRING")) {
#           fully_contained_inner_line <- st_line_merge(fully_contained_inner_line)
#         }
#         
#         if (!is.null(fully_contained_inner_line) && !all(st_is_empty(fully_contained_inner_line))) {
#           boundary_polys[[i]] <- fully_contained_inner_line
#         }
#       }
#     }
#   }
# }
# 
# ### remove null or empty entries
# boundary_polys_clean <- boundary_polys[!sapply(boundary_polys, function(x) {
#   is.null(x) || inherits(x, "try-error") || nrow(x) == 0 || all(st_is_empty(x))
# })]
# 
# ### combine into sf
# result_lines <- do.call(rbind, boundary_polys_clean) %>% st_make_valid()
# 
# ### add cols
# result_lines <- result_lines %>%
#   mutate(line_id = NA,
#          Event_ID = NA)
# result_lines$line_id <- "399"
# result_lines$Event_ID <- "CA4095112320220060902"
# result_lines <- result_lines %>%
#   dplyr::select(line_id, Event_ID, geometry)
# 
# ### combine with the rest of the inner lines
# lines_fires <- rbind(lines_fires, result_lines)
# 
# ### write out
# st_write(lines_fires,
#          "E:/fuel_treat/esa_subset/ft_boundaries/inner_lines.shp",
#          append = FALSE)

### subset lines
line_cali_409 <- lines_fires %>% 
  filter(Event_ID == "CA4095112320220060902") %>%
  filter(line_id == "399")

### distance function
get_dist_df <- function(pt_i) {
  dist_i <- st_distance(pt_i, result_lines)
  return(data.frame(uid = pt_i$uid, dist_bound = as.numeric(dist_i)))
}

### parallelize
plan(multisession, workers = 5)

chunk_size <- 1000
n_chunks <- ceiling(nrow(cali_409_pts) / chunk_size)

for (k in 1:n_chunks) {
  idx <- ((k - 1) * chunk_size + 1):min(k * chunk_size, nrow(cali_409_pts))
  chunk <- cali_409_pts[idx, ]
  
  chunk_result <- future_lapply(1:nrow(chunk), function(i) {
    get_dist_df(chunk[i, ])
  })

  chunk_df <- data.table::rbindlist(chunk_result)
  data.table::fwrite(chunk_df, paste0("results_chunk_", k, ".csv"))
}

# ### apply function to each row in each chunk
# results <- future_lapply(1:nrow(cali_409_pts), function(i) {
#   get_dist_df(cali_409_pts[i, ])
# })
# 
# ### combine results from this chunk
# results_df_cali_409 <- do.call(rbind, results)

```
###### fires to re-run
Fires where part of the fire didn't run -- likely because I combined adjacent fires and something got messed up with the fire_id in the inner_lines sjp
```{r}
##### need to re-run for part of fire (because combined adjacent fires)
### 115264: ft contained by fire, part of fire didn't calculate distances --> re-run  [diff fires/fts]
### part of 146803 is missing distance for points [diff fires/fts]
### part of 96707 is missing distance for points [diff fires/fts]
### part of 146388 is missing distance for points [diff fires/fts]
### part of 172929 is missing distance for points [diff fires/fts]
### part of 130719 missing [diff fires/fts]
### 171512 missing distance for some pts [diff fires/fts]
### 170789 missing distance for some pts [diff fires/fts]

### open inner lines
lines_fires <- st_read("E:/fuel_treat/esa_subset/ft_boundaries/inner_lines.shp")

### open sample points
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp") %>%
  filter(., fire_id %in% c("115264", "146803", "96707", "146388",
                           "172929", "130719", "171512", "170789"))

### get nearest feature
nearest_line <- st_nearest_feature(pts, lines_fires)

# Extract the nearest line geometries or rows
nearest_line <- lines_fires[nearest_line, ]

### drop geom
st_geometry(nearest_line) <- NULL

### add to points
pts_lines <- cbind(pts, nearest_line)

### set up parallels
plan(multisession, workers = 8)

### split into chunks
pts_chunks <- split(pts_lines,
                   sort(rank(1:nrow(pts_lines)) %% future::nbrOfWorkers()))

### function for each chunk
process_chunk <- function(pts_chunk) {
  
  ### function for each worker
  get_dist_df <- function(pt_i) {
    line_i <- lines_fires %>%
      filter(line_id %in% pt_i$line_id)

    if (nrow(line_i) == 0) {
      return(data.frame(uid = pt_i$uid, dist_bound = NA_real_))
    }

    dist_i <- st_distance(pt_i, line_i)

    return(data.frame(uid = pt_i$uid, dist_bound = as.numeric(dist_i)))
  }

  ### apply function to each row in each chunk
  results <- lapply(1:nrow(pts_chunk), function(i) {
    get_dist_df(pts_chunk[i, ])
  })

  ### combine results from this chunk
  do.call(rbind, results)
}

### run function on each chunk in parallel
dist_list <- future_lapply(pts_chunks, process_chunk)

### combine all chunks into final data frame
dist_df <- do.call(rbind, dist_list)

### open the other fixed pts
pts_dist <- read.csv("E:/fuel_treat/covars/pts_dist_min_fix.csv")

### drop fixed uids
pts_dist <- pts_dist %>%
  filter(!uid %in% dist_df$uid)

### combine
dist_all <- rbind(pts_dist, dist_df)

### save
write_csv(dist_all,
         "E:/fuel_treat/covars/pts_dist_min_fix_full.csv")
```

## Points on ft boundaries
Don't want to include points whose pixels straddle the boundaries
```{r}
### open distance from pts to nearest boundary file
dist_bound <- read_csv("E:/fuel_treat/covars/pts_dist_min_fix_full.csv")

### subset to pts that are close to the nearest boundary, as these are the points likely to be on the boundary. Since each pixel is 30 x 30, the furthest a point could be from the boundary and still be inside the pixel that's crossed by the boundary is sqrt(1800). Use a slightly bigger number just for wiggle room
dist_bound <- dist_bound %>%
  filter(dist_bound < 60)

### open pts shp and restrict to pts close to boundary
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp") %>%
  filter(.,
         uid %in% dist_bound$uid)

### convert pts to squares
pts <- pts %>%
  st_buffer(dist = 15,
            endCapStyle = "SQUARE")

### open boundaries
lines_fires <- st_read("E:/fuel_treat/esa_subset/ft_boundaries/inner_lines.shp") %>%
  mutate(., poly_id = row_number())

### check for overlaps
overlap_pts <- st_intersection(pts, lines_fires)

### drop geom
st_geometry(overlap_pts) <- NULL

### column for overlap
overlap_pts <- overlap_pts %>%
  mutate(overlap_bound = "overlap") %>%
  dplyr::select(uid, overlap_bound) %>%
  distinct()

### open full pts shp 
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp") 

### drop geom
st_geometry(pts) <- NULL

### merge
pts <- merge(x = pts,
             y = overlap_pts,
             by = "uid",
             all.x = TRUE)

### change NAs
pts$overlap_bound[is.na(pts$overlap_bound)] <- "nonoverlap"

### write out
write_csv(pts,
          "E:/fuel_treat/esa_subset/pts_overlap_status.csv")
```

## Points on fire boundaries
Don't want to include points whose pixels straddle the fire boundary
```{r}
### open pts shp and restrict to pts close to boundary
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp") 

### convert pts to squares
pts <- pts %>%
  st_buffer(dist = 15,
            endCapStyle = "SQUARE")

### get fires
mt <- st_read("E:/fuel_treat/esa_subset/esa_fires_simp_fix.shp") %>%
  filter(., Event_ID %in% pts$fire_id)

### output
outer_bound <- list()

### loop
for (i in 1:nrow(mt)) {
  
  ### get fire
  temp_fire <- mt[i, ]
  
  ### get pts
  temp_pts <- pts %>%
    filter(fire_id %in% temp_fire)
  
  ### get overlap
  temp_over <- st_intersection(temp_pts, temp_fire)
  
  ### store
  outer_bound[[i]] <- temp_over
  
  ### clean 
  rm(temp_pts, temp_over)
  gc()
  
}

### combine
outer_bound_pts <- do.call(rbind, outer_bound)

### calculate area
outer_bound_pts$pix_area <- st_area(outer_bound_pts)

### drop pts whose pixels are not fully contained
full_pix <- outer_bound_pts %>%
  mutate(pix_area = as.numeric(pix_area)) %>%
  filter(pix_area > 899.999999999)

### drop geom
st_geometry(full_pix) <- NULL

### clean
rm(outer_bound, outer_bound_pts)
gc()

### simplify full_pix for merge
full_pix <- full_pix %>%
  dplyr::select(uid, pix_area) %>%
  mutate(in_fire = "inside")

### drop pts geom
st_geometry(pts) <- NULL

### merge with full pts
pts <- merge(x = pts,
             y = full_pix,
             by = "uid",
             all.x = TRUE)

### change NAs
pts$in_fire[is.na(pts$in_fire)] <- "not_inside"

### simplify
pts <- pts %>%
  dplyr::select(uid, in_fire)

### write out
write_csv(pts,
          "E:/fuel_treat/esa_subset/pts_within_fire_status.csv")

# check <- bound_polys_all %>% filter(poly_id %in% c(14, 15, 16))
# check_pts <- pts %>% filter(uid == "ID4485611430720180802_212424")
# ggplot() + geom_sf(data = check) + geom_sf(data = check_pts, color = "red", fill = NA)
```

### Combine pt boundary info
```{r}
### open pts on ft boundaries
ft_pts <- read.csv("E:/fuel_treat/esa_subset/pts_overlap_status.csv")

### open pts on fire boundaries
fire_pts <- read.csv("E:/fuel_treat/esa_subset/pts_within_fire_status.csv")

### combine
ft_fire <- merge(x = ft_pts,
                 y = fire_pts,
                 by = "uid",
                 all = TRUE)

### clean up
rm(ft_pts, fire_pts)
gc()

### open pts shp
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")

### simplify ft_fire
ft_fire <- ft_fire %>%
  dplyr::select(uid, overlap_bound, in_fire)

### merge with pts
pt_status <- merge(x = pts,
                   y = ft_fire,
                   by = "uid",
                   all = TRUE)

### write out
st_write(pt_status,
         "E:/fuel_treat/esa_subset/pt_status.shp")
st_write(pt_status,
         "E:/fuel_treat/esa_subset/pt_status.gpkg")
```
#### subset for terraclimate
only run climate extraction for pts that aren't on boundaries
```{r}
### restrict pts -- drop pts on ft-fire boundary and fire boundary
pt_keep <- pt_status %>%
  filter(overlap_bound == "nonoverlap") %>%
  filter(in_fire == "inside")
### drops ~200,000 pts

### write out
st_write(pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee.shp")


### what I need for GEE
# uid = unique identifier for each sample point
# fire_yr = year fire burned (the same for all points in a given fire)
# Ig_Date = date fire began (the same for all points in a given fire)
# dt_brnd = the date each individual pixel burned

### open 
pt_keep <- st_read("E:/fuel_treat/esa_subset/pt_gee.shp")

### simplify cols for GEE
pt_keep <- pt_keep %>%
  dplyr::select(uid, 
                fire_yr,
                Ig_Date = ig_date, 
                geometry)

### try with just fires before 2001
test <- pt_keep %>% filter(fire_yr < 2001)
### write out
st_write(test,
         "E:/fuel_treat/esa_subset/pt_gee_1.shp")

### fires from 2000-2005
test_pt_keep <- pt_keep %>%
  filter(fire_yr > 2000 & fire_yr < 2006)
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_2.shp")

### fires from 2006, ignition date 2006-09-02
test_pt_keep <- pt_keep %>%
  filter(fire_yr == 2006 & Ig_Date == "2006-09-02")
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_3.shp")

### fires from 2006, ignition date NOT 2006-09-02
test_pt_keep <- pt_keep %>%
  filter(fire_yr == 2006) %>%
  filter(!Ig_Date == "2006-09-02")
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_4.shp")

### fires from 2007-2010
test_pt_keep <- pt_keep %>%
  filter(fire_yr > 2006 & fire_yr < 2011)
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_5.shp")

### fires from 2011-2015
test_pt_keep <- pt_keep %>%
  filter(fire_yr > 2010 & fire_yr < 2016)
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_6.shp")

### after 2015
test_pt_keep <- pt_keep %>%
  filter(fire_yr > 2015)
st_write(test_pt_keep,
         "E:/fuel_treat/esa_subset/pt_gee_7.shp")
```


## Covariates
### topography
#### TPI
```{r}
### get tpi file pattern
tpi_files <- list.files(path = "E:/fuel_treat/covars/tpi",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them
tpi_files <- lapply(tpi_files, read.csv)

### combine
tpi_files <- do.call("rbind", tpi_files)

### clean cols
tpi_files <- tpi_files %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, tpi = elevation)

### write out
write_csv(tpi_files, "E:/fuel_treat/covars/tpi.csv")
```

#### DEM
Extracted in GEE. Need to convert aspect to SRAI
Source: USGS 3DEP 10m National Map Seamless (1/3 Arc-Second) https://developers.google.com/earth-engine/datasets/catalog/USGS_3DEP_10m  
```{r}
### get file list
dem_files <- list.files(path = "E:/fuel_treat/covars/dem",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them all
dem_all <- lapply(dem_files, read_csv)

### combine
dem_all <- bind_rows(dem_all)

### drop rows I don't care about
dem_all <- dem_all %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, elevation, slope, aspect)

### convert aspect to SRAI
### SRAI = 1 - cos((pi/180)(aspect-30) ) / 2
dem_all <- dem_all %>%
  mutate(asp_rad = pi/180 * (aspect-30),
         aspect_srai_2 = 1 - cos(asp_rad),
         aspect_srai = aspect_srai_2/2) %>%
  dplyr::select(-asp_rad,
                -aspect_srai_2)

### write out
write_csv(dem_all,
          "E:/fuel_treat/covars/dem.csv")
```

### Pre-fire land cover (LCMAP)
1: developed  
2: cropland  
3: grass/shrub  
4: tree cover: tree cover density > 10%  
5: water  
6: wetland  
7: ice/snow  
8: barren: soil, sand, clearcuts
```{r}
### get file list
lcmap_files <- list.files(path = "E:/fuel_treat/covars/lcmap",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them all
lcmap_all <- lapply(lcmap_files, read_csv)

### combine
lcmap_all <- bind_rows(lcmap_all)

### drop columns I don't care about
lcmap_all <- lcmap_all %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, landcover)

### make landcover df
landcover_df <- data.frame(landcover = c(1:8),
                           lc_type = c("developed", "cropland",
                                       "grass_shrub", "treecover",
                                       "water", "wetland",
                                       "ice_snow", "barren"))

### add landcover type 
lcmap_legend <- merge(lcmap_all,
                   landcover_df,
                   by = "landcover",
                   all = TRUE)

### write out
write_csv(lcmap_legend,
          "E:/fuel_treat/covars/lcmap.csv")
```

## Vegetation indices
Use pre-fire growing season 
Growing season definitions:
- Oregon: April 1 to October 31 (Perry & Oetter 2024, https://doi.org/10.1002/ecs2.4865)
- Colorado: April to September (Carroll et al. 2021, https://doi.org/10.1002/ecs2.3414)

```{r}
### prep data for GEE

### open sample points
esa <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts.shp")

### add month
esa <- esa %>%
  mutate(ig_month = month(ig_date))

### assign growing year
### if a fire started January-September, use the previous calendar year
### if a fire started in October-December, use the fire_year, as the fire occurred post-growing season
esa <- esa %>%
  mutate(grow_yr = ifelse(ig_month < 10,
                          year_prior, fire_year))

### write out
st_write(esa, 
         "E:/fuel_treat/esa_subset/esa_sample_pts_veg.shp")
```

### NDVI (pre-fire)
Check range. Should be -1 to 1
https://eos.com/make-an-analysis/ndmi/:
-1 to -0.1 (negative values) usually signal non-vegetated surfaces like open water, snow, or thick cloud cover;
0 to 0.1 (low values) are typical for bare soil, rocky areas, or deserts — lands with little to no photosynthetic activity;
0.2 to 0.5 (moderate values) suggest sparse or stressed vegetation. Grasslands, shrubs, meadows, and fields under drought or entering dormancy often fall into this range;
0.6 to 1 (high values) point to lush, healthy vegetation, such as dense crop canopies or mature forests.
```{r}
### get ndmi file pattern
ndvi_files <- list.files(path = "E:/fuel_treat/covars/ndvi",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them
ndvi_files <- lapply(ndvi_files, read.csv)

### combine
ndvi_files <- do.call("rbind", ndvi_files)

### clean cols
ndvi_files <- ndvi_files %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, ndvi = mean_gs_ndvi)

### write out
write_csv(ndvi_files, "E:/fuel_treat/covars/ndvi.csv")
```


### NDMI (pre-fire)
Normalized Difference Moisture Index (range: -1 to 1)
https://eos.com/make-an-analysis/ndmi/:
-1 to -0.8 Bare soil,
-0.8 to -0.6 Almost absent canopy cover,
-0.6 – -0.4 Very low canopy cover,
-0.4 – -0.2 Low canopy cover, dry or very low canopy cover, wet,
-0.2 – 0 Mid-low canopy cover, high water stress or low canopy cover, low water stress,
0 – 0.2 Average canopy cover, high water stress or mid-low canopy cover, low water stress,
0.2 – 0.4 Mid-high canopy cover, high water stress or average canopy cover, low water stress,
0.4 – 0.6 High canopy cover, no water stress,
0.6 – 0.8 Very high canopy cover, no water stress,
0.8 – 1 Total canopy cover, no water stress/waterlogging
```{r}
### get ndmi file pattern
ndmi_files <- list.files(path = "E:/fuel_treat/covars/ndmi",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them
ndmi_files <- lapply(ndmi_files, read.csv)

### combine
ndmi_files <- do.call("rbind", ndmi_files)

### clean cols
ndmi_files <- ndmi_files %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, ndmi = mean_gs_ndmi)

### write out
write_csv(ndmi_files, "E:/fuel_treat/covars/ndmi.csv")
```

### EVI (pre-fire)
Enhanced veg index (range -1 to 1, healthy veg = 0.2-0.8)
```{r}
### get evi file pattern
evi_files <- list.files(path = "E:/fuel_treat/covars/evi",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them
evi_files <- lapply(evi_files, read.csv)

### combine
evi_files <- do.call("rbind", evi_files)

### clean cols
evi_files <- evi_files %>%
  dplyr::select(uid, fire_id, fire_year, year_prior,
                CBI_bc, evi = mean_gs_evi)

### write out
write_csv(evi_files, "E:/fuel_treat/covars/evi.csv")
```

## Climate 
chunks that failed to export in GEE (Error: Computed value is too large. (Error code: 3)):
- pts_3 chunk 3, chunk 4
- pts_7 chunk 1, 2, 5
### figure out which ones are missing from GEE
```{r}
############################
### chunk 3
############################
### open original chunks
pts_3 <- st_read("E:/fuel_treat/esa_subset/pt_gee_3.shp")

### get file list for 3
pts_3_files <- list.files(path = "E:/fuel_treat/covars/terraclimate",
                        pattern = "^TerraClimateExtracted_3_.*\\.csv$",
                        full.names = TRUE)

### open them
pts_3_files <- lapply(pts_3_files, read.csv)

### combine
pts_3_files <- do.call("rbind", pts_3_files)

### get pts that are still missing
pts_3_still <- pts_3 %>%
  filter(!uid %in% pts_3_files$uid)

### write them out
st_write(pts_3_still,
         "E:/fuel_treat/esa_subset/pt_gee_8.shp")

### clean up
rm(pts_3, pts_3_files, pts_3_still)
gc()

############################
### chunk 7
############################
### open original chunks
pts_7 <- st_read("E:/fuel_treat/esa_subset/pt_gee_7.shp")

### get file list for 3
pts_7_files <- list.files(path = "E:/fuel_treat/covars/terraclimate",
                        pattern = "^TerraClimateExtracted_7_.*\\.csv$",
                        full.names = TRUE)

### open them
pts_7_files <- lapply(pts_7_files, read.csv)

### combine
pts_7_files <- do.call("rbind", pts_7_files)

### get pts that are still missing
pts_7_still <- pts_7 %>%
  filter(!uid %in% pts_7_files$uid)

### write them out
st_write(pts_7_still,
         "E:/fuel_treat/esa_subset/pt_gee_9.shp")

### clean up
rm(pts_3, pts_3_files, pts_3_still)
gc()
```

#### notes from Steve:
allclimatedata.csv

Contains a row for each provided sample points (rows), and columns for weather data from terraclimate and gridmet

Columns:
- uid: the unique point id from the original provided sample points
- XXXX_lag_Y: terraclimate variable XXXX at month lag Y, based on the burn date for the sample point. lag 0 is the month containing the burn date in the original sample point asset, lag 11 is 11 months prior (so we have 12 months total).
- remaining columns are the requested bands from gridmet on the burn date for the sample point.

Note on units:
Values are extracted directly from the Earth Engine assets and are not transformed to be in comparable units across data sources. 
Given that the units are different, these will need to be transformed before use/comparison. For example, terraclimate has temperatures
in units of 0.1 degrees C (e.g., a value of 254 is 25.4C), while gridmet has temps in deg K.

Links to info on band units
- https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands
- https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_GRIDMET#bands

Note on invalid sample points in original asset: some of the sample points in the original asset file (25,755) appeared to have a null burn date and so were dropped, as the absence of a burn date precluded proper selection of weather assets.
#### steve's code to merge chunks
```{r}
### function to load files
load_dir_files = function(dir) {
  return(rbindlist(
           lapply(list.files(dir), 
                  FUN=function(f) {
                     return(fread(paste0(dir, f)))
                  }
           )
        )
  )
}

### open all terraclimate data
all_tc <- load_dir_files("E:/fuel_treat/covars/terraclimate/")

### write out
fwrite(all_tc, "E:/fuel_treat/covars/terraclimate.csv")
```
#### climate summaries
```{r}
### open pts
pts_all <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")

### get ig_date
st_geometry(pts_all) <- NULL
pts_all <- pts_all %>%
  dplyr::select(uid, ig_date, year = fire_year) %>%
  mutate(month = month(ig_date))

### open tc data
all_tc <- read.csv("E:/fuel_treat/covars/terraclimate.csv")

### merge 
pts_tc <- merge(x = pts_all,
                y = all_tc,
                by = "uid",
                all = TRUE)

### clean up
rm(all_tc, pts_all)

### range of ignition months
table(pts_tc$month)
# 1       3       4       5       6       7       8       9      10      11      12 
# 351    3965   15420  297325  787817 1094961 1819105  767972  566516    9852     758 

###################################################
### work with january fires
pts_tc_jan <- pts_tc %>%
  filter(month < 2)

### lag_0 = jan
### lag_1 = dec
### lag_2 = nov
### lag_3 = oct
### lag_4 = sep
### lag_5 = aug
### lag_6 = jul
### lag_7 = jun
### lag_8 = may
### lag_9 = apr
### lag_10 = mar
### lag_11 = feb

### make long
pts_tc_jan_long <- pts_tc_jan %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_jan_long <- pts_tc_jan_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number %in% c("0", "1"), "winter",
                         ifelse(lag_number %in% c("2", "3", "4"), "fall",
                                ifelse(lag_number %in% c("5", "6", "7"), "summer",
                                       ifelse(lag_number %in% c("8", "9", "10"),
                                              "spring", "misc")))))

### get seasonal metrics
pts_tc_jan_summ <- pts_tc_jan_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

rm(pts_tc_jan, pts_tc_jan_long)
gc()

### write out
write_csv(pts_tc_jan_summ, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_jan.csv")

rm(pts_tc_jan_summ)
gc()

###################################################
### work with march fires
pts_tc_mar <- pts_tc %>%
  filter(month == 3)

### lag_0 = mar
### lag_1 = feb
### lag_2 = jan
### lag_3 = dec
### lag_4 = nov
### lag_5 = oct
### lag_6 = sep
### lag_7 = aug
### lag_8 = jul
### lag_9 = jun
### lag_10 = may
### lag_11 = apr

### make long
pts_tc_mar_long <- pts_tc_mar %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_mar_long <- pts_tc_mar_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number %in% c("1", "2", "3"), "winter",
                         ifelse(lag_number %in% c("4", "5", "6"), "fall",
                                ifelse(lag_number %in% c("7", "8", "9"), "summer",
                                       ifelse(lag_number %in% c("10", "11"),
                                              "spring", "misc")))))

### get seasonal metrics
pts_tc_mar_summ <- pts_tc_mar_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

### write out
write_csv(pts_tc_mar_summ, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_mar.csv")

rm(pts_tc_mar, pts_tc_mar_long, pts_tc_mar_summ)
gc()

###################################################
### work with april fires
pts_tc_apr <- pts_tc %>%
  filter(month == 4)

### lag_0 = apr
### lag_1 = mar
### lag_2 = fed
### lag_3 = jan
### lag_4 = dec
### lag_5 = nov
### lag_6 = oct
### lag_7 = sep
### lag_8 = aug
### lag_9 = jul
### lag_10 = jun
### lag_11 = may

### make long
pts_tc_apr_long <- pts_tc_apr %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_apr_long <- pts_tc_apr_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number %in% c("0", "1"), "spring",
                         ifelse(lag_number %in% c("2", "3", "4"), "winter",
                                ifelse(lag_number %in% c("5", "6", "7"), "fall",
                                       ifelse(lag_number %in% c("8", "9", "10"),
                                              "summer", "misc")))))

### get seasonal metrics
pts_tc_apr_summ <- pts_tc_apr_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

write_csv(pts_tc_apr_summ, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_apr.csv")

rm(pts_tc_apr, pts_tc_apr_long, pts_tc_apr_summ)
gc()

###################################################
### work with may fires
pts_tc_may <- pts_tc %>%
  filter(month == 5)

### lag_0 = may
### lag_1 = apr
### lag_2 = mar
### lag_3 = fed
### lag_4 = jan
### lag_5 = dec
### lag_6 = nov
### lag_7 = oct
### lag_8 = sep
### lag_9 = aug
### lag_10 = jul
### lag_11 = jun

### make long
pts_tc_may_long <- pts_tc_may %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_may_long <- pts_tc_may_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number %in% c("0", "1", "2"), "spring",
                         ifelse(lag_number %in% c("3", "4", "5"), "winter",
                                ifelse(lag_number %in% c("6", "7", "8"), "fall",
                                       ifelse(lag_number %in% c("9", "10", "11"),
                                              "summer", "misc")))))

### get seasonal metrics
pts_tc_may_summ <- pts_tc_may_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

rm(pts_tc_may, pts_tc_may_long)
gc()

###################################################
### work with june fires
pts_tc_jun <- pts_tc %>%
  filter(month == 6)

### lag_0 = jun
### lag_1 = may
### lag_2 = apr
### lag_3 = mar
### lag_4 = fed
### lag_5 = jan
### lag_6 = dec
### lag_7 = nov
### lag_8 = oct
### lag_9 = sep
### lag_10 = aug
### lag_11 = jul

### make long
pts_tc_jun_long <- pts_tc_jun %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_jun_long <- pts_tc_jun_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number %in% c("1", "2", "3"), "spring",
                         ifelse(lag_number %in% c("4", "5", "6"), "winter",
                                ifelse(lag_number %in% c("7", "8", "9"), "fall",
                                       ifelse(lag_number %in% c("10", "11"),
                                              "summer", "misc")))))

### get seasonal metrics
pts_tc_jun_summ <- pts_tc_jun_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

rm(pts_tc_jun, pts_tc_jun_long)
gc()

##############################
### work with dec fires
pts_tc_dec <- pts_tc %>%
  filter(month == 12)

### lag_0 = dec
### lag_1 = nov
### lag_2 = oct
### lag_3 = sep
### lag_4 = aug
### lag_5 = jul
### lag_6 = jun
### lag_7 = may
### lag_8 = apr
### lag_9 = mar
### lag_10 = feb
### lag_11 = jan

### make long
pts_tc_dec_long <- pts_tc_dec %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_dec_long <- pts_tc_dec_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
    sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number == "0", "winter",
                         ifelse(lag_number %in% c("1", "2", "3"), "fall",
                                ifelse(lag_number %in% c("4", "5", "6"), "summer",
                                       ifelse(lag_number %in% c("7", "8", "9"),
                                              "spring", "misc")))))

### lag_0 = dec
### lag_1 = nov
### lag_2 = oct
### lag_3 = sep
### lag_4 = aug
### lag_5 = jul
### lag_6 = jun
### lag_7 = may
### lag_8 = apr
### lag_9 = mar
### lag_10 = feb
### lag_11 = jan

### get seasonal metrics
pts_tc_dec_summ <- pts_tc_dec_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

write_csv(pts_tc_dec_summ, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_dec.csv")

##############################
### work with oct fires
pts_tc_oct <- pts_tc %>%
  filter(month == 10)

### lag_0 = oct
### lag_1 = sep
### lag_2 = aug
### lag_3 = jul
### lag_4 = jun
### lag_5 = may
### lag_6 = apr
### lag_7 = mar
### lag_8 = feb
### lag_9 = jan
### lag_10 = dec
### lag_11 = nov

#### just do 2007
pts_tc_oct_2007 <- pts_tc_oct %>%
  filter(year == 2007)

### make long
pts_tc_oct_2007_long <- pts_tc_oct_2007 %>%
  pivot_longer(cols = -c(uid, ig_date, year, month),
               names_to = "metric",
               values_to = "value")

### separate lag, add column for season
pts_tc_oct_2007_long <- pts_tc_oct_2007_long %>%
  separate(metric, into = c("metric_name", "lag", "lag_number"),  
           sep = "_", extra = "merge", fill = "right") %>%
  dplyr::select(-lag) %>%
  mutate(season = ifelse(lag_number == "0", "winter",
                         ifelse(lag_number %in% c("1", "2", "3"), "fall",
                                ifelse(lag_number %in% c("4", "5", "6"), "summer",
                                       ifelse(lag_number %in% c("7", "8", "9"),
                                              "spring", "misc")))))

### get seasonal metrics
pts_tc_oct_2007_summ <- pts_tc_oct_2007_long %>%
  group_by(uid, ig_date, year, month, metric_name, season) %>%
  summarise(max_seasonal_value = if (all(is.na(value))) NA_real_ else max(value, na.rm = TRUE),
            mean_seasonal_value = if (all(is.na(value))) NA_real_ else mean(value, na.rm = TRUE),
            total_seasonal_value = if (all(is.na(value))) NA_real_ else sum(value, na.rm = TRUE))

write_csv(pts_tc_oct_2007_summ, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_oct_2007.csv")
```
#### combine and fix units
Units from TerraClimate in GEE:
- pr: mm, no scale

- soil: mm, scale = 0.1
- tmmn: degrees C, scale = 0.1
- tmmx: degrees C, scale = 0.1

- vpd: kPA, scale = 0.01
- vs: m/s, scale = 0.01
- pdsi: no unit, scale = 0.01

```{r}
# ### list files
# tc_files <- list.files(path = "E:/fuel_treat/covars/terraclimate/tc_month/",
#                         pattern = ".csv$",
#                         full.names = TRUE)
# 
# ### open them
# tc_files <- lapply(tc_files, read.csv)
# 
# ### check 17
# test <- tc_files[[17]]
# 
# ### fix weird value in 17
# test$total_seasonal_value[test$total_seasonal_value == "-"] <- NA
# write_csv(test, "E:/fuel_treat/covars/terraclimate/tc_month/terraclimate_jun_2007.csv")

### list files
tc_files <- list.files(path = "E:/fuel_treat/covars/terraclimate/tc_month/",
                        pattern = ".csv$",
                        full.names = TRUE)

### open them
tc_files <- lapply(tc_files, read.csv)

### combine
tc_files <- do.call("rbind", tc_files)

### deal with scaling factors
# - pr: mm, no scale
# - soil: mm, scale = 0.1
# - tmmn: degrees C, scale = 0.1
# - tmmx: degrees C, scale = 0.1
# - vpd: kPA, scale = 0.01
# - vs: m/s, scale = 0.01
# - pdsi: no unit, scale = 0.01
tc_files <- tc_files %>%
  mutate(max_seasonal_value = ifelse(metric_name %in% c("vs", "vpd", "pdsi"), 
                                           max_seasonal_value*0.01, 
                                           ifelse(metric_name %in% c("soil", "tmmx", "tmmn"),
                                                  max_seasonal_value*0.1, 
                                                  max_seasonal_value)),
         mean_seasonal_value = ifelse(metric_name %in% c("vs", "vpd", "pdsi"), 
                                           mean_seasonal_value*0.01, 
                                           ifelse(metric_name %in% c("soil", "tmmx", "tmmn"),
                                                  mean_seasonal_value*0.1, 
                                                  mean_seasonal_value)),
         total_seasonal_value = ifelse(metric_name %in% c("vs", "vpd", "pdsi"), 
                                           total_seasonal_value*0.01, 
                                           ifelse(metric_name %in% c("soil", "tmmx", "tmmn"),
                                                  total_seasonal_value*0.1, 
                                                  total_seasonal_value)))

### get rid of season = misc
tc_files <- tc_files %>%
  filter(!season == "misc")

### make wide
tc_wide <- tc_files %>%
  pivot_longer(cols = c(max_seasonal_value, mean_seasonal_value, total_seasonal_value),
               names_to = "metric",
               values_to = "value") %>%
  unite("season_metric", season, metric_name, metric, sep = "_") %>%
  pivot_wider(names_from = season_metric, values_from = value)

### drop the cols I don't need
tc_wide <- tc_wide %>%
  dplyr::select(-`__total_seasonal_value`, -`__max_seasonal_value`, 
                -`__mean_seasonal_value`, -`_pdsi_max_seasonal_value`, 
                -`_pdsi_mean_seasonal_value`, -`_pdsi_total_seasonal_value`,
                -fall_pdsi_total_seasonal_value, -winter_pdsi_total_seasonal_value,
                -spring_pdsi_total_seasonal_value, -summer_pdsi_total_seasonal_value,
                -fall_soil_total_seasonal_value, -winter_soil_total_seasonal_value,
                -spring_soil_total_seasonal_value, -summer_soil_total_seasonal_value,
                -fall_pr_max_seasonal_value, -winter_pr_max_seasonal_value,
                -spring_pr_max_seasonal_value, -summer_pr_max_seasonal_value,
                -fall_pr_mean_seasonal_value, -winter_pr_mean_seasonal_value,
                -spring_pr_mean_seasonal_value, -summer_pr_mean_seasonal_value,
                -fall_tmmn_total_seasonal_value, -winter_tmmn_total_seasonal_value,
                -spring_tmmn_total_seasonal_value, -summer_tmmn_total_seasonal_value,
                -fall_tmmx_total_seasonal_value, -winter_tmmx_total_seasonal_value,
                -spring_tmmx_total_seasonal_value, -summer_tmmx_total_seasonal_value,
                -fall_vs_total_seasonal_value, -winter_vs_total_seasonal_value,
                -spring_vs_total_seasonal_value, -summer_vs_total_seasonal_value,
                -fall_vpd_total_seasonal_value, -winter_vpd_total_seasonal_value,
                -spring_vpd_total_seasonal_value, -summer_vpd_total_seasonal_value)

### write out
write_csv(tc_wide, "E:/fuel_treat/covars/terraclim_summs.csv")
```

Note on units:
Values are extracted directly from the Earth Engine assets and are not transformed to be in comparable units across data sources. 
Given that the units are different, these will need to be transformed before use/comparison. For example, terraclimate has temperatures
in units of 0.1 degrees C (e.g., a value of 254 is 25.4C), while gridmet has temps in deg K.

Links to info on band units
- https://developers.google.com/earth-engine/datasets/catalog/IDAHO_EPSCOR_TERRACLIMATE#bands



## VIIRS
From viirs_code.Rmd

Gets VIIRS detections from GEE, intersects them with the fire perimeters, then rasterizes them. In the rasterizing process, the value of the pixel is equal to the "day" of the fire: a value of 1 indicates that the pixel burned on the day the fire ignited, while a value of 10 would mean that the pixel burned on the 10th day of the fire.

Note that VIIRS started in 2012, so we don't have VIIRS data for any fires pre-2012

## EPA Ecoregions
### by points
```{r}
### open pts
esa <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts.shp")
  
### simplify
esa <- esa %>%
  dplyr::select(uid, geometry)

### open ecoregions
ecoreg <- st_read("E:/fuel_treat/epa_ecoregions/us_eco_l3.shp") %>%
  st_transform(., crs = 6350)

ggplot() + 
  geom_sf(data = ecoreg, 
          aes(color = NA_L2NAME, fill = NA_L2NAME))

### simplify ecoregions
ecoreg <- ecoreg %>%
  filter(!NA_L1NAME %in% c("EASTERN TEMPERATE FORESTS",
                           "TROPICAL WET FORESTS")) %>%
  filter(!NA_L2NAME %in% c("ATLANTIC HIGHLANDS",
                           "MIXED WOOD SHIELD",
                           "TEXAS-LOUISIANA COASTAL PLAIN"))

### simplify
ecoreg <- ecoreg %>%
  dplyr::select(NA_L3NAME, NA_L2NAME, NA_L1NAME, geometry)

### set up parallels
plan(multisession, workers = 8)

### make chunks
# chunk_size <- 100000  # Size of each chunk (adjust as needed)
esa_chunks <- split(esa, 
                    ceiling(seq_along(esa$geometry) / 100000))

### intersect
result_chunks <- future_map(esa_chunks, 
                            ~ st_intersection(.x, ecoreg))
# esa_eco <- st_intersection(esa, ecoreg)

### combine
final_result <- do.call(rbind, result_chunks)

### simplify
final_result <- final_result %>%
  dplyr::select(uid, 
                ecoreg_1 = NA_L1NAME,
                ecoreg_2 = NA_L2NAME,
                ecoreg_3 = NA_L3NAME,
                geometry)

### drop geom
st_geometry(final_result) <- NULL

### write out fires and ecoregions
write_csv(final_result, "E:/fuel_treat/covars/ecoregion.csv")
```

### by fire
```{r}
### open fires we're using
fires_ft <- st_read("E:/fuel_treat/burned_ft_fires_use.shp")

### open ecoregions
ecoreg <- st_read("E:/fuel_treat/epa_ecoregions/us_eco_l3.shp") %>%
  st_transform(., crs = 6350)

### simplify ecoregions
ecoreg <- ecoreg %>%
  filter(!NA_L1NAME %in% c("EASTERN TEMPERATE FORESTS",
                           "TROPICAL WET FORESTS"))

### intersect
fires_eco <- st_intersection(fires_ft, ecoreg)

### simplify
fires_eco <- fires_eco %>%
  dplyr::select(Event_ID, 
                ecoreg_1 = NA_L1NAME,
                ecoreg_2 = NA_L2NAME,
                ecoreg_3 = NA_L3NAME,
                geometry)

### see which fires aren't in just 1 ecoregion
check <- fires_eco
st_geometry(check) <- NULL
check_summ <- check %>% 
  group_by(Event_ID) %>% 
  summarise(n_ecoreg = length(unique(ecoreg_3)))
check_summ <- check_summ %>% 
  filter(n_ecoreg > 1)

### 3619 fires are just in 1 ecoregion, but 313 burned across ecoregions
fires_across <- fires_eco %>%
  filter(Event_ID %in% check_summ$Event_ID)

### write out fires and ecoregions
st_write(fires_eco, "E:/fuel_treat/epa_ecoregions/fires_ecoreg.shp")
```

## Combine covariates
- ecoregion
- tpi and dem
- ndvi, ndmi, evi
- boundary points (boundary of fire/ft and fire boundary)
- distance to boundary
- climate
```{r}
### open ecoreg
ecoreg <- read.csv("E:/fuel_treat/covars/ecoregion.csv")

### open lcmap
lcmap <- read.csv("E:/fuel_treat/covars/lcmap.csv")

### combine
ecoreg <- merge(x = ecoreg,
                y = lcmap,
                by = "uid",
                all = TRUE)

### clean
rm(lcmap)
gc()

### open dem
dem <- read.csv("E:/fuel_treat/covars/dem.csv")

### simplify cols
dem <- dem %>%
  dplyr::select(uid, elevation, slope, aspect_srai)

### combine
ecoreg <- merge(x = ecoreg,
                y = dem,
                by = "uid",
                all = TRUE)

### clean
rm(dem)
gc()

### open tpi
tpi <- read.csv("E:/fuel_treat/covars/tpi.csv") %>%
  dplyr::select(., uid, tpi)

### combine
ecoreg <- merge(x = ecoreg,
                y = tpi,
                by = "uid",
                all = TRUE)

### write out
write_csv(ecoreg,
          "E:/fuel_treat/covars/esa_covars.csv")

### open ndmi, ndvi, evi
ndvi <- read.csv("E:/fuel_treat/covars/ndvi.csv") %>%
  dplyr::select(., uid, ndvi)
ndmi <- read.csv("E:/fuel_treat/covars/ndmi.csv") %>%
  dplyr::select(., uid, ndmi)
evi <- read.csv("E:/fuel_treat/covars/evi.csv") %>%
  dplyr::select(., uid, evi)

### drop dups from evi
evi <- evi %>% distinct()

### merge them
veg_indices <- ndvi %>%
  left_join(ndmi, by = "uid") %>%
  left_join(evi, by = "uid")
  
### merge with other covars
covars <- ecoreg %>%
  left_join(veg_indices, by = "uid")
  
### clean up
rm(ecoreg, evi, ndmi, ndvi, veg_indices)
gc()

### open boundary status
pt_status <- st_read("E:/fuel_treat/esa_subset/pt_status.shp")

### clean up
st_geometry(pt_status) <- NULL
pt_status <- pt_status %>%
  dplyr::select(uid,
                in_fire,
                overlap_bound = ovrlp_b)
# pt_status <- pt_status %>% distinct()

### combine
covars <- covars %>%
  left_join(pt_status, by = "uid")

### clean up
rm(pt_status)
gc()

### open distance to boundary
dist_all <- read.csv("E:/fuel_treat/covars/pts_dist_min_fix_full.csv")

### combine
covars <- covars %>%
  left_join(dist_all, by = "uid")

### clean up
rm(dist_all)
gc()

### open climate data
clim <- read.csv("E:/fuel_treat/covars/terraclim_summs.csv")

### simplify clim
clim <- clim %>% 
  dplyr::select(-ig_date, -year, -month)

### drop uids in clim that aren't in covars
clim <- clim %>%
  filter(uid %in% covars$uid)
clim <- distinct(clim)

### duplicate uids in clim?
dup_uids <- duplicated(clim$uid) | duplicated(clim$uid, 
                                              fromLast = TRUE)

### the dup uid's are happening where one row with the uid has data and the other row just has NA values for the climate data
### get climate cols
non_uid_cols <- setdiff(names(clim), "uid")

### figure out which ones have only NA vals
all_na <- rowSums(is.na(clim[non_uid_cols])) == length(non_uid_cols)

### drop rows with duplicated uids AND all NA values for climate
clim_summ <- clim[!(dup_uids & all_na), ]

### combine
covars <- covars %>%
  left_join(clim_summ, by = "uid")

### write out
write_csv(covars, "E:/fuel_treat/covars/esa_covars_all.csv")
```

## Extract ft info
```{r}
### open pts
esa <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts.shp")

### simplify cols
esa <- esa %>%
  dplyr::select(uid, fire_id, fire_year, geometry)

### open fts
fts <- st_read("E:/fuel_treat/esa_subset/esa_fts.shp")

### set up parallels for intersection
plan(multisession, workers = 8)

### make chunks
# chunk_size <- 100000  # Size of each chunk (adjust as needed)
esa_chunks <- split(esa, 
                    ceiling(seq_along(esa$geometry) / 100000))

### intersect in parallel
result_chunks <- future_map(esa_chunks, ~ {
  
  ### filter to fts that burned in the right fire
  chunk_fire_ids <- unique(.x$fire_id) 
  
  ## filter fts 
  filtered_fts <- fts %>% 
    filter(Event_ID %in% chunk_fire_ids)
  
  ### intersect
  intersections <- st_intersection(.x, filtered_fts)
  
  ### return
  return(intersections)
})

### combine
final_result <- do.call(rbind, result_chunks)

### remove geom
st_geometry(final_result) <- NULL

### add column for treated
final_result <- final_result %>%
  mutate(treat_status = "treated")

### drop fire_id from esa_ft
final_result <- final_result %>%
  dplyr::select(-fire_id)

### drop event id from final_result
final_result <- final_result %>%
  dplyr::select(-Event_ID)

### merge with esa 5454704
esa_ft <- merge(x = esa, 
                y = final_result,
                by = c("uid", "fire_year"),
                all.x = TRUE)

### drop geom
st_geometry(esa_ft) <- NULL

### make distinct
esa_ft <- distinct(esa_ft)

### keep earliest ignition date
esa_ft_simp <- esa_ft %>%
  arrange(Ig_Date) %>%
  group_by(uid, pid_unique, poly_id, date_comp, act_code, source, state, treat_status) %>%
  slice_min(order_by = Ig_Date, n = 1) %>%
  ungroup()

### write out
write_csv(esa_ft_simp,
          "E:/fuel_treat/esa_subset/esa_sample_pts_ft.csv")

# ### figure out repeats
# esa_check <- esa_ft_simp %>%
#   group_by(uid) %>%
#   summarise(n_occur = n()) %>%
#   ungroup() %>%
#   filter(n_occur > 1)
# 
# ### filter to these
# esa_check_dup <- esa_ft_simp %>%
#   filter(uid %in% esa_check$uid)
# 
# ### find date difference
# esa_check_dates <- esa_check %>%
#   arrange(uid, Ig_Date) %>%
#   group_by(uid) %>%
#   mutate(diff_date = c(NA, diff(Ig_Date)))
# 
# ### look at UIDs where diff_date > 27 days
# esa_check_long <- esa_check_dates %>%
#   filter(diff_date > 27)
# 
# ### filter to these ones
# esa_check_long_diff <- esa_ft %>%
#   filter(uid %in% esa_check_long$uid)
```

## Time since treatment
```{r}
### open pts with ft info
esa_ft_simp <- read.csv("E:/fuel_treat/esa_subset/esa_sample_pts_ft.csv")

### open pts
pts <- st_read("E:/fuel_treat/esa_subset/esa_sample_pts_simp.shp")

### filter to pts in pts
esa_ft_simp_pts <- esa_ft_simp %>%
  filter(uid %in% pts$uid)

### convert dates
esa_ft_simp_pts$Ig_Date <- as.Date(esa_ft_simp_pts$Ig_Date)
esa_ft_simp_pts$date_comp <- as.Date(esa_ft_simp_pts$date_comp)

### add time elapsed from treatment to fire
esa_ft_simp_pts <- esa_ft_simp_pts %>%
  mutate(days_elapsed = as.numeric(difftime(Ig_Date, date_comp, units = "days")),
         wks_elapsed = round(as.numeric(difftime(Ig_Date, date_comp, units = "weeks")), 0)) %>%
  mutate(yrs_elapse = round(days_elapsed/365.25, 1))

### open ft categories
categories <- read.csv("E:/fuel_treat/ft_polys/all_ft_category.csv") %>%
  dplyr::select(., act_code, activity_cat, fire_id = Event_ID, poly_id, source, state)
categories <- distinct(categories)

### make join col
categories <- categories %>%
  mutate(join_id = paste0(fire_id, "_", poly_id))
esa_ft_simp_pts <- esa_ft_simp_pts %>%
  mutate(join_id = paste0(fire_id, "_", poly_id))

### add categories to pts
pts_activities <- merge(x = esa_ft_simp_pts,
                        y = categories, 
                        # by = "act_code",
                        by = c("join_id", "fire_id",
                               "poly_id", "state",
                               "act_code"),
                        all.x = TRUE)

### deal with activity code 1113
pts_activities <- pts_activities %>%
  mutate(activity_cat = ifelse(act_code == "1113",
                               "fire_ft",
                               activity_cat))

### write out
write_csv(pts_activities,
          "E:/fuel_treat/covars/esa_ft_info.csv")


# ### drop nas
# pts_activities <- pts_activities %>%
#   filter(!is.na(treat_status))
# 
# pts_activities <- pts_activities %>%
#   mutate(activity_cat = ifelse(act_code.x == "1113",
#                                "fire_ft",
#                                activity_cat))
# 
# ### NAs
# na_activity <- pts_activities %>%
#   filter(is.na(activity_cat))
# 
# ### drop NAs
# pts_activities <- pts_activities %>%
#   filter(!is.na(activity_cat))
# 
# ggplot() +
#   geom_histogram(data = pts_activities, 
#                  aes(x = yrs_elapse,
#                      color = activity_cat,
#                      fill = activity_cat)) +
#   xlab("Years from treatment to wildfire") +
#   ylab("Number of treatments") +
#   theme_bw()
```

## Add ft info to covars
```{r}
### open covars
covars <- read.csv("E:/fuel_treat/covars/esa_covars_all.csv")

### open fuel treat info
ft_info <- read.csv("E:/fuel_treat/covars/esa_ft_info.csv")

### combine them
ft_covars <- merge(x = covars,
                   y = ft_info,
                   by = c("uid", "fire_id", "fire_year"),
                   all = TRUE)

### distinct
ft_covars <- distinct(ft_covars)

### are there uid's repeated?
check_uid <- ft_covars %>%
  group_by(uid) %>%
  summarise(n_occur = n()) %>%
  filter(n_occur > 1)

### take a look at these
check_uid <- ft_covars %>%
  filter(uid %in% check_uid$uid)

### take a look at one of them
check_2 <- ft_covars %>%
  filter(uid == "CA3761912020720170716_177970")

### why are these different?
all.equal(check_2[1, ], check_2[2, ])
all.equal(check_2[1, ], check_2[3, ])

### the issue is treatments at different times. ugh.

### write it out as it is, just to have it all in one place
write_csv(ft_covars, "E:/fuel_treat/covars/esa_covars_fts_all.csv")
```

## RDD




## 2. Next batch of fires and fuel treatments
Use fires I've already downloaded CBI
```{r}
### figure out which fp fires I have
fp_fires <- list.files(path = "E:/fuel_treat/firedpy/cbi_gee_firedpy",
                       pattern = "*_CBI_bc.tif",
                       full.names = TRUE)
fp_file_base <- basename(fp_fires)
fp_file_name <- sub("_CBI_bc\\.tif$", "", fp_file_base)

### figure out which mtbs fires I have
mt_fires <- list.files(path = "E:/fuel_treat/mtbs/cbi_gee_mtbs",
                       pattern = "*_CBI_bc.tif",
                       full.names = TRUE)
mt_file_base <- basename(mt_fires)
mt_file_name <- sub("_CBI_bc\\.tif$", "", mt_file_base)

### combine vectors
all_files <- c(fp_file_name, mt_file_name)

### ESA fires
fire <- st_read("E:/fuel_treat/esa_subset/esa_fires_simp.shp")

### open all fires with burned fts
fires_ft <- st_read("E:/fuel_treat/burned_ft_fires_use.shp")

### remove fires done in ESA round
fires_ft <- fires_ft %>%
  filter(!Event_ID %in% fire$Event_ID)

### clean up
rm(fire)
gc()
```

#### still need CBI
```{r}
### fires that still need CBI
fires_cbi <- fires_ft %>%
  filter(!Event_ID %in% all_files)

### open mtbs and firedpy (raw versions to avoid splits across state boundaries)
mtbs <- st_read("E:/fuel_treat/mtbs/mtbs_perims_DD.shp")
fired <- st_read("E:/fuel_treat/firedpy/firedpy_2000_2024_west_nonrx.shp")

### subset to fires I still need
mtbs <- mtbs %>%
  filter(Event_ID %in% fires_cbi$Event_ID)
fired <- fired %>%
  filter(Event_ID %in% fires_cbi$Event_ID)

### extract state as column
mtbs <- mtbs %>%
  mutate(state = stringr::str_extract(Event_ID, "^.{2}"))

### simplify to combine
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, state, geometry)
fired <- fired %>%
  dplyr::select(Event_ID, Incid_Type, Ig_Date, state, geometry)

### align crs
mtbs <- mtbs %>%
  st_transform(6350)

### combine
fm <- rbind(mtbs, fired)

################################
### deal with adjacent fires
################################

### figure out which fires overlap
adj_matrix <- st_intersects(fm, sparse = FALSE)

### figure out which have similar dates too
date_diff_matrix <- outer(fm$Ig_Date, 
                          fm$Ig_Date, 
                          function(x, y) abs(as.numeric(difftime(x, y, units = "days"))))

### set distance between ignition dates
n_days <- 28

### make combined adjacency condition: polygons touch AND ignition dates are within 28 days from each other
combined_matrix <- adj_matrix & (date_diff_matrix <= n_days)

### make graph of connected components
g <- graph_from_adjacency_matrix(combined_matrix, mode = "undirected")

### assign group ids based on connected components
fm$group_id <- components(g)$membership

### combine geometries for grouped polygons
fires_merged <- fm %>%
  group_by(group_id) %>%
  arrange(Ig_Date) %>%
  summarise(
    
    ### keep earliest ignition date and corresponding Event_ID
    Ig_Date = first(Ig_Date), 
    Event_ID = first(Event_ID),
    
    ### keep track of the number of merged fires
    n_fires = n(),
    geometry = st_union(geometry),
    .groups = "drop")
st_write(fires_merged, "E:/fuel_treat/fires_gee_post_esa_merged.shp")
```
##### prep for GEE
```{r}
### prep cols for GEE

### bring in state col
state_fm <- fm 
st_geometry(state_fm) <- NULL
state_fm <- state_fm %>%
  dplyr::select(Event_ID, state)
fires_merged <- merge(x = fires_merged,
                      y = state_fm,
                      by = "Event_ID",
                      all.x = TRUE)

### drop unnecessary cols
fires_gee <- fires_merged %>%
  dplyr::select(-group_id, -n_fires) %>%
  mutate(Fire_Year = year(Ig_Date),
         Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258)) %>%
  dplyr::select(Fired_ID = Event_ID, Fire_Year, Start_Day, End_Day, geometry)

### Make sure date columns don't get read in with decimals
fires_gee$Fire_Year <- as.character(fires_gee$Fire_Year, 0)
fires_gee$Start_Day <- as.character(fires_gee$Start_Day, 0)
fires_gee$End_Day <- as.character(fires_gee$End_Day, 0)

### transform
fires_gee <- fires_gee %>%
  st_transform(crs = 6350)

### write out
st_write(fires_gee,
         "E:/fuel_treat/fires_gee_post_merged.shp",
         append = FALSE)
```
#### get associated fts
```{r}
### open fuel treatments (full, not just burned)
ft_footprint <- st_read("E:/fuel_treat/ft_polys/burned_ft/all_ft_burned_full_poly_update.gpkg")

### filter to fires
ft_fires <- ft_footprint %>%
  filter(Event_ID %in% fm$Event_ID)

### simplify fm 
fm_simp <- fm
st_geometry(fm_simp) <- NULL
fm_simp <- fm_simp %>%
  dplyr::select(-state)

### combine
ft_fires <- merge(x = ft_fires,
                  y = fm_simp,
                  by = "Event_ID",
                  all.x = TRUE)

### want the event_id from fires_merged
fires_simp <- fires_merged
st_geometry(fires_simp) <- NULL
fires_simp <- fires_simp %>%
  dplyr::select(group_id,
                ig_date_keep = Ig_Date,
                event_id_keep = Event_ID)

### merge in
ft_fires_group <- merge(x = ft_fires,
                        y = fires_simp,
                        by = "group_id",
                        all.x = TRUE)

### simplify
ft_fires_group <- ft_fires_group %>%
  dplyr::select(-Event_ID, -Ig_Date)

### drop dups (43870 dropped to 43348)
ft_fires_group <- ft_fires_group %>% distinct()

### rename cols
ft_fires_group <- ft_fires_group %>%
  rename(Event_ID = event_id_keep,
         Ig_Date = ig_date_keep)

### write out
st_write(ft_fires_group,
         "E:/fuel_treat/ft_polys/burned_ft/all_ft_burned_full_poly_update_postesa.gpkg")
```


## Categorize mech vs rx fire
```{r}
### in twig, sometimes there are activity codes that have been classified differently in terms of twig_category
#### 1000: mechanical (4), fire (2)
#### 1100: mechanical (4), fire (3)
#### 1102: mechanical (2), fire (11)
#### 1111: mechanical (4), fire (30)
#### 1113: mechanical (4), fire (37)
#### 1120: mechanical (80), fire (1)
#### 1131: mechanical (5), fire (1)
#### 1150: mechanical (71), fire (3)
#### 1153: mechanical (80), fire (3)
#### 1160: mechanical (60), fire (1)
#### 1180: mechanical (57), fire (2)
#### 1182: mechanical (2), fire (2)
#### 2020: mechanical (2), fire (1)
#### 2321: mechanical (4), fire (3)
#### 2340: mechanical (2), fire (2)
#### 2341: mechanical (11), fire (5), biological (19)
#### 2360: mechanical (7), fire (3), biological (16)
#### 2370: mechanical (9), fire (1)
#### 2400: mechanical (12), fire (3)
#### 2530: mechanical (7), fire (1)
#### 3370: mechanical (3), fire (1)
#### 3380: mechanical (2), fire (1)
#### 4131: mechanical (49), fire (1)
#### 4231: mechanical (64), fire (1)
#### 4320: mechanical (4), fire (1)
#### 4331: mechanical (6), fire (4)
#### 4341: mechanical (6), fire (2)
#### 4342: mechanical (3), fire (1)
#### 4346: mechanical (4), fire (1)
#### 4382: mechanical (7), fire (2)
#### 4383: mechanical (2), fire (1)
#### 4452: mechanical (12), fire (2)
#### 4455: mechanical (19), fire (1)
#### 4466: mechanical (4), fire (1)
#### 4471: mechanical (6), fire (17)
#### 4473: mechanical (13), fire (3)
#### 4474: mechanical (33), fire (1)
#### 4475: mechanical (10), fire (1)
#### 4481: mechanical (1), fire (2)
#### 4491: mechanical (5), fire (18)
#### 4493: mechanical (10), fire (1)
#### 4511: mechanical (49), fire (5)
#### 4521: mechanical (80), fire (3)
#### 4550: mechanical (2), fire (1)
#### 4570: mechanical (9), fire (1)
#### 5100: mechanical (5), fire (1)
#### 5217: mechanical (4), fire (1)
#### 5510: mechanical (4), fire (1)
#### 5520: mechanical (2), fire (1)
#### 5540: mechanical (5), fire (2)
#### 5550: mechanical (3), fire (1)
#### 5633: mechanical (5), fire (3)
#### 6000: mechanical (1), fire (1)
#### 6050: mechanical (17), fire (2)
#### 6100: mechanical (3), fire (2)
#### 6105: mechanical (8), fire (1)
#### 6131: mechanical (5), fire (1)
#### 7100: mechanical (6), fire (3)
#### 8100: mechanical (2), fire (1)
#### 8200: mechanical (1), fire (6)
```

### UPDATE FROM HERE?

## Wildfires for CBI
Fires I need to add since updating the dataset
```{r}
### Fires I've already done CBI for
cbi_done <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_gee.shp")

### open the original fire perimeters
mtbs <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_through_2022/mtbs_perims_DD.shp") %>%
  st_transform(crs = 6350)

### open treated mtbs in western us
mtbs_burned <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_through_2022/mtbs_fuel_treats_updated.shp")

### these shapefiles have splits at state boundaries, but I want the complete MTBS perimeters (one polygon per fire)

### subset mtbs to fires in fts
mtbs <- mtbs %>%
  filter(Event_ID %in% mtbs_burned$Event_ID)

### subset to fires I don't already have CBI for
mtbs_need <- mtbs %>%
  filter(!Event_ID %in% cbi_done$Fire_ID)

### combine columns 

### prep mtbs_need for merge
st_geometry(mtbs_need) <- NULL
mtbs_need <- mtbs_need %>%
  distinct()

### prep mtbs for merge
mtbs <- mtbs %>%
  dplyr::select(Event_ID, Incid_Type)

### merge
mtbs <- merge(mtbs,
              mtbs_need,
              by = c("Event_ID", "Incid_Type"))

### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)

### extract state as column
mtbs <- mtbs %>%
  mutate(state = stringr::str_extract(Event_ID, "^.{2}"))

### Fire seasons
#### In Parks et al. 2019, they use the following seasons:
#### AZ and NM: April 1-June 30 (julian 91-181)
#### CA, ID, MT, OR, UT, WA, WY: June 1-Sept 15 (julian 152-258)
#### assume it's the same for CO, NV
#### use these
# other_julian <- c("CA", "CO", "ID",
#                   "MT", "NV", "OR",
#                   "SD", "TX",
#                   "UT", "WA", "WY")

### use julian fire season dates for CA, ID, MT, OR, UT, WA, WY

### assign julian start and end date based on state dates from Parks et al. 2019
mtbs <- mtbs %>%
  mutate(Start_Day = ifelse(state %in% c("AZ", "NM"), 91, 152),
         End_Day = ifelse(state %in% c("AZ", "NM"), 181, 258))

### add year column
mtbs <- mtbs %>%
  mutate(year = year(Ig_Date))

### Select columns for GEE
### export fire perimeters for CBI analysis
# - Fire_ID
# - Fire_Year
# - Start_Day (start day of fire season in Julian days)
# - End_Day (end day of fire season in Julian days)
mtbs <- mtbs %>%
  dplyr::select(Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day,
                End_Day,
                Incid_Type,
                geometry)

### Make sure date columns don't get read in with decimals
mtbs$Fire_Year <- as.character(mtbs$Fire_Year, 0)
mtbs$Start_Day <- as.character(mtbs$Start_Day, 0)
mtbs$End_Day <- as.character(mtbs$End_Day, 0)

### Write out shp for gee
st_write(mtbs,
         "E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_through_2022/mtbs_gee.shp")
```

### Are some of these fires completely contained by MTBS perimeters?
```{r, warning = FALSE}
### open shp of burned FTs
burned_ft <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_mtbs_firedpy.shp")

### open csv for firedpy
fp <- read.csv("E:/usda_2023/usfs_fuel_treatments/western_us/firedpy_updated/firedpy_ft_burned_all.csv")

### open csv for mtbs
mtbs_fts <- read.csv("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fts_w_us_updated.csv") %>%
  
  ### fix ignition date
  mutate(Ig_Date = make_date(year, month, date))

### rename cols for both csvs
fp <- fp %>%
  dplyr::select(ft_id, 
                firedpy_id = id,
                firedpy_ig_date = ig_date,
                firedpy_ig_day = ig_day,
                firedpy_ig_month = ig_mnth,
                firedpy_ig_year = ig_year)
mtbs_fts <- mtbs_fts %>%
  dplyr::select(ft_id, 
                mtbs_id = Event_ID,
                mtbs_ig_date = Ig_Date,
                mtbs_ig_day = date,
                mtbs_ig_month = month,
                mtbs_ig_year = year)

### merge in data
burned_mtbs <- merge(x = burned_ft,
                     y = mtbs_fts,
                     by = "ft_id",
                     all.x = TRUE)
burned_m_p <- merge(x = burned_mtbs,
                    y = fp,
                    by = "ft_id",
                    all.x = TRUE) 

### drop geom
burned_mp <- burned_m_p
st_geometry(burned_mp) <- NULL
burned_mp <- burned_mp %>%
  distinct()

### subset to ft's that burned in both in the same year
burned_mp <- burned_mp %>%
  filter(!is.na(mtbs_id)) %>%
  filter(!is.na(firedpy_id)) %>%
  filter(mtbs_ig_year == firedpy_ig_year)

### add unique rowname
burned_mp <- burned_mp %>%
  mutate(uid = row_number())

### split mtbs and firedpy
b_m <- burned_mp %>%
  dplyr::select(uid, mtbs_id)
b_f <- burned_mp %>%
  dplyr::select(uid, firedpy_id)

### open fire perimeters
firedpy <- st_read("E:/fired_py_data/firedpy_update_2024/fired_conus_ak_2000_to_2024_events.shp") %>%
  filter(id %in% b_f$firedpy_id) %>%
  st_transform(., 6350)
mtbs <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_through_2022/mtbs_gee.shp") %>%
  filter(Fire_ID %in% b_m$mtbs_id)

### add geom to the dfs
b_m <- merge(y = b_m, 
             x = mtbs,
             by.y = "mtbs_id",
             by.x = "Fire_ID",
             all.y = TRUE)
b_f <- merge(y = b_f, 
             x = firedpy,
             by.y = "firedpy_id",
             by.x = "id",
             all.y = TRUE)

### make df to fill
uid <- NA
mtbs_id <- NA
firedpy_id <- NA
complete_over <- NA
store_comp_overlap <- as.data.frame(cbind(uid, mtbs_id, 
                                          firedpy_id, complete_over))

### loop through and figure out if any of the firedpy are completely within the mtbs perimeters
for (i in 1:nrow(b_f)) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### identify firedpy row
  fp_poly <- b_f[i, ]
  
  ### get mtbs row
  mtbs_poly <- b_m %>%
    filter(uid %in% fp_poly$uid)
  
  ### make cols
  uid <- fp_poly$uid
  mtbs_id <- mtbs_poly$Fire_ID
  firedpy_id <- fp_poly$id
  
  ### make col for overlap
  complete_over <- as.numeric(unlist(st_covered_by(fp_poly,
                                                   mtbs_poly)))
  # complete_unlist <- unlist(complete_over)
  
  if(length(complete_over) > 0) {
  
  ### make df
  df_i <- as.data.frame(cbind(uid, mtbs_id, 
                              firedpy_id, complete_over))
  
  ### store output
  store_comp_overlap <- rbind(store_comp_overlap,
                              df_i)
  }}

### drop empty row
store_comp_overlap <- store_comp_overlap %>%
  filter(!is.na(uid))

### remove these firedpy id's from the cbi dataset
firedpy_keep_keep <- firedpy_keep %>%
  filter(!Fire_ID %in% store_comp_overlap$firedpy_id)

### Write out shp for gee
st_write(firedpy_keep_keep,
         "E:/usda_2023/usfs_fuel_treatments/western_us/firedpy_updated/firedpy_gee.shp")
```




### Overlapping treatments
```{r}
### open shp of fuel treatments that subsequently burned
# burned_ft <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/all_burned_fuel_treats_updated.shp")
# burned_ft <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/all_burned_fts_polygons.shp")
### to include firedpy:
burned_ft <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_mtbs_firedpy.shp")

### Some of these treatment records are different activities that took place at the same location at the same time (ex. thinning and biomass removal)

### geometry valid
burned_ft <- st_make_valid(burned_ft)

### Open full fuel treatment database
ft <- st_read("E:/usda_2023/usfs_fuel_treatments/S_USA.Activity_HazFuelTrt_PL.shp") %>%
  mutate(., 
         ft_id = row_number()) %>%
  filter(.,
         ft_id %in% burned_ft$ft_id)

### plot one treatment and the overlap
check_ft <- ft %>% filter(ft_id == "8629")
check_burned <- burned_ft %>% filter(ft_id == "8629")
ggplot() +
  geom_sf(data = check_ft, color = "red", fill = NA) +
  geom_sf(data = check_burned, color = "blue", fill = NA) +
  NULL
### they overlap completely
st_geometry(check_ft)==st_geometry(check_burned)
## FALSE -- but why????

### get completion date and state
ft_date <- ft %>%
  dplyr::select(ft_id,
                STATE_ABBR,
                DATE_COMPL,
                geometry)
st_geometry(ft_date) <- NULL

### separate out date components
ft_date <- ft_date %>%
  mutate(date_comp = day(DATE_COMPL),
         month_comp = month(DATE_COMPL),
         year_comp = year(DATE_COMPL))

### merge in
burned_ft <- merge(x = burned_ft,
                   y = ft_date,
                   by = c("ft_id",
                          "STATE_ABBR"),
                   all.x = TRUE)

### write out
# st_write(burned_ft,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/all_burned_fuel_treats_year.shp")
# st_write(burned_ft,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/all_burned_fuel_treats_year_updated.shp")
st_write(burned_ft,
         "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_updated_polygons.shp")
```

## CODE FROM ft_overlaps.Rmd

## Overlapping fuel treatments
```{r warning = FALSE}
### open shp of burned FTs
burned_ft <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_updated_polygons.shp")

### open csv for firedpy
fp <- read.csv("E:/usda_2023/usfs_fuel_treatments/western_us/firedpy_ft_burned_all.csv")

### open csv for mtbs
mtbs_fts <- read.csv("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fts_w_us_updated.csv") %>%
  
  ### fix ignition date
  mutate(Ig_Date = make_date(year, month, date))

### rename cols for both csvs
fp <- fp %>%
  dplyr::select(ft_id, 
                firedpy_id = id,
                firedpy_ig_date = ig_date,
                firedpy_ig_day = ig_day,
                firedpy_ig_month = ig_mnth,
                firedpy_ig_year = ig_year)
mtbs_fts <- mtbs_fts %>%
  dplyr::select(ft_id, 
                mtbs_id = Event_ID,
                mtbs_ig_date = Ig_Date,
                mtbs_ig_day = date,
                mtbs_ig_month = month,
                mtbs_ig_year = year)

### merge in data
burned_mtbs <- merge(x = burned_ft,
                     y = mtbs_fts,
                     by = "ft_id",
                     all.x = TRUE)
burned_m_p <- merge(x = burned_mtbs,
                    y = fp,
                    by = "ft_id",
                    all.x = TRUE) 

### clean up intermediate files
rm(burned_mtbs, mtbs_fts, fp)

### double check that fires happened AFTER treatment
burned_m_p <- burned_m_p %>%
  mutate(interval_mtbs = round(as.numeric(difftime(DATE_COMPL,
                                                       mtbs_ig_date, units = "days"))),
         interval_fp = round(as.numeric(difftime(DATE_COMPL,
                                                       firedpy_ig_date, units = "days"))))

### are any of these values positive?
range(burned_m_p$interval_mtbs, na.rm = TRUE)
range(burned_m_p$interval_fp, na.rm = TRUE)
### nope. that's good!

### how many treatments burned in both an mtbs fire and a firedpy fire?
burned_both <- burned_m_p %>%
  filter(!is.na(mtbs_id)) %>%
  filter(!is.na(firedpy_id))
st_geometry(burned_both) <- NULL
burned_both <- burned_both %>%
  distinct()
### 837 treatments

### drop interval cols
burned_m_p <- burned_m_p %>%
  dplyr::select(-interval_mtbs,
                -interval_fp)

### figure out which fire was first
burned_m_p <- burned_m_p %>%
  mutate(int_mtbs = round(as.numeric(difftime(mtbs_ig_date,
                                                  firedpy_ig_date, 
                                              units = "days"))))
### negative value means that MTBS fire happened first
### positive value means that firedpy fire happened first

### id first fire
burned_m_p <- burned_m_p %>%
  mutate(first_fire_id = ifelse(is.na(int_mtbs) & is.na(firedpy_id),
                                mtbs_id,
                                ifelse(is.na(int_mtbs) & is.na(mtbs_id),
                                       firedpy_id,
                                       ifelse(int_mtbs < 0, mtbs_id, firedpy_id))),
         first_fire_source = ifelse(is.na(int_mtbs) & is.na(firedpy_id),
                                "mtbs",
                                ifelse(is.na(int_mtbs) & is.na(mtbs_id),
                                       "firedpy",
                                       ifelse(int_mtbs < 0, "mtbs", "firedpy"))))

### add ignition date info for first fire
burned_m_p <- burned_m_p %>%
  mutate(fire_ig_date = ifelse(first_fire_source == "mtbs",
                               as.character(mtbs_ig_date),
                               firedpy_ig_date))

### clean up
burned_m_p <- burned_m_p %>%
  dplyr::select(ft_id, 
                STATE_ABBR, 
                ACTIVITY_C, 
                ACTIVITY, 
                TREATMENT_, 
                TREATMENT1,
                DATE_COMPL, date_comp, month_comp, year_comp,
                first_fire_id,
                first_fire_source,
                fire_ig_date,
                geometry)

### write out
st_write(burned_m_p,
         "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_updated_polygons_fireID.shp")

### THESE ARE FOR THE FULL FUEL TREATMENTS -- THERE COULD BE PARTS OF THE FUEL TREATMENT THAT BURNED IN MTBS BUT NOT IN FIREDPY and VICE VERSA
```

#### look at an example
```{r}
### look at one example: ft_id = 8358
ex_ft <- burned_m_p %>%
  filter(ft_id == "8358") 

### get fire perimeters
mtbs_all <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_1984_2022_west.shp") %>%
  # filter(., Event_ID %in% ex_ft$mtbs_id)
  filter(., Event_ID == "MT4754911296120070628")
firedpy <- st_read("E:/fired_py_data/firedpy_update_2024/fired_conus_ak_2000_to_2024_events.shp") %>%
  # filter(., id %in% ex_ft$firedpy_id) %>%
  filter(., id == "149288") %>%
  st_transform(., 6350)

### plot
ggplot() +
  geom_sf(data = ex_ft) +
  geom_sf(data = mtbs_all, aes(color = Event_ID), fill = NA) +
  geom_sf(data = firedpy, aes(color = as.character(id)), fill = NA)

########
### another example: 24334
ex_ft <- burned_m_p %>%
  filter(ft_id == "24334") 
```

## Intersect with fires
Want the polygon that actually burned in each fuel treatment
```{r, warning = FALSE}
### open fire perimeter polygons
fp <- st_read("E:/fired_py_data/firedpy_update_2024/fired_conus_ak_2000_to_2024_events.shp") %>%
  filter(., id %in% burned_m_p$first_fire_id) %>%
  st_transform(., 6350) %>%
  dplyr::select(., Fire_ID = id,
                Fire_Year = ig_year,
                Start_Day = ig_month, 
                End_Day = ig_day,
                geometry)

mt <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/mtbs_1984_2022_west.shp") %>%
  dplyr::select(., Fire_ID = Event_ID,
                Fire_Year = year,
                Start_Day = month,
                End_Day = date,
                geometry) %>%
  filter(., Fire_ID %in% burned_m_p$first_fire_id)

### rbind fires
all_fires <- rbind(fp, mt)
rm(fp, mt)
gc()

### loop and get actual burned polygon
store_burned <- list()
for (i in 1:nrow(burned_m_p)) {
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get treatment i
  tr_temp <- burned_m_p[i, ]
  
  ### subset to fires that burned after
  fire_temp <- all_fires %>%
    filter(Fire_ID %in% tr_temp$first_fire_id)
  
  ### Intersect
  temp_intersect <- st_intersection(tr_temp, fire_temp)
  
  ### store intersections as a list
  store_burned[[i]] <- list(temp_intersect, unique(burned_m_p$ft_id)[i])
}
rm(burned_mp, all_fires)
gc()

### df for unlisting: temp_intersect_join
temp_intersect_join <- temp_intersect

for (i in 1:length(store_burned)) {
  # for (i in 1:10) { ## make sure it works on subset of data
  
  ### progress bar
  print(paste0("STEP ", i))
  
  ### make df
  # temp_data <- as.data.frame(store_burned[[i]][[1]])
  temp_data <- store_burned[[i]][[1]]
  
  if(nrow(temp_data) > 0) {
    
    ### rbind with adj_treat_burn
    temp_intersect_join <- rbind(temp_intersect_join,
                                 temp_data)
  } 
  
}

### drop copied row
temp_intersect_join <- temp_intersect_join %>%
  distinct()
# 35429

### write out
st_write(temp_intersect_join,
         "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_burned_polygons.shp")

# ### version for GEE
# temp_intersect_join <- temp_intersect_join %>%
#   dplyr::select(ft_id, state = STATE_A,
#                 date_comp = DATE_CO,
#                 year_comp = yer_cmp,
#                 fire_year = Fire_Yr)
# st_write(temp_intersect_join,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_gee.shp")

### clean up
rm(burned_m_p, fire_temp, store_burned,
   temp_data, temp_intersect,
   tr_temp)
gc()
```

## Drop wildfires
Drop wildfires and wildland fire use
```{r}
### remove wildfires, wildland fire use, planned treatment burned in wildfire
temp_intersect_join <- temp_intersect_join %>%
  filter(!ACTIVITY %in% c("Wildfire - Fuels Benefit",
                          "Wildfire - Human Ignition",
                          "Wildfire - Natural Ignition",
                          "Planned Treatment Burned in Wildfire",
                          "Wildland Fire Use"))

### write out
st_write(temp_intersect_join,
         "E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_burned_polygons_use.shp")
```


## Intersect overlaps
### Count by state
```{r}
### open file 
temp_intersect_join <- st_read("E:/usda_2023/usfs_fuel_treatments/western_us/burned_ft_2022/all_burned_fuel_treats_year_burned_polygons_use.shp")

### rename cols
temp_intersect_join <- temp_intersect_join %>%
  dplyr::select(ft_id,
                STATE_ABBR = STATE_A,
                ACTIVITY_C = ACTIVITY_,
                ACTIVITY, 
                TREATMENT_,
                TREATMENT1,
                DATE_CO,
                date_comp = dat_cmp,
                month_comp = mnth_cm,
                year_comp = yer_cmp,
                first_fire_id = frst_fr_d,
                first_fire_source = frst_fr_s,
                fire_ig_date = fr_g_dt,
                Fire_ID,
                Fire_Year = Fire_Yr,
                Start_Day = Strt_Dy,
                End_Day,
                geometry)


### see breakdown by state
table(temp_intersect_join$STATE_ABBR)

#   AZ    CA    CO    ID    MT    NM    NV    OR    UT    WA    WY 
# 1005 16343  1052   887   921   255    29  8104   198  2209   571 
```
For each footprint, I want to know if another footprint overlaps it. So the output I want is a df with a column for ft_id 1, ft_id 2, and true/false whether they overlap.

#### run all states
```{r, warning=FALSE}
### parallelize
plan(multicore)

### intersect in parallel
ft_fill <- future_map_dfr(1:(nrow(temp_intersect_join)-1), 
                          function(i) {
  temp_overlap <- st_intersection(temp_intersect_join[i, ],
                                  temp_intersect_join[(i+1):nrow(temp_intersect_join),
                                                      ])
  temp_overlap
}, .options = furrr_options(seed = TRUE))


### update column names
ft_fill <- ft_fill %>%
  dplyr::select(ft_id_1 = ft_id,
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = DATE_CO,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                ft_id_2 = ft_id.1,
                state_2 = STATE_ABBR.1,
                activity_2 = ACTIVITY.1,
                date_compl_2 = DATE_CO.1,
                fire_2 = first_fire_id.1,
                fire_source_2 = first_fire_source.1,
                fire_ig_2 = fire_ig_date.1,
                geometry)

### make valid
ft_fill <- st_make_valid(ft_fill) ## 93765 rows

### drop dups
ft_fill <- unique(ft_fill) ## drops 5 rows

# ### write out
# st_write(ft_fill,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/all_states.shp")
# Failed to create feature 8 in all_states
# Error: Feature creation failed.

### fix problem shapes
ft_fill_split <- ft_fill %>%
  st_collection_extract()

### write out
st_write(ft_fill_split,
         "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/all_states.shp")
```

#### nevada
```{r, warning=FALSE}
### subset to NV
test_neva <- temp_intersect_join %>%
  filter(STATE_ABBR == "NV")
# rm(temp_intersect_join)
# gc()

### make two sf dfs for dummy df
nv_1 <- test_neva %>%
  filter(ft_id == "87244")
nv_2 <- test_neva %>%
  filter(ft_id == "421221")

### intersect two to make dummy df
ft_fill <- st_intersection(nv_1,
                           nv_2)

### change columns for dummy df
ft_fill <- ft_fill %>%
  dplyr::select(ft_id_1 = ft_id, 
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                ft_id_2 = ft_id.1,
                state_2 = STATE_ABBR.1,
                activity_2 = ACTIVITY.1,
                date_compl_2 = date_comp.1,
                fire_2 = first_fire_id.1,
                fire_source_2 = first_fire_source.1,
                fire_ig_2 = fire_ig_date.1,
                geometry)

# i <- 1
### make loop
for (i in 1:nrow(test_neva)) {
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get polygon
  temp_1 <- test_neva[i, ] %>%
    dplyr::select(ft_id_1 = ft_id, 
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                geometry)
  
  ### filter dataset by the state of interest
  test_state <- test_neva %>%
    filter(STATE_ABBR == temp_1$state_1)
  
  # for (j in 2:(nrow(test_state)-1)) {
    for (j in (i+1):(nrow(test_state))) {
    
    ### get polygon 2
    temp_2 <- test_state[j, ] %>%
      dplyr::select(ft_id_2 = ft_id,
                    state_2 = STATE_ABBR,
                    activity_2 = ACTIVITY,
                    date_compl_2 = date_comp,
                    fire_2 = first_fire_id,
                    fire_source_2 = first_fire_source,
                    fire_ig_2 = fire_ig_date,
                    geometry)
    
    # if(temp_1$ft_id_1 != temp_2$ft_id_2) {
      
      ### intersect
      temp_overlap <- st_intersection(temp_1,
                                      temp_2)
      
      # ### store intersections as a list
      # store_overlaps[j] <- temp_overlap
      
      ### add to df
      ft_fill <- rbind(ft_fill,
                       temp_overlap)
    # }
    
  }
  
}

### remove dup row
ft_fill <- ft_fill %>%
  distinct()

### make valid
ft_fill <- st_make_valid(ft_fill)

# ### add area
# ft_fill$area_overlap <- as.numeric(sf::st_area(ft_fill))

# ### remove problem geoms
# ft_fill <- ft_fill %>%
#   filter(area_overlap > 905)

# ### write out
# st_write(ft_fill,
#          "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/neva.shp")
### can't write this out: Failed to create feature 0 in neva

### fix problem shapes
ft_fill_split <- ft_fill %>%
  st_collection_extract()

### what is this doing?
# 87244
# NV
# Burning of Piled Material
# 2015-11-20
# NV3925811988320161014
# mtbs
# 2016-10-14
# 421221

### check with one row from ft_fill
check <- ft_fill %>%
   filter(ft_id_1 == "87244" & ft_id_2 == "421221")
ggplot() +
  geom_sf(data = check)
check_2 <- ft_fill_split %>%
  filter(ft_id_1 == "87244" & ft_id_2 == "421221")
ggplot() +
  geom_sf(data = check, color = "red", fill = "red", alpha = 0.2) +
  geom_sf(data = check_2, color = "blue", fill = "blue", alpha = 0.2)
### splits GEOMETRY COLLECTIONS to individual objects, drops part of the object (line, point)

### are any of the objects just dropped?
length(unique(ft_fill$ft_id_1))
length(unique(ft_fill_split$ft_id_1))
### yes, looks like there are 4 ft_id_1's that are dropped
check <- ft_fill %>%
  filter(!ft_id_1 %in% ft_fill_split$ft_id_1)
ggplot() +
  geom_sf(data = check, aes(color = "ft_id_1"))
### the ones that get dropped are MULTILINESTRINGs

# write out
st_write(ft_fill_split,
         "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/neva.shp")

### clean up
rm(ft_fill, ft_fill_split, temp_1,
   temp_2, temp_overlap, test_neva, test_state)
gc()
```

#### utah
```{r, warning=FALSE}
### subset to UT
utah <- temp_intersect_join %>%
  filter(STATE_ABBR == "UT")

### intersect two to make dummy df
ft_fill <- st_intersection(nv_1,
                           nv_2)

### change columns for dummy df
ft_fill <- ft_fill %>%
  dplyr::select(ft_id_1 = ft_id, 
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                ft_id_2 = ft_id.1,
                state_2 = STATE_ABBR.1,
                activity_2 = ACTIVITY.1,
                date_compl_2 = date_comp.1,
                fire_2 = first_fire_id.1,
                fire_source_2 = first_fire_source.1,
                fire_ig_2 = fire_ig_date.1,
                geometry)

# i <- 1
### make loop
for (i in 1:nrow(utah)) {
  ### progress bar
  print(paste0("STEP ", i))
  
  ### get polygon
  temp_1 <- utah[i, ] %>%
    dplyr::select(ft_id_1 = ft_id, 
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                geometry)
  
  ### filter dataset by the state of interest
  test_state <- utah %>%
    filter(STATE_ABBR == temp_1$state_1)
  
  for (j in (i+1):(nrow(test_state))) {
    
    ### get polygon 2
    temp_2 <- test_state[j, ] %>%
      dplyr::select(ft_id_2 = ft_id,
                    state_2 = STATE_ABBR,
                    activity_2 = ACTIVITY,
                    date_compl_2 = date_comp,
                    fire_2 = first_fire_id,
                    fire_source_2 = first_fire_source,
                    fire_ig_2 = fire_ig_date,
                    geometry)
  
      ### intersect
      temp_overlap <- st_intersection(temp_1,
                                      temp_2)
      
      # ### store intersections as a list
      # store_overlaps[j] <- temp_overlap
      
      ### add to df
      ft_fill <- rbind(ft_fill,
                       temp_overlap)
    
  }
  
}

### remove dup row
ft_fill <- ft_fill %>%
  distinct()

### make valid
ft_fill <- st_make_valid(ft_fill)

### fix problem shapes
ft_fill_split <- ft_fill %>%
  st_collection_extract()

# ### are any of the objects just dropped?
# length(unique(ft_fill$ft_id_1))
# length(unique(ft_fill_split$ft_id_1))
# ### yes, 16 ft_id_1 are dropped
# check <- ft_fill %>%
#   filter(!ft_id_1 %in% ft_fill_split$ft_id_1)
# check[3, ] %>%
#   ggplot() +
#   geom_sf()
# ### the ones that get dropped are LINESTRINGs, MULTILINESTRINGs, and POINTs

### write out
st_write(ft_fill_split,
         "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/utah.shp")

### clean up
rm(utah, ft_fill_split, ft_fill, 
   temp_1, temp_2, temp_overlap, test_state)
gc()
```

#### new mexico
```{r, warning=FALSE}
### subset to UT
nmex <- temp_intersect_join %>%
  filter(STATE_ABBR == "NM")

### intersect two to make dummy df
ft_fill <- st_intersection(nv_1,
                           nv_2)

### change columns for dummy df
ft_fill <- ft_fill %>%
  dplyr::select(ft_id_1 = ft_id, 
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                ft_id_2 = ft_id.1,
                state_2 = STATE_ABBR.1,
                activity_2 = ACTIVITY.1,
                date_compl_2 = date_comp.1,
                fire_2 = first_fire_id.1,
                fire_source_2 = first_fire_source.1,
                fire_ig_2 = fire_ig_date.1,
                geometry)

### parallelize
plan(multicore)

### intersect in parallel
ft_fill <- future_map_dfr(1:(nrow(nmex)-1), function(i) {
  temp_overlap <- st_intersection(nmex[i, ],
                                  nmex[(i+1):nrow(nmex), ])
  temp_overlap
}, .options = furrr_options(seed = TRUE))

# ### make loop
# for (i in 1:nrow(nmex)) {
#   ### progress bar
#   print(paste0("STEP ", i))
# 
#   ### get polygon
#   temp_1 <- nmex[i, ] %>%
#     dplyr::select(ft_id_1 = ft_id,
#                 state_1 = STATE_ABBR,
#                 activity_1 = ACTIVITY,
#                 date_compl_1 = date_comp,
#                 fire_1 = first_fire_id,
#                 fire_source_1 = first_fire_source,
#                 fire_ig_1 = fire_ig_date,
#                 geometry)
# 
#   ### filter dataset by the state of interest
#   test_state <- nmex %>%
#     filter(STATE_ABBR == temp_1$state_1)
# 
#   for (j in (i+1):(nrow(test_state))) {
# 
#     ### get polygon 2
#     temp_2 <- test_state[j, ] %>%
#       dplyr::select(ft_id_2 = ft_id,
#                     state_2 = STATE_ABBR,
#                     activity_2 = ACTIVITY,
#                     date_compl_2 = date_comp,
#                     fire_2 = first_fire_id,
#                     fire_source_2 = first_fire_source,
#                     fire_ig_2 = fire_ig_date,
#                     geometry)
# 
#       ### intersect
#       temp_overlap <- st_intersection(temp_1,
#                                       temp_2)
# 
#       # ### store intersections as a list
#       # store_overlaps[j] <- temp_overlap
# 
#       ### add to df
#       ft_fill <- rbind(ft_fill,
#                        temp_overlap)
#     }
# 
# }

### update column names
ft_fill <- ft_fill %>%
  dplyr::select(ft_id_1 = ft_id,
                state_1 = STATE_ABBR,
                activity_1 = ACTIVITY,
                date_compl_1 = date_comp,
                fire_1 = first_fire_id,
                fire_source_1 = first_fire_source,
                fire_ig_1 = fire_ig_date,
                ft_id_2 = ft_id.1,
                state_2 = STATE_ABBR.1,
                activity_2 = ACTIVITY.1,
                date_compl_2 = date_comp.1,
                fire_2 = first_fire_id.1,
                fire_source_2 = first_fire_source.1,
                fire_ig_2 = fire_ig_date.1,
                geometry)

### remove neva dup row
ft_fill <- ft_fill %>%
  filter(state_1 == "NM")

### make valid
ft_fill <- st_make_valid(ft_fill)

### fix problem shapes
ft_fill_split <- ft_fill %>%
  st_collection_extract()

### are any of the objects just dropped?
length(unique(ft_fill$ft_id_1))
length(unique(ft_fill_split$ft_id_1))
### yes, 3 ft_id_1 are dropped
check <- ft_fill %>%
  filter(!ft_id_1 %in% ft_fill_split$ft_id_1)
check %>%
  ggplot() +
  geom_sf()
### the ones that get dropped are LINESTRINGs

### write out
st_write(ft_fill_split,
         "E:/usda_2023/usfs_fuel_treatments/western_us/fuel_treat_overlaps/nmex_check.shp")

### clean up
rm(nmex, ft_fill_split, ft_fill, 
   temp_1, temp_2, temp_overlap, test_state)
gc()
```